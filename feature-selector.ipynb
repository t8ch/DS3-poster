{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, Sequential, initializers, constraints, regularizers, backend\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook',font_scale=1.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel contraint that effectively implements one-to-one connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define feature selection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# all you need to create a mask matrix M, which is a NxN identity matrix\n",
    "# and you can write a contraint like below\n",
    "class DiagonalWeight(constraints.Constraint):\n",
    "    \"\"\"Constrains the weights to be diagonal.\n",
    "    \"\"\"\n",
    "    def __call__(self, w):\n",
    "        N = tf.shape(w)[-1]\n",
    "        m = tf.eye(N)\n",
    "        w = m*w\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regularizer: L1 + time-dependent tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modified L0 loss: $\\tilde L_0 = \\alpha \\sum_n |w_n+\\beta|$, with $\\beta=0.05$ here.\n",
    "\n",
    "only one-to-one connections (=diagonal weight matrix): $w_{nk} = w_{n}\\text{ if } $n=k$\\text{ and 0 otherwise}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class L1_tilde(regularizers.Regularizer):\n",
    "    \"\"\"Regularizer for ...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalization = 1000, alpha = .05):\n",
    "        self.counter = 0\n",
    "        self.normalization = normalization\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, x):\n",
    "        regularization = 0.\n",
    "        prefactor = min(1,self.counter/self.normalization)\n",
    "        regularization += backend.sum(backend.abs(x+0.05))\n",
    "        self.counter += 1\n",
    "        return self.alpha*regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class selection_layer(layers.Dense):\n",
    "    def __init__(self, units, norm=1000, alpha=0.05):\n",
    "        super(selection_layer, self).__init__(units, kernel_constraint=DiagonalWeight(),\n",
    "                                        kernel_initializer = initializers.Ones(),\n",
    "                                        kernel_regularizer= L1_tilde(alpha=alpha, normalization=norm),\n",
    "                                        #bias_regularizer=constant_bias(),\n",
    "                                        activation='relu',\n",
    "                                        use_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        weights = tf.linalg.tensor_diag_part((model.layers[0].weights[0]).numpy())\n",
    "        weights_history.append(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## most naive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([selection_layer(5)])\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_x = np.random.normal(size=(600,5))\n",
    "test_y = np.concatenate((test_x[:,:4],np.random.normal(size = (600,1))), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples\n",
      "Epoch 1/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 2/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 3/300\n",
      "600/600 [==============================] - 0s 32us/sample - loss: 0.3882\n",
      "Epoch 4/300\n",
      "600/600 [==============================] - 0s 37us/sample - loss: 0.3882\n",
      "Epoch 5/300\n",
      "600/600 [==============================] - 0s 28us/sample - loss: 0.3882\n",
      "Epoch 6/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n",
      "Epoch 7/300\n",
      "600/600 [==============================] - 0s 39us/sample - loss: 0.3882\n",
      "Epoch 8/300\n",
      "600/600 [==============================] - 0s 39us/sample - loss: 0.3882\n",
      "Epoch 9/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 10/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 11/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 12/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 13/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 14/300\n",
      "600/600 [==============================] - 0s 37us/sample - loss: 0.3882\n",
      "Epoch 15/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 16/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 17/300\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.3882\n",
      "Epoch 18/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 19/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 20/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3881\n",
      "Epoch 21/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 22/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 23/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 24/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 25/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 26/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 27/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 28/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 29/300\n",
      "600/600 [==============================] - 0s 42us/sample - loss: 0.3881\n",
      "Epoch 30/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 31/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 32/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 33/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 34/300\n",
      "600/600 [==============================] - 0s 42us/sample - loss: 0.3882\n",
      "Epoch 35/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3881\n",
      "Epoch 36/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 37/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 38/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 39/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3881\n",
      "Epoch 40/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 41/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 42/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 43/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 44/300\n",
      "600/600 [==============================] - 0s 39us/sample - loss: 0.3882\n",
      "Epoch 45/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3881\n",
      "Epoch 46/300\n",
      "600/600 [==============================] - 0s 38us/sample - loss: 0.3882\n",
      "Epoch 47/300\n",
      "600/600 [==============================] - 0s 39us/sample - loss: 0.3882\n",
      "Epoch 48/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 49/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 50/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 51/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 52/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 53/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 54/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 55/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 56/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 57/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 58/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 59/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 60/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 61/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3881\n",
      "Epoch 62/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 63/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 64/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 65/300\n",
      "600/600 [==============================] - 0s 36us/sample - loss: 0.3882\n",
      "Epoch 66/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 67/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3881\n",
      "Epoch 68/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 69/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 70/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 71/300\n",
      "600/600 [==============================] - 0s 29us/sample - loss: 0.3882\n",
      "Epoch 72/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 73/300\n",
      "600/600 [==============================] - 0s 37us/sample - loss: 0.3882\n",
      "Epoch 74/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 75/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 76/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 77/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3881\n",
      "Epoch 78/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 79/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 80/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 81/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 82/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 83/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n",
      "Epoch 84/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 85/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 86/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 87/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 88/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 89/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 90/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 91/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 92/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 93/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 94/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 95/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 97/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 98/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 99/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 100/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 101/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 102/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 103/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 104/300\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.3882\n",
      "Epoch 105/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 106/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 107/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 108/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 109/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 110/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 111/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 112/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 113/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3881\n",
      "Epoch 114/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 115/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 116/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 117/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 118/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 119/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 120/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 121/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 122/300\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.3882\n",
      "Epoch 123/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 124/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3881\n",
      "Epoch 125/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 126/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 127/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 128/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 129/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 130/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 131/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 132/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 133/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3881\n",
      "Epoch 134/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 135/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 136/300\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.3882\n",
      "Epoch 137/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 138/300\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.3882\n",
      "Epoch 139/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3881\n",
      "Epoch 140/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 141/300\n",
      "600/600 [==============================] - 0s 58us/sample - loss: 0.3882\n",
      "Epoch 142/300\n",
      "600/600 [==============================] - 0s 42us/sample - loss: 0.3882\n",
      "Epoch 143/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 144/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 145/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 146/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 147/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 148/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 149/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3881\n",
      "Epoch 150/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 151/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3881\n",
      "Epoch 152/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 153/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 154/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 155/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 156/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 157/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 158/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 159/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 160/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 161/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 162/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 163/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 164/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 165/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 166/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 167/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 168/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 169/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 170/300\n",
      "600/600 [==============================] - 0s 56us/sample - loss: 0.3882\n",
      "Epoch 171/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 172/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 173/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 174/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 175/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 176/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 177/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3881\n",
      "Epoch 178/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 179/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 180/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 181/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 182/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 183/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 184/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 185/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 186/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 187/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 188/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 189/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 190/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 191/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 192/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 193/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 194/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 195/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 196/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 197/300\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.3882\n",
      "Epoch 198/300\n",
      "600/600 [==============================] - 0s 61us/sample - loss: 0.3882\n",
      "Epoch 199/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 200/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 201/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 202/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 203/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 204/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 205/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 206/300\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.3882\n",
      "Epoch 207/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 208/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 209/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 210/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 211/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 212/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 213/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 214/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 215/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 216/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 217/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 218/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 219/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 220/300\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.3882\n",
      "Epoch 221/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 222/300\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.3882\n",
      "Epoch 223/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3881\n",
      "Epoch 224/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3881\n",
      "Epoch 225/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 226/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 227/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 228/300\n",
      "600/600 [==============================] - 0s 36us/sample - loss: 0.3882\n",
      "Epoch 229/300\n",
      "600/600 [==============================] - 0s 35us/sample - loss: 0.3882\n",
      "Epoch 230/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 231/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 232/300\n",
      "600/600 [==============================] - 0s 38us/sample - loss: 0.3882\n",
      "Epoch 233/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 234/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 235/300\n",
      "600/600 [==============================] - 0s 40us/sample - loss: 0.3882\n",
      "Epoch 236/300\n",
      "600/600 [==============================] - 0s 43us/sample - loss: 0.3882\n",
      "Epoch 237/300\n",
      "600/600 [==============================] - 0s 41us/sample - loss: 0.3882\n",
      "Epoch 238/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n",
      "Epoch 239/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 240/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 241/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 242/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 243/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 244/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 245/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 246/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 247/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3881\n",
      "Epoch 248/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 249/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 250/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 251/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 252/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 253/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 254/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 255/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 256/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 257/300\n",
      "600/600 [==============================] - 0s 42us/sample - loss: 0.3882\n",
      "Epoch 258/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 259/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 260/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 261/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 262/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 263/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 264/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 265/300\n",
      "600/600 [==============================] - 0s 47us/sample - loss: 0.3882\n",
      "Epoch 266/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 267/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 268/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 269/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 270/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n",
      "Epoch 271/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 272/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 273/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n",
      "Epoch 274/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 275/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 276/300\n",
      "600/600 [==============================] - 0s 46us/sample - loss: 0.3882\n",
      "Epoch 277/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 278/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 279/300\n",
      "600/600 [==============================] - 0s 52us/sample - loss: 0.3882\n",
      "Epoch 280/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 281/300\n",
      "600/600 [==============================] - 0s 45us/sample - loss: 0.3882\n",
      "Epoch 282/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 283/300\n",
      "600/600 [==============================] - 0s 39us/sample - loss: 0.3882\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 285/300\n",
      "600/600 [==============================] - 0s 51us/sample - loss: 0.3882\n",
      "Epoch 286/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 287/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 288/300\n",
      "600/600 [==============================] - 0s 53us/sample - loss: 0.3882\n",
      "Epoch 289/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 290/300\n",
      "600/600 [==============================] - 0s 48us/sample - loss: 0.3882\n",
      "Epoch 291/300\n",
      "600/600 [==============================] - 0s 57us/sample - loss: 0.3882\n",
      "Epoch 292/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 293/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 294/300\n",
      "600/600 [==============================] - 0s 54us/sample - loss: 0.3882\n",
      "Epoch 295/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 296/300\n",
      "600/600 [==============================] - 0s 50us/sample - loss: 0.3882\n",
      "Epoch 297/300\n",
      "600/600 [==============================] - 0s 49us/sample - loss: 0.3882\n",
      "Epoch 298/300\n",
      "600/600 [==============================] - 0s 55us/sample - loss: 0.3882\n",
      "Epoch 299/300\n",
      "600/600 [==============================] - 0s 59us/sample - loss: 0.3882\n",
      "Epoch 300/300\n",
      "600/600 [==============================] - 0s 44us/sample - loss: 0.3882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f455b882c50>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(test_x, test_y, epochs = 300, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential_45/selection_layer_62/kernel:0' shape=(5, 5) dtype=float32, numpy=\n",
       " array([[ 0.8783788 ,  0.        ,  0.        ,  0.        , -0.        ],\n",
       "        [ 0.        ,  0.8741574 ,  0.        , -0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.8655264 , -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        ,  0.88217187,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        , -0.        , -0.0020455 ]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### train for different alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 348us/sample - loss: 8.6623\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.2397\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.2102\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.1805\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.1512\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.1184\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0837\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0494\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0188\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9892\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9605\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9329\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9056\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8808\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8593\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8412\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8245\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8086\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7945\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.7814\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7699\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7593\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.7501\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.7409\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7333\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.7254\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7176\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7096\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7030\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.6958\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6899\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.6832\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6771\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6706\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6647\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.6582\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6527\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6479\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6430\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 37us/sample - loss: 0.6382\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6339\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.6289\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6254\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6200\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6157\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6118\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6075\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6025\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5978\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5931\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5883\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5842\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5795\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5754\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5713\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5678\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.5643\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5594\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5566\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5530\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5486\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5450\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5400\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5373\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5331\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5302\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5260\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5231\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5192\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5162\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5119\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5083\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5046\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.5015\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.4984\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.4942\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4917\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.4883\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4851\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4816\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.4779\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4745\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4707\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.4675\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4646\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4609\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.4580\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4555\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.4517\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4478\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4455\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4439\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.4404\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4381\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.4348\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4329\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4306\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4278\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.4240\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.4220\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.4187\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 0.4156\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.4141\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.4108\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.4080\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4064\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4020\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4005\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.3973\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.3947\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3918\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.3905\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3879\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.3854\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.3828\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.3816\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.3789\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.3760\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.3752\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.3721\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.3698\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3675\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.3658\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.3635\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 0.3608\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 34us/sample - loss: 0.3599\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.3563\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3559\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3543\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.3520\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.3503\n",
      "Epoch 132/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.3496\n",
      "Epoch 133/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.3466\n",
      "Epoch 134/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3459\n",
      "Epoch 135/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.3434\n",
      "Epoch 136/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.3423\n",
      "Epoch 137/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.3399\n",
      "Epoch 138/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.3383\n",
      "Epoch 139/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.3362\n",
      "Epoch 140/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.3343\n",
      "Epoch 141/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3326\n",
      "Epoch 142/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.3306\n",
      "Epoch 143/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.3300\n",
      "Epoch 144/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3289\n",
      "Epoch 145/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.3266\n",
      "Epoch 146/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3257\n",
      "Epoch 147/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.3240\n",
      "Epoch 148/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.3232\n",
      "Epoch 149/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.3222\n",
      "Epoch 150/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.3218\n",
      "Epoch 151/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.3199\n",
      "Epoch 152/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.3184\n",
      "Epoch 153/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.3181\n",
      "Epoch 154/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3159\n",
      "Epoch 155/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.3144\n",
      "Epoch 156/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.3146\n",
      "Epoch 157/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.3126\n",
      "Epoch 158/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.3113\n",
      "Epoch 159/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.3107\n",
      "Epoch 160/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.3102\n",
      "Epoch 161/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.3083\n",
      "Epoch 162/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.3078\n",
      "Epoch 163/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.3070\n",
      "Epoch 164/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.3063\n",
      "Epoch 165/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.3050\n",
      "Epoch 166/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.3051\n",
      "Epoch 167/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3031\n",
      "Epoch 168/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.3016\n",
      "Epoch 169/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.3019\n",
      "Epoch 170/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.3018\n",
      "Epoch 171/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.3002\n",
      "Epoch 172/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.2999\n",
      "Epoch 173/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2991\n",
      "Epoch 174/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2978\n",
      "Epoch 175/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2972\n",
      "Epoch 176/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.2966\n",
      "Epoch 177/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.2961\n",
      "Epoch 178/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2950\n",
      "Epoch 179/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2944\n",
      "Epoch 180/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.2935\n",
      "Epoch 181/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2939\n",
      "Epoch 182/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2930\n",
      "Epoch 183/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2919\n",
      "Epoch 184/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2913\n",
      "Epoch 185/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2902\n",
      "Epoch 186/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2910\n",
      "Epoch 187/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2900\n",
      "Epoch 188/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2894\n",
      "Epoch 189/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2899\n",
      "Epoch 190/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2873\n",
      "Epoch 191/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2877\n",
      "Epoch 192/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2876\n",
      "Epoch 193/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2858\n",
      "Epoch 194/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2865\n",
      "Epoch 195/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2857\n",
      "Epoch 196/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2856\n",
      "Epoch 197/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.2841\n",
      "Epoch 198/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2841\n",
      "Epoch 199/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2843\n",
      "Epoch 200/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2826\n",
      "Epoch 201/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2831\n",
      "Epoch 202/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2820\n",
      "Epoch 203/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2816\n",
      "Epoch 204/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2808\n",
      "Epoch 205/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2809\n",
      "Epoch 206/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2810\n",
      "Epoch 207/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2790\n",
      "Epoch 208/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2787\n",
      "Epoch 209/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2785\n",
      "Epoch 210/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2768\n",
      "Epoch 211/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2776\n",
      "Epoch 212/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2767\n",
      "Epoch 213/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2769\n",
      "Epoch 214/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2759\n",
      "Epoch 215/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2755\n",
      "Epoch 216/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2753\n",
      "Epoch 217/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2745\n",
      "Epoch 218/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2735\n",
      "Epoch 219/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2746\n",
      "Epoch 220/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2739\n",
      "Epoch 221/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2732\n",
      "Epoch 222/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2726\n",
      "Epoch 223/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2713\n",
      "Epoch 224/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2717\n",
      "Epoch 225/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2719\n",
      "Epoch 226/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2706\n",
      "Epoch 227/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.2692\n",
      "Epoch 228/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2702\n",
      "Epoch 229/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2697\n",
      "Epoch 230/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2694\n",
      "Epoch 231/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.2686\n",
      "Epoch 232/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.2678\n",
      "Epoch 233/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2680\n",
      "Epoch 234/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2688\n",
      "Epoch 235/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.2670\n",
      "Epoch 236/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.2672\n",
      "Epoch 237/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2664\n",
      "Epoch 238/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2665\n",
      "Epoch 239/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2664\n",
      "Epoch 240/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2649\n",
      "Epoch 241/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2655\n",
      "Epoch 242/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2649\n",
      "Epoch 243/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2658\n",
      "Epoch 244/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2644\n",
      "Epoch 245/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2647\n",
      "Epoch 246/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2644\n",
      "Epoch 247/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2620\n",
      "Epoch 248/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2633\n",
      "Epoch 249/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2627\n",
      "Epoch 250/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.2628\n",
      "Epoch 251/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2631\n",
      "Epoch 252/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2619\n",
      "Epoch 253/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2617\n",
      "Epoch 254/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2621\n",
      "Epoch 255/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2608\n",
      "Epoch 256/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2615\n",
      "Epoch 257/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2601\n",
      "Epoch 258/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 0.2606\n",
      "Epoch 259/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2618\n",
      "Epoch 260/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.2593\n",
      "Epoch 261/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2603\n",
      "Epoch 262/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2599\n",
      "Epoch 263/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2590\n",
      "Epoch 264/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2597\n",
      "Epoch 265/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2591\n",
      "Epoch 266/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2598\n",
      "Epoch 267/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2580\n",
      "Epoch 268/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2596\n",
      "Epoch 269/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2585\n",
      "Epoch 270/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2580\n",
      "Epoch 271/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2572\n",
      "Epoch 272/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2584\n",
      "Epoch 273/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2564\n",
      "Epoch 274/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2565\n",
      "Epoch 275/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.2566\n",
      "Epoch 276/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2567\n",
      "Epoch 277/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2560\n",
      "Epoch 278/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2567\n",
      "Epoch 279/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2570\n",
      "Epoch 280/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2551\n",
      "Epoch 281/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2562\n",
      "Epoch 282/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2555\n",
      "Epoch 283/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2546\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2545\n",
      "Epoch 285/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2549\n",
      "Epoch 286/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2549\n",
      "Epoch 287/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2544\n",
      "Epoch 288/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2536\n",
      "Epoch 289/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.2551\n",
      "Epoch 290/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2539\n",
      "Epoch 291/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2536\n",
      "Epoch 292/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2533\n",
      "Epoch 293/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2522\n",
      "Epoch 294/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2536\n",
      "Epoch 295/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2532\n",
      "Epoch 296/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2532\n",
      "Epoch 297/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2522\n",
      "Epoch 298/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2528\n",
      "Epoch 299/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2530\n",
      "Epoch 300/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2523\n",
      "Epoch 301/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2520\n",
      "Epoch 302/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2527\n",
      "Epoch 303/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2521\n",
      "Epoch 304/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2506\n",
      "Epoch 305/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2512\n",
      "Epoch 306/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2520\n",
      "Epoch 307/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2506\n",
      "Epoch 308/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2506\n",
      "Epoch 309/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2510\n",
      "Epoch 310/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.2495\n",
      "Epoch 311/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2505\n",
      "Epoch 312/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2501\n",
      "Epoch 313/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2497\n",
      "Epoch 314/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2504\n",
      "Epoch 315/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2500\n",
      "Epoch 316/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.2491\n",
      "Epoch 317/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2497\n",
      "Epoch 318/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2493\n",
      "Epoch 319/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2496\n",
      "Epoch 320/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2493\n",
      "Epoch 321/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2483\n",
      "Epoch 322/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.2491\n",
      "Epoch 323/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.2485\n",
      "Epoch 324/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2487\n",
      "Epoch 325/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2489\n",
      "Epoch 326/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2487\n",
      "Epoch 327/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2493\n",
      "Epoch 328/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2476\n",
      "Epoch 329/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2479\n",
      "Epoch 330/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.2482\n",
      "Epoch 331/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2470\n",
      "Epoch 332/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2476\n",
      "Epoch 333/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2475\n",
      "Epoch 334/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2470\n",
      "Epoch 335/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2470\n",
      "Epoch 336/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2469\n",
      "Epoch 337/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2476\n",
      "Epoch 338/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2459\n",
      "Epoch 339/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2470\n",
      "Epoch 340/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2466\n",
      "Epoch 341/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2470\n",
      "Epoch 342/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2460\n",
      "Epoch 343/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2461\n",
      "Epoch 344/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2460\n",
      "Epoch 345/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2464\n",
      "Epoch 346/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2445\n",
      "Epoch 347/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2464\n",
      "Epoch 348/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2457\n",
      "Epoch 349/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.2456\n",
      "Epoch 350/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2444\n",
      "Epoch 351/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2452\n",
      "Epoch 352/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.2449\n",
      "Epoch 353/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2447\n",
      "Epoch 354/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2444\n",
      "Epoch 355/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2454\n",
      "Epoch 356/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2454\n",
      "Epoch 357/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2448\n",
      "Epoch 358/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2451\n",
      "Epoch 359/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2450\n",
      "Epoch 360/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2438\n",
      "Epoch 361/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2443\n",
      "Epoch 362/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2445\n",
      "Epoch 363/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2434\n",
      "Epoch 364/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2447\n",
      "Epoch 365/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2441\n",
      "Epoch 366/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2450\n",
      "Epoch 367/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2436\n",
      "Epoch 368/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2438\n",
      "Epoch 369/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2434\n",
      "Epoch 370/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2438\n",
      "Epoch 371/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2433\n",
      "Epoch 372/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2429\n",
      "Epoch 373/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2429\n",
      "Epoch 374/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2434\n",
      "Epoch 375/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2424\n",
      "Epoch 376/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2428\n",
      "Epoch 377/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2429\n",
      "Epoch 378/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2427\n",
      "Epoch 379/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2424\n",
      "Epoch 380/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2423\n",
      "Epoch 381/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2416\n",
      "Epoch 382/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2437\n",
      "Epoch 383/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2424\n",
      "Epoch 384/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2421\n",
      "Epoch 385/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2424\n",
      "Epoch 386/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2417\n",
      "Epoch 387/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.2421\n",
      "Epoch 388/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2410\n",
      "Epoch 389/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2421\n",
      "Epoch 390/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2416\n",
      "Epoch 391/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2416\n",
      "Epoch 392/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2400\n",
      "Epoch 393/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2425\n",
      "Epoch 394/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2412\n",
      "Epoch 395/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2414\n",
      "Epoch 396/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2407\n",
      "Epoch 397/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2408\n",
      "Epoch 398/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2404\n",
      "Epoch 399/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2405\n",
      "Epoch 400/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2402\n",
      "Epoch 401/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2403\n",
      "Epoch 402/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2415\n",
      "Epoch 403/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2402\n",
      "Epoch 404/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2395\n",
      "Epoch 405/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2424\n",
      "Epoch 406/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.2389\n",
      "Epoch 407/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2395\n",
      "Epoch 408/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2393\n",
      "Epoch 409/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2398\n",
      "Epoch 410/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2404\n",
      "Epoch 411/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.2393\n",
      "Epoch 412/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2398\n",
      "Epoch 413/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2389\n",
      "Epoch 414/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2391\n",
      "Epoch 415/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2397\n",
      "Epoch 416/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2390\n",
      "Epoch 417/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2397\n",
      "Epoch 418/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2394\n",
      "Epoch 419/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2378\n",
      "Epoch 420/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2391\n",
      "Epoch 421/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2394\n",
      "Epoch 422/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2383\n",
      "Epoch 423/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2378\n",
      "Epoch 424/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2391\n",
      "Epoch 425/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2373\n",
      "Epoch 426/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2385\n",
      "Epoch 427/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2382\n",
      "Epoch 428/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.2381\n",
      "Epoch 429/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2384\n",
      "Epoch 430/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2378\n",
      "Epoch 431/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2378\n",
      "Epoch 432/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2385\n",
      "Epoch 433/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2386\n",
      "Epoch 434/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2376\n",
      "Epoch 435/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2374\n",
      "Epoch 436/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2378\n",
      "Epoch 437/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2372\n",
      "Epoch 438/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2379\n",
      "Epoch 439/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2374\n",
      "Epoch 440/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2372\n",
      "Epoch 441/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2378\n",
      "Epoch 442/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2376\n",
      "Epoch 443/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2382\n",
      "Epoch 444/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2371\n",
      "Epoch 445/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2366\n",
      "Epoch 446/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2360\n",
      "Epoch 447/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 0.2367\n",
      "Epoch 448/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.2373\n",
      "Epoch 449/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2360\n",
      "Epoch 450/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2368\n",
      "Epoch 451/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2378\n",
      "Epoch 452/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2358\n",
      "Epoch 453/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2363\n",
      "Epoch 454/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2358\n",
      "Epoch 455/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2366\n",
      "Epoch 456/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2364\n",
      "Epoch 457/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.2358\n",
      "Epoch 458/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2369\n",
      "Epoch 459/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2349\n",
      "Epoch 460/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2356\n",
      "Epoch 461/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2349\n",
      "Epoch 462/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2371\n",
      "Epoch 463/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2347\n",
      "Epoch 464/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.2359\n",
      "Epoch 465/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2354\n",
      "Epoch 466/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2359\n",
      "Epoch 467/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2347\n",
      "Epoch 468/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2353\n",
      "Epoch 469/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2354\n",
      "Epoch 470/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2351\n",
      "Epoch 471/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2356\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 67us/sample - loss: 0.2358\n",
      "Epoch 473/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2349\n",
      "Epoch 474/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2343\n",
      "Epoch 475/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.2350\n",
      "Epoch 476/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2353\n",
      "Epoch 477/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2344\n",
      "Epoch 478/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2342\n",
      "Epoch 479/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2344\n",
      "Epoch 480/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2336\n",
      "Epoch 481/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.2347\n",
      "Epoch 482/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2344\n",
      "Epoch 483/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2343\n",
      "Epoch 484/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.2345\n",
      "Epoch 485/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.2340\n",
      "Epoch 486/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.2341\n",
      "Epoch 487/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.2338\n",
      "Epoch 488/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.2342\n",
      "Epoch 489/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.2340\n",
      "Epoch 490/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.2332\n",
      "Epoch 491/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.2340\n",
      "Epoch 492/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.2334\n",
      "Epoch 493/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2338\n",
      "Epoch 494/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.2331\n",
      "Epoch 495/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2338\n",
      "Epoch 496/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.2338\n",
      "Epoch 497/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.2340\n",
      "Epoch 498/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2327\n",
      "Epoch 499/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.2325\n",
      "Epoch 500/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.2337\n",
      "Train on 400 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 350us/sample - loss: 15.1871\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 8.4749\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 8.1803\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 7.9333\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 7.7081\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 7.5056\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 7.3237\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 7.1536\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 6.9916\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 6.8366\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 6.6924\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 6.5560\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 6.4279\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 6.3071\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 6.1920\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 6.0829\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 5.9787\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 5.8772\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 5.7755\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 5.6767\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 5.5778\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 5.4804\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 5.3852\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 5.2906\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 5.1979\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 5.1048\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 5.0128\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 4.9216\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 4.8312\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 4.7408\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 4.6516\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 4.5624\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 4.4739\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 4.3864\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 4.2980\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 4.2104\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 4.1237\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 4.0371\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 3.9507\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 3.8643\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 3.7794\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 3.6932\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 3.6075\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 3.5216\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 3.4369\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 3.3525\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 3.2694\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 3.1857\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 3.1030\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 3.0198\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 34us/sample - loss: 2.9369\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 2.8545\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 2.7734\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 2.6927\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 2.6108\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 2.5317\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 2.4516\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 2.3719\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 2.2927\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 2.2142\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 2.1376\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 2.0619\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.9867\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.9129\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.8421\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.7089\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.6409\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.5738\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.5074\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.4435\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.3812\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.3210\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.2649\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.2110\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.1577\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.1123\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0842\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0658\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0490\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0358\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0296\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0239\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0195\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 1.0168\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0134\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0110\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0092\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0046\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0027\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0004\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9962\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9936\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9901\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9878\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9842\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9809\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9785\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9750\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.9716\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9685\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.9650\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9618\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9585\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9565\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9529\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9484\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9476\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9416\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9391\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.9355\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.9322\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9294\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9251\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9217\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9169\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9143\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9121\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9088\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9034\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9007\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.8971\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8943\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8893\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8894\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8841\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8808\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8769\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8756\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8720\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8670\n",
      "Epoch 132/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8660\n",
      "Epoch 133/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8627\n",
      "Epoch 134/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8575\n",
      "Epoch 135/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8536\n",
      "Epoch 136/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8527\n",
      "Epoch 137/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.8488\n",
      "Epoch 138/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8454\n",
      "Epoch 139/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.8415\n",
      "Epoch 140/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8372\n",
      "Epoch 141/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.8349\n",
      "Epoch 142/500\n",
      "400/400 [==============================] - 0s 33us/sample - loss: 0.8304\n",
      "Epoch 143/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8258\n",
      "Epoch 144/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8229\n",
      "Epoch 145/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.8223\n",
      "Epoch 146/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8173\n",
      "Epoch 147/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8134\n",
      "Epoch 148/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8123\n",
      "Epoch 149/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8065\n",
      "Epoch 150/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8018\n",
      "Epoch 151/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8039\n",
      "Epoch 152/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8010\n",
      "Epoch 153/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7951\n",
      "Epoch 154/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7912\n",
      "Epoch 155/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7908\n",
      "Epoch 156/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.7865\n",
      "Epoch 157/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.7840\n",
      "Epoch 158/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.7798\n",
      "Epoch 159/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.7751\n",
      "Epoch 160/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7719\n",
      "Epoch 161/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7690\n",
      "Epoch 162/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7643\n",
      "Epoch 163/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7631\n",
      "Epoch 164/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.7592\n",
      "Epoch 165/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.7557\n",
      "Epoch 166/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7540\n",
      "Epoch 167/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.7498\n",
      "Epoch 168/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7504\n",
      "Epoch 169/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7455\n",
      "Epoch 170/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7435\n",
      "Epoch 171/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7415\n",
      "Epoch 172/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7373\n",
      "Epoch 173/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7378\n",
      "Epoch 174/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7333\n",
      "Epoch 175/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7320\n",
      "Epoch 176/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.7304\n",
      "Epoch 177/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.7272\n",
      "Epoch 178/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7264\n",
      "Epoch 179/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.7220\n",
      "Epoch 180/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.7199\n",
      "Epoch 181/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.7195\n",
      "Epoch 182/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7158\n",
      "Epoch 183/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7126\n",
      "Epoch 184/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7111\n",
      "Epoch 185/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.7096\n",
      "Epoch 186/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7063\n",
      "Epoch 187/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7078\n",
      "Epoch 188/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7012\n",
      "Epoch 189/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.6998\n",
      "Epoch 190/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7021\n",
      "Epoch 191/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6968\n",
      "Epoch 192/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6942\n",
      "Epoch 193/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6959\n",
      "Epoch 194/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6917\n",
      "Epoch 195/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.6895\n",
      "Epoch 196/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.6878\n",
      "Epoch 197/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6853\n",
      "Epoch 198/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6875\n",
      "Epoch 199/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6824\n",
      "Epoch 200/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6777\n",
      "Epoch 201/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6826\n",
      "Epoch 202/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6753\n",
      "Epoch 203/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6785\n",
      "Epoch 204/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6787\n",
      "Epoch 205/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6765\n",
      "Epoch 206/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6735\n",
      "Epoch 207/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6699\n",
      "Epoch 208/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6686\n",
      "Epoch 209/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6680\n",
      "Epoch 210/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.6656\n",
      "Epoch 211/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6671\n",
      "Epoch 212/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6618\n",
      "Epoch 213/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6598\n",
      "Epoch 214/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6602\n",
      "Epoch 215/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6605\n",
      "Epoch 216/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6557\n",
      "Epoch 217/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6557\n",
      "Epoch 218/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6551\n",
      "Epoch 219/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6501\n",
      "Epoch 220/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6476\n",
      "Epoch 221/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6507\n",
      "Epoch 222/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6495\n",
      "Epoch 223/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6481\n",
      "Epoch 224/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6444\n",
      "Epoch 225/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6431\n",
      "Epoch 226/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6433\n",
      "Epoch 227/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6415\n",
      "Epoch 228/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6358\n",
      "Epoch 229/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6367\n",
      "Epoch 230/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6380\n",
      "Epoch 231/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6390\n",
      "Epoch 232/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6321\n",
      "Epoch 233/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6318\n",
      "Epoch 234/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6310\n",
      "Epoch 235/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6327\n",
      "Epoch 236/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6289\n",
      "Epoch 237/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6293\n",
      "Epoch 238/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6268\n",
      "Epoch 239/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6271\n",
      "Epoch 240/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6231\n",
      "Epoch 241/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6198\n",
      "Epoch 242/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6255\n",
      "Epoch 243/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6224\n",
      "Epoch 244/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6200\n",
      "Epoch 245/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6199\n",
      "Epoch 246/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6197\n",
      "Epoch 247/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6170\n",
      "Epoch 248/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6158\n",
      "Epoch 249/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6146\n",
      "Epoch 250/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6109\n",
      "Epoch 251/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.6123\n",
      "Epoch 252/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.6070\n",
      "Epoch 253/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6094\n",
      "Epoch 254/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6100\n",
      "Epoch 255/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6076\n",
      "Epoch 256/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6099\n",
      "Epoch 257/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6045\n",
      "Epoch 258/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6055\n",
      "Epoch 259/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6073\n",
      "Epoch 260/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6044\n",
      "Epoch 261/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6038\n",
      "Epoch 262/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6033\n",
      "Epoch 263/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5984\n",
      "Epoch 264/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6019\n",
      "Epoch 265/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5979\n",
      "Epoch 266/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6000\n",
      "Epoch 267/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5980\n",
      "Epoch 268/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5969\n",
      "Epoch 269/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5980\n",
      "Epoch 270/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5884\n",
      "Epoch 271/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5929\n",
      "Epoch 272/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5923\n",
      "Epoch 273/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5915\n",
      "Epoch 274/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5918\n",
      "Epoch 275/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5887\n",
      "Epoch 276/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5905\n",
      "Epoch 277/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5895\n",
      "Epoch 278/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5862\n",
      "Epoch 279/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5849\n",
      "Epoch 280/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5876\n",
      "Epoch 281/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.5904\n",
      "Epoch 282/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5827\n",
      "Epoch 283/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5838\n",
      "Epoch 284/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5815\n",
      "Epoch 285/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5810\n",
      "Epoch 286/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5845\n",
      "Epoch 287/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5821\n",
      "Epoch 288/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5810\n",
      "Epoch 289/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5776\n",
      "Epoch 290/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5820\n",
      "Epoch 291/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5766\n",
      "Epoch 292/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5791\n",
      "Epoch 293/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5729\n",
      "Epoch 294/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5735\n",
      "Epoch 295/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5785\n",
      "Epoch 296/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5765\n",
      "Epoch 297/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.5711\n",
      "Epoch 298/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5761\n",
      "Epoch 299/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5719\n",
      "Epoch 300/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5713\n",
      "Epoch 301/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5682\n",
      "Epoch 302/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5685\n",
      "Epoch 303/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5707\n",
      "Epoch 304/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5693\n",
      "Epoch 305/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5655\n",
      "Epoch 306/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5728\n",
      "Epoch 307/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 0.5642\n",
      "Epoch 308/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5693\n",
      "Epoch 309/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5649\n",
      "Epoch 310/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 0.5631\n",
      "Epoch 311/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5624\n",
      "Epoch 312/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5622\n",
      "Epoch 313/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5644\n",
      "Epoch 314/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5602\n",
      "Epoch 315/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5630\n",
      "Epoch 316/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5649\n",
      "Epoch 317/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5593\n",
      "Epoch 318/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.5578\n",
      "Epoch 319/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5640\n",
      "Epoch 320/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5601\n",
      "Epoch 321/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5571\n",
      "Epoch 322/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5576\n",
      "Epoch 323/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.5571\n",
      "Epoch 324/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5548\n",
      "Epoch 325/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5561\n",
      "Epoch 326/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5552\n",
      "Epoch 327/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5590\n",
      "Epoch 328/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5548\n",
      "Epoch 329/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5485\n",
      "Epoch 330/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5518\n",
      "Epoch 331/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5521\n",
      "Epoch 332/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5584\n",
      "Epoch 333/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5528\n",
      "Epoch 334/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5549\n",
      "Epoch 335/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5487\n",
      "Epoch 336/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5481\n",
      "Epoch 337/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5515\n",
      "Epoch 338/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5469\n",
      "Epoch 339/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5502\n",
      "Epoch 340/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5472\n",
      "Epoch 341/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5473\n",
      "Epoch 342/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5456\n",
      "Epoch 343/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5372\n",
      "Epoch 344/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5496\n",
      "Epoch 345/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5441\n",
      "Epoch 346/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5397\n",
      "Epoch 347/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5484\n",
      "Epoch 348/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5438\n",
      "Epoch 349/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5405\n",
      "Epoch 350/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5431\n",
      "Epoch 351/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5445\n",
      "Epoch 352/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5434\n",
      "Epoch 353/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5391\n",
      "Epoch 354/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5422\n",
      "Epoch 355/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5395\n",
      "Epoch 356/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5410\n",
      "Epoch 357/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5363\n",
      "Epoch 358/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5415\n",
      "Epoch 359/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5348\n",
      "Epoch 360/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.5417\n",
      "Epoch 361/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5322\n",
      "Epoch 362/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5335\n",
      "Epoch 363/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5381\n",
      "Epoch 364/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5381\n",
      "Epoch 365/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5351\n",
      "Epoch 366/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5324\n",
      "Epoch 367/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5367\n",
      "Epoch 368/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5344\n",
      "Epoch 369/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5349\n",
      "Epoch 370/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5350\n",
      "Epoch 371/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5295\n",
      "Epoch 372/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5337\n",
      "Epoch 373/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5317\n",
      "Epoch 374/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5349\n",
      "Epoch 375/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5280\n",
      "Epoch 376/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5289\n",
      "Epoch 377/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5283\n",
      "Epoch 378/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5280\n",
      "Epoch 379/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5321\n",
      "Epoch 380/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5282\n",
      "Epoch 381/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5274\n",
      "Epoch 382/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5251\n",
      "Epoch 383/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5259\n",
      "Epoch 384/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5290\n",
      "Epoch 385/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5272\n",
      "Epoch 386/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5261\n",
      "Epoch 387/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5228\n",
      "Epoch 388/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5257\n",
      "Epoch 389/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5216\n",
      "Epoch 390/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5200\n",
      "Epoch 391/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5268\n",
      "Epoch 392/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5236\n",
      "Epoch 393/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5231\n",
      "Epoch 394/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5225\n",
      "Epoch 395/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5224\n",
      "Epoch 396/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5188\n",
      "Epoch 397/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5208\n",
      "Epoch 398/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5205\n",
      "Epoch 399/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5178\n",
      "Epoch 400/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5176\n",
      "Epoch 401/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5193\n",
      "Epoch 402/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5164\n",
      "Epoch 403/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5169\n",
      "Epoch 404/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5176\n",
      "Epoch 405/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5145\n",
      "Epoch 406/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5182\n",
      "Epoch 407/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5161\n",
      "Epoch 408/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5132\n",
      "Epoch 409/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5199\n",
      "Epoch 410/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5143\n",
      "Epoch 411/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5154\n",
      "Epoch 412/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.5118\n",
      "Epoch 413/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5219\n",
      "Epoch 414/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5101\n",
      "Epoch 415/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5124\n",
      "Epoch 416/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5102\n",
      "Epoch 417/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5120\n",
      "Epoch 418/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5103\n",
      "Epoch 419/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5106\n",
      "Epoch 420/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5099\n",
      "Epoch 421/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5094\n",
      "Epoch 422/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5090\n",
      "Epoch 423/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5132\n",
      "Epoch 424/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5038\n",
      "Epoch 425/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.5015\n",
      "Epoch 426/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5097\n",
      "Epoch 427/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5082\n",
      "Epoch 428/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5087\n",
      "Epoch 429/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5073\n",
      "Epoch 430/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5070\n",
      "Epoch 431/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5040\n",
      "Epoch 432/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5031\n",
      "Epoch 433/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5049\n",
      "Epoch 434/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5069\n",
      "Epoch 435/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5064\n",
      "Epoch 436/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.5030\n",
      "Epoch 437/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5035\n",
      "Epoch 438/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5029\n",
      "Epoch 439/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5023\n",
      "Epoch 440/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.4992\n",
      "Epoch 441/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5029\n",
      "Epoch 442/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5058\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5002\n",
      "Epoch 444/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4989\n",
      "Epoch 445/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.4993\n",
      "Epoch 446/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4960\n",
      "Epoch 447/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5004\n",
      "Epoch 448/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.4967\n",
      "Epoch 449/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4966\n",
      "Epoch 450/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.4941\n",
      "Epoch 451/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4950\n",
      "Epoch 452/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.4985\n",
      "Epoch 453/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4918\n",
      "Epoch 454/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.4979\n",
      "Epoch 455/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4913\n",
      "Epoch 456/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4995\n",
      "Epoch 457/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4890\n",
      "Epoch 458/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.4910\n",
      "Epoch 459/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.4930\n",
      "Epoch 460/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4926\n",
      "Epoch 461/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.4895\n",
      "Epoch 462/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.4915\n",
      "Epoch 463/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.4928\n",
      "Epoch 464/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.4853\n",
      "Epoch 465/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.4868\n",
      "Epoch 466/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.4922\n",
      "Epoch 467/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4876\n",
      "Epoch 468/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.4916\n",
      "Epoch 469/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4872\n",
      "Epoch 470/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4865\n",
      "Epoch 471/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4870\n",
      "Epoch 472/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.4832\n",
      "Epoch 473/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4883\n",
      "Epoch 474/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.4854\n",
      "Epoch 475/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.4861\n",
      "Epoch 476/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4893\n",
      "Epoch 477/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4832\n",
      "Epoch 478/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4839\n",
      "Epoch 479/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.4854\n",
      "Epoch 480/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.4840\n",
      "Epoch 481/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.4857\n",
      "Epoch 482/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4824\n",
      "Epoch 483/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4802\n",
      "Epoch 484/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.4806\n",
      "Epoch 485/500\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.4812\n",
      "Epoch 486/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.4828\n",
      "Epoch 487/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.4830\n",
      "Epoch 488/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.4823\n",
      "Epoch 489/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.4783\n",
      "Epoch 490/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.4814\n",
      "Epoch 491/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.4733\n",
      "Epoch 492/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.4837\n",
      "Epoch 493/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.4816\n",
      "Epoch 494/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.4813\n",
      "Epoch 495/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.4816\n",
      "Epoch 496/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.4735\n",
      "Epoch 497/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.4786\n",
      "Epoch 498/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.4761\n",
      "Epoch 499/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.4821\n",
      "Epoch 500/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.4753\n",
      "Train on 400 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 316us/sample - loss: 26.3694\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 13.5438\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 13.3421\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 13.1454\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 12.9504\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 12.7566\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 12.5657\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 12.3768\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 12.1913\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 12.0093\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 11.8308\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 11.6526\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 11.4747\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 11.2995\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 11.1241\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 10.9482\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 10.7731\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 10.5970\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 10.4225\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 10.2500\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 10.0764\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 9.9037\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 9.7309\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 9.5584\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 9.3872\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 9.2141\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 9.0413\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 8.8685\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 8.6961\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 8.5250\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 8.3534\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 8.1830\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 8.0133\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 7.8436\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 7.6739\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 7.5050\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 7.3361\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 7.1682\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 6.9997\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 6.8315\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 6.6629\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 6.4951\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 6.3281\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 6.1608\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 5.9942\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 5.8286\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 5.6643\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 5.4980\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 5.3317\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 5.1660\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 5.0000\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 4.8350\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 4.6709\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 4.5077\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 4.3460\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 4.1845\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 4.0246\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 3.8632\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 3.7042\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 3.5452\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 3.3870\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 3.2314\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 3.0758\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 2.9223\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 2.7694\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 2.6184\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 2.4686\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 2.3203\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 2.1743\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 2.0312\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.8887\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 1.7504\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.6159\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.4855\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.3578\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.2341\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 1.1282\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0891\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0770\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0705\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0633\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0574\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0508\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0479\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 70us/sample - loss: 1.0454\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0424\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 35us/sample - loss: 1.0412\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 1.0389\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0377\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0350\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0346\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0327\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 1.0318\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0289\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0277\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 1.0277\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0258\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0242\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0223\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0205\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 1.0192\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 32us/sample - loss: 1.0175\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 1.0148\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 1.0148\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0125\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0108\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0086\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0081\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0053\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 1.0022\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0015\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0005\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.9976\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.9951\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9931\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.9916\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9906\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9866\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9851\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.9844\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.9816\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9788\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9786\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9743\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9715\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9699\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9686\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9647\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9617\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9626\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9581\n",
      "Epoch 132/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9557\n",
      "Epoch 133/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.9539\n",
      "Epoch 134/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9531\n",
      "Epoch 135/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9502\n",
      "Epoch 136/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9466\n",
      "Epoch 137/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9429\n",
      "Epoch 138/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9447\n",
      "Epoch 139/500\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.9406\n",
      "Epoch 140/500\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.9373\n",
      "Epoch 141/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.9367\n",
      "Epoch 142/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9335\n",
      "Epoch 143/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9298\n",
      "Epoch 144/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.9285\n",
      "Epoch 145/500\n",
      "400/400 [==============================] - 0s 37us/sample - loss: 0.9265\n",
      "Epoch 146/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9205\n",
      "Epoch 147/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9233\n",
      "Epoch 148/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.9163\n",
      "Epoch 149/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9153\n",
      "Epoch 150/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9130\n",
      "Epoch 151/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9091\n",
      "Epoch 152/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9052\n",
      "Epoch 153/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9051\n",
      "Epoch 154/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9007\n",
      "Epoch 155/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8964\n",
      "Epoch 156/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8963\n",
      "Epoch 157/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.8944\n",
      "Epoch 158/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8892\n",
      "Epoch 159/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8867\n",
      "Epoch 160/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8849\n",
      "Epoch 161/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8800\n",
      "Epoch 162/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8791\n",
      "Epoch 163/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8753\n",
      "Epoch 164/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8707\n",
      "Epoch 165/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8678\n",
      "Epoch 166/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.8652\n",
      "Epoch 167/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.8611\n",
      "Epoch 168/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.8602\n",
      "Epoch 169/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8561\n",
      "Epoch 170/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.8543\n",
      "Epoch 171/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.8518\n",
      "Epoch 172/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8480\n",
      "Epoch 173/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8475\n",
      "Epoch 174/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8443\n",
      "Epoch 175/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8383\n",
      "Epoch 176/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8381\n",
      "Epoch 177/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8352\n",
      "Epoch 178/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.8314\n",
      "Epoch 179/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.8308\n",
      "Epoch 180/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8253\n",
      "Epoch 181/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8251\n",
      "Epoch 182/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8214\n",
      "Epoch 183/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8199\n",
      "Epoch 184/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8190\n",
      "Epoch 185/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8125\n",
      "Epoch 186/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8173\n",
      "Epoch 187/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8085\n",
      "Epoch 188/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8079\n",
      "Epoch 189/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8039\n",
      "Epoch 190/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8019\n",
      "Epoch 191/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8002\n",
      "Epoch 192/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7955\n",
      "Epoch 193/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7953\n",
      "Epoch 194/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7927\n",
      "Epoch 195/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.7870\n",
      "Epoch 196/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7849\n",
      "Epoch 197/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7830\n",
      "Epoch 198/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7813\n",
      "Epoch 199/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7768\n",
      "Epoch 200/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7799\n",
      "Epoch 201/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7732\n",
      "Epoch 202/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.7724\n",
      "Epoch 203/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7678\n",
      "Epoch 204/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7686\n",
      "Epoch 205/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7660\n",
      "Epoch 206/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.7633\n",
      "Epoch 207/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7622\n",
      "Epoch 208/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7607\n",
      "Epoch 209/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7570\n",
      "Epoch 210/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7546\n",
      "Epoch 211/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7528\n",
      "Epoch 212/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.7508\n",
      "Epoch 213/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.7468\n",
      "Epoch 214/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7450\n",
      "Epoch 215/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7413\n",
      "Epoch 216/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.7430\n",
      "Epoch 217/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7397\n",
      "Epoch 218/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7390\n",
      "Epoch 219/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.7383\n",
      "Epoch 220/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7326\n",
      "Epoch 221/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7299\n",
      "Epoch 222/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7316\n",
      "Epoch 223/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7271\n",
      "Epoch 224/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.7224\n",
      "Epoch 225/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7258\n",
      "Epoch 226/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7216\n",
      "Epoch 227/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7214\n",
      "Epoch 228/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.7231\n",
      "Epoch 229/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7163\n",
      "Epoch 230/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7143\n",
      "Epoch 231/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.7150\n",
      "Epoch 232/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7139\n",
      "Epoch 233/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7118\n",
      "Epoch 234/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7091\n",
      "Epoch 235/500\n",
      "400/400 [==============================] - 0s 72us/sample - loss: 0.7084\n",
      "Epoch 236/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7081\n",
      "Epoch 237/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.7026\n",
      "Epoch 238/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.7033\n",
      "Epoch 239/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7045\n",
      "Epoch 240/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6971\n",
      "Epoch 241/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7019\n",
      "Epoch 242/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6956\n",
      "Epoch 243/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6950\n",
      "Epoch 244/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6947\n",
      "Epoch 245/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.6939\n",
      "Epoch 246/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6914\n",
      "Epoch 247/500\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.6863\n",
      "Epoch 248/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6898\n",
      "Epoch 249/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6944\n",
      "Epoch 250/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.6840\n",
      "Epoch 251/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6831\n",
      "Epoch 252/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6839\n",
      "Epoch 253/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6801\n",
      "Epoch 254/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6777\n",
      "Epoch 255/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6770\n",
      "Epoch 256/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6767\n",
      "Epoch 257/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6764\n",
      "Epoch 258/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.6728\n",
      "Epoch 259/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6697\n",
      "Epoch 260/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.6704\n",
      "Epoch 261/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.6669\n",
      "Epoch 262/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6708\n",
      "Epoch 263/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6651\n",
      "Epoch 264/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6696\n",
      "Epoch 265/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6651\n",
      "Epoch 266/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.6620\n",
      "Epoch 267/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.6619\n",
      "Epoch 268/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6597\n",
      "Epoch 269/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6589\n",
      "Epoch 270/500\n",
      "400/400 [==============================] - 0s 29us/sample - loss: 0.6551\n",
      "Epoch 271/500\n",
      "400/400 [==============================] - 0s 35us/sample - loss: 0.6562\n",
      "Epoch 272/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.6565\n",
      "Epoch 273/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.6502\n",
      "Epoch 274/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6524\n",
      "Epoch 275/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6485\n",
      "Epoch 276/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6509\n",
      "Epoch 277/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6507\n",
      "Epoch 278/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6469\n",
      "Epoch 279/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.6449\n",
      "Epoch 280/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6445\n",
      "Epoch 281/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.6437\n",
      "Epoch 282/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.6436\n",
      "Epoch 283/500\n",
      "400/400 [==============================] - 0s 40us/sample - loss: 0.6408\n",
      "Epoch 284/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.6444\n",
      "Epoch 285/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.6377\n",
      "Epoch 286/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.6387\n",
      "Epoch 287/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 0.6348\n",
      "Epoch 288/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.6368\n",
      "Epoch 289/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6360\n",
      "Epoch 290/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.6361\n",
      "Epoch 291/500\n",
      "400/400 [==============================] - 0s 40us/sample - loss: 0.6332\n",
      "Epoch 292/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.6311\n",
      "Epoch 293/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6363\n",
      "Epoch 294/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.6277\n",
      "Epoch 295/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6274\n",
      "Epoch 296/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.6225\n",
      "Epoch 297/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6272\n",
      "Epoch 298/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.6295\n",
      "Epoch 299/500\n",
      "400/400 [==============================] - 0s 40us/sample - loss: 0.6237\n",
      "Epoch 300/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.6283\n",
      "Epoch 301/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.6219\n",
      "Epoch 302/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6222\n",
      "Epoch 303/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6236\n",
      "Epoch 304/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 0.6191\n",
      "Epoch 305/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6160\n",
      "Epoch 306/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.6212\n",
      "Epoch 307/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.6159\n",
      "Epoch 308/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.6218\n",
      "Epoch 309/500\n",
      "400/400 [==============================] - 0s 34us/sample - loss: 0.6157\n",
      "Epoch 310/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.6097\n",
      "Epoch 311/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.6137\n",
      "Epoch 312/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.6139\n",
      "Epoch 313/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 0.6098\n",
      "Epoch 314/500\n",
      "400/400 [==============================] - 0s 36us/sample - loss: 0.6075\n",
      "Epoch 315/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.6084\n",
      "Epoch 316/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.6104\n",
      "Epoch 317/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6057\n",
      "Epoch 318/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.6014\n",
      "Epoch 319/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6112\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 53us/sample - loss: 0.6045\n",
      "Epoch 321/500\n",
      "400/400 [==============================] - 0s 36us/sample - loss: 0.6012\n",
      "Epoch 322/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6008\n",
      "Epoch 323/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.6002\n",
      "Epoch 324/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6059\n",
      "Epoch 325/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6018\n",
      "Epoch 326/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6024\n",
      "Epoch 327/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5972\n",
      "Epoch 328/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5949\n",
      "Epoch 329/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6027\n",
      "Epoch 330/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5957\n",
      "Epoch 331/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5922\n",
      "Epoch 332/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5977\n",
      "Epoch 333/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5886\n",
      "Epoch 334/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5948\n",
      "Epoch 335/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.5922\n",
      "Epoch 336/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5918\n",
      "Epoch 337/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5961\n",
      "Epoch 338/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5881\n",
      "Epoch 339/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5968\n",
      "Epoch 340/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5893\n",
      "Epoch 341/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5881\n",
      "Epoch 342/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5869\n",
      "Epoch 343/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5893\n",
      "Epoch 344/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.5863\n",
      "Epoch 345/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.5826\n",
      "Epoch 346/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.5873\n",
      "Epoch 347/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5803\n",
      "Epoch 348/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5877\n",
      "Epoch 349/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5797\n",
      "Epoch 350/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5818\n",
      "Epoch 351/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5805\n",
      "Epoch 352/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5856\n",
      "Epoch 353/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5796\n",
      "Epoch 354/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5760\n",
      "Epoch 355/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5825\n",
      "Epoch 356/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5781\n",
      "Epoch 357/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5756\n",
      "Epoch 358/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5763\n",
      "Epoch 359/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5791\n",
      "Epoch 360/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5708\n",
      "Epoch 361/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5774\n",
      "Epoch 362/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5682\n",
      "Epoch 363/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.5772\n",
      "Epoch 364/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5746\n",
      "Epoch 365/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5726\n",
      "Epoch 366/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5758\n",
      "Epoch 367/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5726\n",
      "Epoch 368/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5745\n",
      "Epoch 369/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5689\n",
      "Epoch 370/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.5643\n",
      "Epoch 371/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.5680\n",
      "Epoch 372/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5689\n",
      "Epoch 373/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5660\n",
      "Epoch 374/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5720\n",
      "Epoch 375/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5675\n",
      "Epoch 376/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5673\n",
      "Epoch 377/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5627\n",
      "Epoch 378/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5685\n",
      "Epoch 379/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5637\n",
      "Epoch 380/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5645\n",
      "Epoch 381/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5626\n",
      "Epoch 382/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5640\n",
      "Epoch 383/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5599\n",
      "Epoch 384/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5614\n",
      "Epoch 385/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5564\n",
      "Epoch 386/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5590\n",
      "Epoch 387/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5664\n",
      "Epoch 388/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5588\n",
      "Epoch 389/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5548\n",
      "Epoch 390/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.5604\n",
      "Epoch 391/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5597\n",
      "Epoch 392/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5536\n",
      "Epoch 393/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5524\n",
      "Epoch 394/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5551\n",
      "Epoch 395/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5540\n",
      "Epoch 396/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5544\n",
      "Epoch 397/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5556\n",
      "Epoch 398/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.5514\n",
      "Epoch 399/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5497\n",
      "Epoch 400/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.5499\n",
      "Epoch 401/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5527\n",
      "Epoch 402/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.5571\n",
      "Epoch 403/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5482\n",
      "Epoch 404/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.5484\n",
      "Epoch 405/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5481\n",
      "Epoch 406/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5494\n",
      "Epoch 407/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5484\n",
      "Epoch 408/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5470\n",
      "Epoch 409/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5520\n",
      "Epoch 410/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5460\n",
      "Epoch 411/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5445\n",
      "Epoch 412/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5410\n",
      "Epoch 413/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5458\n",
      "Epoch 414/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.5430\n",
      "Epoch 415/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5423\n",
      "Epoch 416/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5434\n",
      "Epoch 417/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5429\n",
      "Epoch 418/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5476\n",
      "Epoch 419/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5456\n",
      "Epoch 420/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5400\n",
      "Epoch 421/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5409\n",
      "Epoch 422/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5461\n",
      "Epoch 423/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5396\n",
      "Epoch 424/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5408\n",
      "Epoch 425/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5363\n",
      "Epoch 426/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.5382\n",
      "Epoch 427/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.5399\n",
      "Epoch 428/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5362\n",
      "Epoch 429/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5365\n",
      "Epoch 430/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5341\n",
      "Epoch 431/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5379\n",
      "Epoch 432/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.5344\n",
      "Epoch 433/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5352\n",
      "Epoch 434/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5349\n",
      "Epoch 435/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.5340\n",
      "Epoch 436/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5347\n",
      "Epoch 437/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5379\n",
      "Epoch 438/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5311\n",
      "Epoch 439/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5353\n",
      "Epoch 440/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5302\n",
      "Epoch 441/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5354\n",
      "Epoch 442/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5342\n",
      "Epoch 443/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5227\n",
      "Epoch 444/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5327\n",
      "Epoch 445/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5305\n",
      "Epoch 446/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.5278\n",
      "Epoch 447/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5353\n",
      "Epoch 448/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5271\n",
      "Epoch 449/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5301\n",
      "Epoch 450/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5252\n",
      "Epoch 451/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5271\n",
      "Epoch 452/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5307\n",
      "Epoch 453/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.5280\n",
      "Epoch 454/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5241\n",
      "Epoch 455/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5236\n",
      "Epoch 456/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.5293\n",
      "Epoch 457/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5280\n",
      "Epoch 458/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5254\n",
      "Epoch 459/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5193\n",
      "Epoch 460/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 0.5341\n",
      "Epoch 461/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.5239\n",
      "Epoch 462/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.5209\n",
      "Epoch 463/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5220\n",
      "Epoch 464/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5277\n",
      "Epoch 465/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5251\n",
      "Epoch 466/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5178\n",
      "Epoch 467/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.5209\n",
      "Epoch 468/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5202\n",
      "Epoch 469/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5211\n",
      "Epoch 470/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5204\n",
      "Epoch 471/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5156\n",
      "Epoch 472/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5248\n",
      "Epoch 473/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.5245\n",
      "Epoch 474/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5208\n",
      "Epoch 475/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5164\n",
      "Epoch 476/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5182\n",
      "Epoch 477/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.5149\n",
      "Epoch 478/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5186\n",
      "Epoch 479/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5203\n",
      "Epoch 480/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.5156\n",
      "Epoch 481/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.5192\n",
      "Epoch 482/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.5177\n",
      "Epoch 483/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5140\n",
      "Epoch 484/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5153\n",
      "Epoch 485/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5172\n",
      "Epoch 486/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.5150\n",
      "Epoch 487/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.5089\n",
      "Epoch 488/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5185\n",
      "Epoch 489/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5153\n",
      "Epoch 490/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.5103\n",
      "Epoch 491/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.5090\n",
      "Epoch 492/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5178\n",
      "Epoch 493/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5134\n",
      "Epoch 494/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5091\n",
      "Epoch 495/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.5144\n",
      "Epoch 496/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.5104\n",
      "Epoch 497/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.5130\n",
      "Epoch 498/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.5104\n",
      "Epoch 499/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.5055\n",
      "Epoch 500/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.5130\n",
      "Train on 400 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 340us/sample - loss: 39.1904\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 20.0479\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 19.7533\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 19.4739\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 19.1979\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 18.9222\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 18.6468\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 58us/sample - loss: 18.3731\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 18.1016\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 17.8315\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 17.5621\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 17.2946\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 17.0280\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 16.7617\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 16.4967\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 16.2318\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 15.9684\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 15.7069\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 15.4460\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 15.1844\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 14.9228\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 14.6610\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 14.3999\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 14.1400\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 13.8796\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 13.6210\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 13.3623\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 13.1045\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 12.8469\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 12.5889\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 12.3316\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 12.0737\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 11.8174\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 11.5603\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 11.3066\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 11.0509\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 10.7962\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 10.5413\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 10.2861\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 10.0308\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 9.7757\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 9.5212\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 9.2672\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 9.0127\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 8.7596\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 8.5073\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 8.2555\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 8.0039\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 7.7525\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 7.5003\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 7.2494\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 6.9992\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 6.7479\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 6.4981\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 6.2479\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 5.9990\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 5.7499\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 5.5009\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 5.2524\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 5.0040\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 4.7567\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 4.5109\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 4.2648\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 4.0195\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 3.7761\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 3.5344\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 3.2957\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 3.0584\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 2.8231\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 2.5910\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 2.3619\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 2.1357\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.9128\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.6946\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.4802\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 1.2701\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0875\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0312\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0260\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0259\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0258\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0261\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0252\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0252\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0252\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0251\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0252\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0261\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0246\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0250\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0249\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0252\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0251\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0259\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0246\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0253\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0247\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0261\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0247\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0254\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0254\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 1.0251\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 36us/sample - loss: 1.0257\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0254\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0248\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0252\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0258\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0245\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0271\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0246\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0252\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 1.0247\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0260\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0247\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0245\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0243\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0254\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0256\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0244\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0250\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0247\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0248\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0251\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0245\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0254\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0249\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0247\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0246\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0241\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0247\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 1.0253\n",
      "Epoch 132/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0253\n",
      "Epoch 133/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0240\n",
      "Epoch 134/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0247\n",
      "Epoch 135/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0244\n",
      "Epoch 136/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0253\n",
      "Epoch 137/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0249\n",
      "Epoch 138/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 1.0247\n",
      "Epoch 139/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0249\n",
      "Epoch 140/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0253\n",
      "Epoch 141/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0246\n",
      "Epoch 142/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0243\n",
      "Epoch 143/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0246\n",
      "Epoch 144/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0243\n",
      "Epoch 145/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0251\n",
      "Epoch 146/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0243\n",
      "Epoch 147/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0250\n",
      "Epoch 148/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0246\n",
      "Epoch 149/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0248\n",
      "Epoch 150/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0245\n",
      "Epoch 151/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0254\n",
      "Epoch 152/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0259\n",
      "Epoch 153/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 1.0244\n",
      "Epoch 154/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0237\n",
      "Epoch 155/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0246\n",
      "Epoch 156/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0243\n",
      "Epoch 157/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0246\n",
      "Epoch 158/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0249\n",
      "Epoch 159/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0242\n",
      "Epoch 160/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0249\n",
      "Epoch 161/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0238\n",
      "Epoch 162/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0243\n",
      "Epoch 163/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0255\n",
      "Epoch 164/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0238\n",
      "Epoch 165/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0245\n",
      "Epoch 166/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0247\n",
      "Epoch 167/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0254\n",
      "Epoch 168/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0238\n",
      "Epoch 169/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0244\n",
      "Epoch 170/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0239\n",
      "Epoch 171/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0250\n",
      "Epoch 172/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0239\n",
      "Epoch 173/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0254\n",
      "Epoch 174/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0238\n",
      "Epoch 175/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0242\n",
      "Epoch 176/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0243\n",
      "Epoch 177/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0238\n",
      "Epoch 178/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0237\n",
      "Epoch 179/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0244\n",
      "Epoch 180/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0244\n",
      "Epoch 181/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0243\n",
      "Epoch 182/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0248\n",
      "Epoch 183/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0245\n",
      "Epoch 184/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0234\n",
      "Epoch 185/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0247\n",
      "Epoch 186/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0255\n",
      "Epoch 187/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0245\n",
      "Epoch 188/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0242\n",
      "Epoch 189/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0243\n",
      "Epoch 190/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0243\n",
      "Epoch 191/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0236\n",
      "Epoch 192/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0241\n",
      "Epoch 193/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0249\n",
      "Epoch 194/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0234\n",
      "Epoch 195/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0248\n",
      "Epoch 196/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0249\n",
      "Epoch 197/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0233\n",
      "Epoch 198/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0245\n",
      "Epoch 199/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0236\n",
      "Epoch 200/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 1.0217\n",
      "Epoch 201/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0231\n",
      "Epoch 202/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0231\n",
      "Epoch 203/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0241\n",
      "Epoch 204/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0220\n",
      "Epoch 205/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0210\n",
      "Epoch 206/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0219\n",
      "Epoch 207/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 1.0227\n",
      "Epoch 208/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0202\n",
      "Epoch 209/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0220\n",
      "Epoch 210/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0198\n",
      "Epoch 211/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0200\n",
      "Epoch 212/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0194\n",
      "Epoch 213/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0199\n",
      "Epoch 214/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0175\n",
      "Epoch 215/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0187\n",
      "Epoch 216/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0159\n",
      "Epoch 217/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0170\n",
      "Epoch 218/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0168\n",
      "Epoch 219/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0140\n",
      "Epoch 220/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0141\n",
      "Epoch 221/500\n",
      "400/400 [==============================] - 0s 29us/sample - loss: 1.0119\n",
      "Epoch 222/500\n",
      "400/400 [==============================] - 0s 29us/sample - loss: 1.0118\n",
      "Epoch 223/500\n",
      "400/400 [==============================] - 0s 36us/sample - loss: 1.0100\n",
      "Epoch 224/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0102\n",
      "Epoch 225/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0092\n",
      "Epoch 226/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0078\n",
      "Epoch 227/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0055\n",
      "Epoch 228/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0058\n",
      "Epoch 229/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0052\n",
      "Epoch 230/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0018\n",
      "Epoch 231/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0016\n",
      "Epoch 232/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9998\n",
      "Epoch 233/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9990\n",
      "Epoch 234/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0020\n",
      "Epoch 235/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9966\n",
      "Epoch 236/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9971\n",
      "Epoch 237/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.9947\n",
      "Epoch 238/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9950\n",
      "Epoch 239/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9941\n",
      "Epoch 240/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9914\n",
      "Epoch 241/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9919\n",
      "Epoch 242/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9909\n",
      "Epoch 243/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.9891\n",
      "Epoch 244/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9846\n",
      "Epoch 245/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9856\n",
      "Epoch 246/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9888\n",
      "Epoch 247/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9864\n",
      "Epoch 248/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9832\n",
      "Epoch 249/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9827\n",
      "Epoch 250/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9812\n",
      "Epoch 251/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9798\n",
      "Epoch 252/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9823\n",
      "Epoch 253/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.9788\n",
      "Epoch 254/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9783\n",
      "Epoch 255/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9741\n",
      "Epoch 256/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9785\n",
      "Epoch 257/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.9745\n",
      "Epoch 258/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9724\n",
      "Epoch 259/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9737\n",
      "Epoch 260/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9718\n",
      "Epoch 261/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.9717\n",
      "Epoch 262/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9693\n",
      "Epoch 263/500\n",
      "400/400 [==============================] - 0s 74us/sample - loss: 0.9680\n",
      "Epoch 264/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9654\n",
      "Epoch 265/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9650\n",
      "Epoch 266/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9653\n",
      "Epoch 267/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9635\n",
      "Epoch 268/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9617\n",
      "Epoch 269/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9580\n",
      "Epoch 270/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9603\n",
      "Epoch 271/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.9623\n",
      "Epoch 272/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9557\n",
      "Epoch 273/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9555\n",
      "Epoch 274/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9566\n",
      "Epoch 275/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9557\n",
      "Epoch 276/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9564\n",
      "Epoch 277/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9510\n",
      "Epoch 278/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9490\n",
      "Epoch 279/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9520\n",
      "Epoch 280/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9510\n",
      "Epoch 281/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9443\n",
      "Epoch 282/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9402\n",
      "Epoch 283/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9502\n",
      "Epoch 284/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9452\n",
      "Epoch 285/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9423\n",
      "Epoch 286/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.9429\n",
      "Epoch 287/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9434\n",
      "Epoch 288/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.9399\n",
      "Epoch 289/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9401\n",
      "Epoch 290/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9350\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 50us/sample - loss: 0.9345\n",
      "Epoch 292/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9374\n",
      "Epoch 293/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9309\n",
      "Epoch 294/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.9314\n",
      "Epoch 295/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9328\n",
      "Epoch 296/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.9308\n",
      "Epoch 297/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.9319\n",
      "Epoch 298/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9238\n",
      "Epoch 299/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.9249\n",
      "Epoch 300/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9229\n",
      "Epoch 301/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9223\n",
      "Epoch 302/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9192\n",
      "Epoch 303/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9217\n",
      "Epoch 304/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9171\n",
      "Epoch 305/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9174\n",
      "Epoch 306/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9150\n",
      "Epoch 307/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9145\n",
      "Epoch 308/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9093\n",
      "Epoch 309/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9105\n",
      "Epoch 310/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9128\n",
      "Epoch 311/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9061\n",
      "Epoch 312/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9019\n",
      "Epoch 313/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9075\n",
      "Epoch 314/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.9030\n",
      "Epoch 315/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8997\n",
      "Epoch 316/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.8995\n",
      "Epoch 317/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8955\n",
      "Epoch 318/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.8959\n",
      "Epoch 319/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8924\n",
      "Epoch 320/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8944\n",
      "Epoch 321/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8895\n",
      "Epoch 322/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8917\n",
      "Epoch 323/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8868\n",
      "Epoch 324/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.8854\n",
      "Epoch 325/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8853\n",
      "Epoch 326/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8822\n",
      "Epoch 327/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8800\n",
      "Epoch 328/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8778\n",
      "Epoch 329/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8761\n",
      "Epoch 330/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8723\n",
      "Epoch 331/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8750\n",
      "Epoch 332/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8714\n",
      "Epoch 333/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8663\n",
      "Epoch 334/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.8654\n",
      "Epoch 335/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8637\n",
      "Epoch 336/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8606\n",
      "Epoch 337/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8676\n",
      "Epoch 338/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.8588\n",
      "Epoch 339/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8599\n",
      "Epoch 340/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8557\n",
      "Epoch 341/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8531\n",
      "Epoch 342/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8563\n",
      "Epoch 343/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8512\n",
      "Epoch 344/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8472\n",
      "Epoch 345/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8526\n",
      "Epoch 346/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8410\n",
      "Epoch 347/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8434\n",
      "Epoch 348/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8428\n",
      "Epoch 349/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8406\n",
      "Epoch 350/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8356\n",
      "Epoch 351/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8381\n",
      "Epoch 352/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8387\n",
      "Epoch 353/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8342\n",
      "Epoch 354/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8279\n",
      "Epoch 355/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8369\n",
      "Epoch 356/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8277\n",
      "Epoch 357/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8319\n",
      "Epoch 358/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.8220\n",
      "Epoch 359/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8247\n",
      "Epoch 360/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8174\n",
      "Epoch 361/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8243\n",
      "Epoch 362/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8234\n",
      "Epoch 363/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8166\n",
      "Epoch 364/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8120\n",
      "Epoch 365/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8103\n",
      "Epoch 366/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8119\n",
      "Epoch 367/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.8140\n",
      "Epoch 368/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.8072\n",
      "Epoch 369/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 0.8107\n",
      "Epoch 370/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8029\n",
      "Epoch 371/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8009\n",
      "Epoch 372/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8069\n",
      "Epoch 373/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7984\n",
      "Epoch 374/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.7967\n",
      "Epoch 375/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8022\n",
      "Epoch 376/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.7882\n",
      "Epoch 377/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7919\n",
      "Epoch 378/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7904\n",
      "Epoch 379/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7904\n",
      "Epoch 380/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7881\n",
      "Epoch 381/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.7883\n",
      "Epoch 382/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7862\n",
      "Epoch 383/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7807\n",
      "Epoch 384/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7730\n",
      "Epoch 385/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7797\n",
      "Epoch 386/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7784\n",
      "Epoch 387/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7789\n",
      "Epoch 388/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.7707\n",
      "Epoch 389/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.7726\n",
      "Epoch 390/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7767\n",
      "Epoch 391/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7692\n",
      "Epoch 392/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7691\n",
      "Epoch 393/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7644\n",
      "Epoch 394/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7679\n",
      "Epoch 395/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7670\n",
      "Epoch 396/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7583\n",
      "Epoch 397/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7639\n",
      "Epoch 398/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7589\n",
      "Epoch 399/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7571\n",
      "Epoch 400/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7532\n",
      "Epoch 401/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7502\n",
      "Epoch 402/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7510\n",
      "Epoch 403/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.7501\n",
      "Epoch 404/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7502\n",
      "Epoch 405/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7536\n",
      "Epoch 406/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7431\n",
      "Epoch 407/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.7417\n",
      "Epoch 408/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.7424\n",
      "Epoch 409/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.7465\n",
      "Epoch 410/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7374\n",
      "Epoch 411/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7396\n",
      "Epoch 412/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7352\n",
      "Epoch 413/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7380\n",
      "Epoch 414/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7326\n",
      "Epoch 415/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7287\n",
      "Epoch 416/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.7321\n",
      "Epoch 417/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7331\n",
      "Epoch 418/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7270\n",
      "Epoch 419/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7259\n",
      "Epoch 420/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7258\n",
      "Epoch 421/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7175\n",
      "Epoch 422/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.7205\n",
      "Epoch 423/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7171\n",
      "Epoch 424/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.7171\n",
      "Epoch 425/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7149\n",
      "Epoch 426/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7139\n",
      "Epoch 427/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7132\n",
      "Epoch 428/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.7158\n",
      "Epoch 429/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.7102\n",
      "Epoch 430/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7105\n",
      "Epoch 431/500\n",
      "400/400 [==============================] - 0s 71us/sample - loss: 0.7086\n",
      "Epoch 432/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7068\n",
      "Epoch 433/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.7108\n",
      "Epoch 434/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6996\n",
      "Epoch 435/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7053\n",
      "Epoch 436/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6997\n",
      "Epoch 437/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6978\n",
      "Epoch 438/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.7002\n",
      "Epoch 439/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6946\n",
      "Epoch 440/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.7010\n",
      "Epoch 441/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6992\n",
      "Epoch 442/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6888\n",
      "Epoch 443/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6819\n",
      "Epoch 444/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6959\n",
      "Epoch 445/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6866\n",
      "Epoch 446/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6827\n",
      "Epoch 447/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6844\n",
      "Epoch 448/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6878\n",
      "Epoch 449/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6854\n",
      "Epoch 450/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6853\n",
      "Epoch 451/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6809\n",
      "Epoch 452/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6742\n",
      "Epoch 453/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6795\n",
      "Epoch 454/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6743\n",
      "Epoch 455/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6694\n",
      "Epoch 456/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6794\n",
      "Epoch 457/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6777\n",
      "Epoch 458/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6724\n",
      "Epoch 459/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6771\n",
      "Epoch 460/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6720\n",
      "Epoch 461/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6726\n",
      "Epoch 462/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6753\n",
      "Epoch 463/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.6652\n",
      "Epoch 464/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6722\n",
      "Epoch 465/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6671\n",
      "Epoch 466/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6647\n",
      "Epoch 467/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.6615\n",
      "Epoch 468/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.6685\n",
      "Epoch 469/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6580\n",
      "Epoch 470/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.6647\n",
      "Epoch 471/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.6583\n",
      "Epoch 472/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6621\n",
      "Epoch 473/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6617\n",
      "Epoch 474/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6593\n",
      "Epoch 475/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6559\n",
      "Epoch 476/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6566\n",
      "Epoch 477/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.6512\n",
      "Epoch 478/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6528\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6546\n",
      "Epoch 480/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6500\n",
      "Epoch 481/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.6539\n",
      "Epoch 482/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.6423\n",
      "Epoch 483/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6458\n",
      "Epoch 484/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6542\n",
      "Epoch 485/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 0.6468\n",
      "Epoch 486/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.6445\n",
      "Epoch 487/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6356\n",
      "Epoch 488/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6479\n",
      "Epoch 489/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6505\n",
      "Epoch 490/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.6387\n",
      "Epoch 491/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.6497\n",
      "Epoch 492/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6425\n",
      "Epoch 493/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.6361\n",
      "Epoch 494/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 0.6381\n",
      "Epoch 495/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.6419\n",
      "Epoch 496/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.6410\n",
      "Epoch 497/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.6367\n",
      "Epoch 498/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.6333\n",
      "Epoch 499/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.6325\n",
      "Epoch 500/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.6381\n",
      "Train on 400 samples\n",
      "Epoch 1/500\n",
      "400/400 [==============================] - 0s 355us/sample - loss: 51.6855\n",
      "Epoch 2/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 26.2954\n",
      "Epoch 3/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 25.9333\n",
      "Epoch 4/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 25.5819\n",
      "Epoch 5/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 25.2318\n",
      "Epoch 6/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 24.8824\n",
      "Epoch 7/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 24.5330\n",
      "Epoch 8/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 24.1839\n",
      "Epoch 9/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 23.8342\n",
      "Epoch 10/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 23.4857\n",
      "Epoch 11/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 23.1373\n",
      "Epoch 12/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 22.7875\n",
      "Epoch 13/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 22.4364\n",
      "Epoch 14/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 22.0870\n",
      "Epoch 15/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 21.7375\n",
      "Epoch 16/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 21.3893\n",
      "Epoch 17/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 21.0408\n",
      "Epoch 18/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 20.6929\n",
      "Epoch 19/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 20.3442\n",
      "Epoch 20/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 19.9948\n",
      "Epoch 21/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 19.6467\n",
      "Epoch 22/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 19.3000\n",
      "Epoch 23/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 18.9531\n",
      "Epoch 24/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 18.6079\n",
      "Epoch 25/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 18.2634\n",
      "Epoch 26/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 17.9190\n",
      "Epoch 27/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 17.5738\n",
      "Epoch 28/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 17.2289\n",
      "Epoch 29/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 16.8850\n",
      "Epoch 30/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 16.5410\n",
      "Epoch 31/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 16.1976\n",
      "Epoch 32/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 15.8542\n",
      "Epoch 33/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 15.5111\n",
      "Epoch 34/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 15.1689\n",
      "Epoch 35/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 14.8277\n",
      "Epoch 36/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 14.4861\n",
      "Epoch 37/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 14.1442\n",
      "Epoch 38/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 13.8030\n",
      "Epoch 39/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 13.4619\n",
      "Epoch 40/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 13.1210\n",
      "Epoch 41/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 12.7799\n",
      "Epoch 42/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 12.4392\n",
      "Epoch 43/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 12.1001\n",
      "Epoch 44/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 11.7603\n",
      "Epoch 45/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 11.4227\n",
      "Epoch 46/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 11.0843\n",
      "Epoch 47/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 10.7470\n",
      "Epoch 48/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 10.4092\n",
      "Epoch 49/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 10.0705\n",
      "Epoch 50/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 9.7361\n",
      "Epoch 51/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 9.4008\n",
      "Epoch 52/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 9.0663\n",
      "Epoch 53/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 8.7313\n",
      "Epoch 54/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 8.3955\n",
      "Epoch 55/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 8.0617\n",
      "Epoch 56/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 7.7272\n",
      "Epoch 57/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 7.3945\n",
      "Epoch 58/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 7.0618\n",
      "Epoch 59/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 6.7287\n",
      "Epoch 60/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 6.3975\n",
      "Epoch 61/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 6.0661\n",
      "Epoch 62/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 5.7367\n",
      "Epoch 63/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 5.4084\n",
      "Epoch 64/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 5.0806\n",
      "Epoch 65/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 4.7545\n",
      "Epoch 66/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 4.4301\n",
      "Epoch 67/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 4.1089\n",
      "Epoch 68/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 3.7884\n",
      "Epoch 69/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 3.4701\n",
      "Epoch 70/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 3.1539\n",
      "Epoch 71/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 2.8403\n",
      "Epoch 72/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 2.5306\n",
      "Epoch 73/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 2.2247\n",
      "Epoch 74/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.9211\n",
      "Epoch 75/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.6225\n",
      "Epoch 76/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.3286\n",
      "Epoch 77/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0799\n",
      "Epoch 78/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 1.0301\n",
      "Epoch 79/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0292\n",
      "Epoch 80/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0291\n",
      "Epoch 81/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0280\n",
      "Epoch 82/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0284\n",
      "Epoch 83/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0288\n",
      "Epoch 84/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0290\n",
      "Epoch 85/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0278\n",
      "Epoch 86/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0286\n",
      "Epoch 87/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 1.0292\n",
      "Epoch 88/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0285\n",
      "Epoch 89/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0284\n",
      "Epoch 90/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0287\n",
      "Epoch 91/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0282\n",
      "Epoch 92/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0290\n",
      "Epoch 93/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0284\n",
      "Epoch 94/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0283\n",
      "Epoch 95/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0281\n",
      "Epoch 96/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0286\n",
      "Epoch 97/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0284\n",
      "Epoch 98/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0280\n",
      "Epoch 99/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0281\n",
      "Epoch 100/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0283\n",
      "Epoch 101/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0283\n",
      "Epoch 102/500\n",
      "400/400 [==============================] - 0s 76us/sample - loss: 1.0281\n",
      "Epoch 103/500\n",
      "400/400 [==============================] - 0s 40us/sample - loss: 1.0285\n",
      "Epoch 104/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0287\n",
      "Epoch 105/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0287\n",
      "Epoch 106/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0284\n",
      "Epoch 107/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0280\n",
      "Epoch 108/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 1.0285\n",
      "Epoch 109/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0283\n",
      "Epoch 110/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0277\n",
      "Epoch 111/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0281\n",
      "Epoch 112/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0281\n",
      "Epoch 113/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0287\n",
      "Epoch 114/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0288\n",
      "Epoch 115/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0284\n",
      "Epoch 116/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0286\n",
      "Epoch 117/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0283\n",
      "Epoch 118/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0284\n",
      "Epoch 119/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0279\n",
      "Epoch 120/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0288\n",
      "Epoch 121/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0289\n",
      "Epoch 122/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0279\n",
      "Epoch 123/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0287\n",
      "Epoch 124/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0285\n",
      "Epoch 125/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0279\n",
      "Epoch 126/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0279\n",
      "Epoch 127/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0284\n",
      "Epoch 128/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0275\n",
      "Epoch 129/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0288\n",
      "Epoch 130/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0278\n",
      "Epoch 131/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0279\n",
      "Epoch 132/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0279\n",
      "Epoch 133/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0283\n",
      "Epoch 134/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0281\n",
      "Epoch 135/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0278\n",
      "Epoch 136/500\n",
      "400/400 [==============================] - 0s 68us/sample - loss: 1.0287\n",
      "Epoch 137/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0280\n",
      "Epoch 138/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0280\n",
      "Epoch 139/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0289\n",
      "Epoch 140/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0279\n",
      "Epoch 141/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0276\n",
      "Epoch 142/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0286\n",
      "Epoch 143/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0283\n",
      "Epoch 144/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0283\n",
      "Epoch 145/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0280\n",
      "Epoch 146/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0273\n",
      "Epoch 147/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0284\n",
      "Epoch 148/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0275\n",
      "Epoch 149/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0294\n",
      "Epoch 150/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0283\n",
      "Epoch 151/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0275\n",
      "Epoch 152/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0275\n",
      "Epoch 153/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0281\n",
      "Epoch 154/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0277\n",
      "Epoch 155/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0283\n",
      "Epoch 156/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0283\n",
      "Epoch 157/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0278\n",
      "Epoch 158/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0278\n",
      "Epoch 159/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0287\n",
      "Epoch 160/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0274\n",
      "Epoch 161/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0275\n",
      "Epoch 162/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0274\n",
      "Epoch 163/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0271\n",
      "Epoch 164/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0272\n",
      "Epoch 165/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0284\n",
      "Epoch 166/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0282\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0278\n",
      "Epoch 168/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0275\n",
      "Epoch 169/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0274\n",
      "Epoch 170/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0269\n",
      "Epoch 171/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0277\n",
      "Epoch 172/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0282\n",
      "Epoch 173/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0282\n",
      "Epoch 174/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0284\n",
      "Epoch 175/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0279\n",
      "Epoch 176/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0283\n",
      "Epoch 177/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0283\n",
      "Epoch 178/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0271\n",
      "Epoch 179/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0278\n",
      "Epoch 180/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0271\n",
      "Epoch 181/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0277\n",
      "Epoch 182/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0273\n",
      "Epoch 183/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0273\n",
      "Epoch 184/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0281\n",
      "Epoch 185/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0266\n",
      "Epoch 186/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0276\n",
      "Epoch 187/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0269\n",
      "Epoch 188/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0274\n",
      "Epoch 189/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0276\n",
      "Epoch 190/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0271\n",
      "Epoch 191/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0274\n",
      "Epoch 192/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0273\n",
      "Epoch 193/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0282\n",
      "Epoch 194/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0271\n",
      "Epoch 195/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0271\n",
      "Epoch 196/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0281\n",
      "Epoch 197/500\n",
      "400/400 [==============================] - 0s 69us/sample - loss: 1.0278\n",
      "Epoch 198/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0278\n",
      "Epoch 199/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0272\n",
      "Epoch 200/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0275\n",
      "Epoch 201/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0278\n",
      "Epoch 202/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0278\n",
      "Epoch 203/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 1.0270\n",
      "Epoch 204/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0272\n",
      "Epoch 205/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0272\n",
      "Epoch 206/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0264\n",
      "Epoch 207/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0286\n",
      "Epoch 208/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0272\n",
      "Epoch 209/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0265\n",
      "Epoch 210/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0277\n",
      "Epoch 211/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0276\n",
      "Epoch 212/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0272\n",
      "Epoch 213/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0274\n",
      "Epoch 214/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0265\n",
      "Epoch 215/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0274\n",
      "Epoch 216/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0293\n",
      "Epoch 217/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0275\n",
      "Epoch 218/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0279\n",
      "Epoch 219/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0271\n",
      "Epoch 220/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0267\n",
      "Epoch 221/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0270\n",
      "Epoch 222/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0265\n",
      "Epoch 223/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0291\n",
      "Epoch 224/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0258\n",
      "Epoch 225/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0274\n",
      "Epoch 226/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0262\n",
      "Epoch 227/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0268\n",
      "Epoch 228/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0274\n",
      "Epoch 229/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0271\n",
      "Epoch 230/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0278\n",
      "Epoch 231/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0264\n",
      "Epoch 232/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0261\n",
      "Epoch 233/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0274\n",
      "Epoch 234/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0267\n",
      "Epoch 235/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0268\n",
      "Epoch 236/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0275\n",
      "Epoch 237/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0277\n",
      "Epoch 238/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 1.0286\n",
      "Epoch 239/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 1.0300\n",
      "Epoch 240/500\n",
      "400/400 [==============================] - 0s 40us/sample - loss: 1.0280\n",
      "Epoch 241/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0268\n",
      "Epoch 242/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0279\n",
      "Epoch 243/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0258\n",
      "Epoch 244/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0274\n",
      "Epoch 245/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0279\n",
      "Epoch 246/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 1.0265\n",
      "Epoch 247/500\n",
      "400/400 [==============================] - 0s 33us/sample - loss: 1.0269\n",
      "Epoch 248/500\n",
      "400/400 [==============================] - 0s 36us/sample - loss: 1.0261\n",
      "Epoch 249/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 1.0259\n",
      "Epoch 250/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0250\n",
      "Epoch 251/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0264\n",
      "Epoch 252/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0280\n",
      "Epoch 253/500\n",
      "400/400 [==============================] - 0s 38us/sample - loss: 1.0268\n",
      "Epoch 254/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 1.0270\n",
      "Epoch 255/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0279\n",
      "Epoch 256/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0264\n",
      "Epoch 257/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0266\n",
      "Epoch 258/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0271\n",
      "Epoch 259/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0266\n",
      "Epoch 260/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0269\n",
      "Epoch 261/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0270\n",
      "Epoch 262/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0264\n",
      "Epoch 263/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0276\n",
      "Epoch 264/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0275\n",
      "Epoch 265/500\n",
      "400/400 [==============================] - 0s 44us/sample - loss: 1.0260\n",
      "Epoch 266/500\n",
      "400/400 [==============================] - 0s 41us/sample - loss: 1.0272\n",
      "Epoch 267/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 1.0261\n",
      "Epoch 268/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0276\n",
      "Epoch 269/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0271\n",
      "Epoch 270/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0270\n",
      "Epoch 271/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0276\n",
      "Epoch 272/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0264\n",
      "Epoch 273/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0258\n",
      "Epoch 274/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0237\n",
      "Epoch 275/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0292\n",
      "Epoch 276/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0257\n",
      "Epoch 277/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0260\n",
      "Epoch 278/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0257\n",
      "Epoch 279/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0260\n",
      "Epoch 280/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0271\n",
      "Epoch 281/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0246\n",
      "Epoch 282/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0271\n",
      "Epoch 283/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0302\n",
      "Epoch 284/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 1.0238\n",
      "Epoch 285/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0266\n",
      "Epoch 286/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0248\n",
      "Epoch 287/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0292\n",
      "Epoch 288/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0263\n",
      "Epoch 289/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0243\n",
      "Epoch 290/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 1.0223\n",
      "Epoch 291/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0256\n",
      "Epoch 292/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0271\n",
      "Epoch 293/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0240\n",
      "Epoch 294/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 1.0229\n",
      "Epoch 295/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0233\n",
      "Epoch 296/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0236\n",
      "Epoch 297/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0231\n",
      "Epoch 298/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0253\n",
      "Epoch 299/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0233\n",
      "Epoch 300/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0214\n",
      "Epoch 301/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0212\n",
      "Epoch 302/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0236\n",
      "Epoch 303/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0224\n",
      "Epoch 304/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0221\n",
      "Epoch 305/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0236\n",
      "Epoch 306/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0202\n",
      "Epoch 307/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 1.0185\n",
      "Epoch 308/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0194\n",
      "Epoch 309/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0206\n",
      "Epoch 310/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0204\n",
      "Epoch 311/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0212\n",
      "Epoch 312/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0178\n",
      "Epoch 313/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0193\n",
      "Epoch 314/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0158\n",
      "Epoch 315/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0156\n",
      "Epoch 316/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0148\n",
      "Epoch 317/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0172\n",
      "Epoch 318/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0184\n",
      "Epoch 319/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0145\n",
      "Epoch 320/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0143\n",
      "Epoch 321/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0142\n",
      "Epoch 322/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0149\n",
      "Epoch 323/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0140\n",
      "Epoch 324/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0142\n",
      "Epoch 325/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0156\n",
      "Epoch 326/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 1.0103\n",
      "Epoch 327/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 1.0139\n",
      "Epoch 328/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0086\n",
      "Epoch 329/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 1.0093\n",
      "Epoch 330/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0082\n",
      "Epoch 331/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 1.0051\n",
      "Epoch 332/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 1.0093\n",
      "Epoch 333/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 1.0092\n",
      "Epoch 334/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 1.0101\n",
      "Epoch 335/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 1.0076\n",
      "Epoch 336/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0085\n",
      "Epoch 337/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0092\n",
      "Epoch 338/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 1.0057\n",
      "Epoch 339/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 1.0059\n",
      "Epoch 340/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0029\n",
      "Epoch 341/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 1.0006\n",
      "Epoch 342/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 1.0070\n",
      "Epoch 343/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 1.0046\n",
      "Epoch 344/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9964\n",
      "Epoch 345/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 1.0006\n",
      "Epoch 346/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 1.0018\n",
      "Epoch 347/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9993\n",
      "Epoch 348/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9970\n",
      "Epoch 349/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9973\n",
      "Epoch 350/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9949\n",
      "Epoch 351/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9963\n",
      "Epoch 352/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9966\n",
      "Epoch 353/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9928\n",
      "Epoch 354/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9957\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9918\n",
      "Epoch 356/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9931\n",
      "Epoch 357/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9899\n",
      "Epoch 358/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9884\n",
      "Epoch 359/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9910\n",
      "Epoch 360/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9898\n",
      "Epoch 361/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9872\n",
      "Epoch 362/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9922\n",
      "Epoch 363/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9888\n",
      "Epoch 364/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9841\n",
      "Epoch 365/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9825\n",
      "Epoch 366/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9823\n",
      "Epoch 367/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.9810\n",
      "Epoch 368/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.9796\n",
      "Epoch 369/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9830\n",
      "Epoch 370/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9814\n",
      "Epoch 371/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9793\n",
      "Epoch 372/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9783\n",
      "Epoch 373/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9768\n",
      "Epoch 374/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9758\n",
      "Epoch 375/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9734\n",
      "Epoch 376/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9741\n",
      "Epoch 377/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9717\n",
      "Epoch 378/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9686\n",
      "Epoch 379/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9703\n",
      "Epoch 380/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9675\n",
      "Epoch 381/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9636\n",
      "Epoch 382/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9665\n",
      "Epoch 383/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9687\n",
      "Epoch 384/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.9610\n",
      "Epoch 385/500\n",
      "400/400 [==============================] - 0s 45us/sample - loss: 0.9653\n",
      "Epoch 386/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.9619\n",
      "Epoch 387/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9622\n",
      "Epoch 388/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9547\n",
      "Epoch 389/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.9564\n",
      "Epoch 390/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.9616\n",
      "Epoch 391/500\n",
      "400/400 [==============================] - 0s 46us/sample - loss: 0.9531\n",
      "Epoch 392/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9555\n",
      "Epoch 393/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9518\n",
      "Epoch 394/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9525\n",
      "Epoch 395/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9491\n",
      "Epoch 396/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9471\n",
      "Epoch 397/500\n",
      "400/400 [==============================] - 0s 39us/sample - loss: 0.9413\n",
      "Epoch 398/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9416\n",
      "Epoch 399/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9450\n",
      "Epoch 400/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9407\n",
      "Epoch 401/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9391\n",
      "Epoch 402/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9340\n",
      "Epoch 403/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9401\n",
      "Epoch 404/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9326\n",
      "Epoch 405/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9420\n",
      "Epoch 406/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.9317\n",
      "Epoch 407/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.9299\n",
      "Epoch 408/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9280\n",
      "Epoch 409/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.9244\n",
      "Epoch 410/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9311\n",
      "Epoch 411/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9188\n",
      "Epoch 412/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9268\n",
      "Epoch 413/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.9208\n",
      "Epoch 414/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9201\n",
      "Epoch 415/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.9147\n",
      "Epoch 416/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9203\n",
      "Epoch 417/500\n",
      "400/400 [==============================] - 0s 42us/sample - loss: 0.9250\n",
      "Epoch 418/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.9147\n",
      "Epoch 419/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.9144\n",
      "Epoch 420/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.9088\n",
      "Epoch 421/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.9094\n",
      "Epoch 422/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9118\n",
      "Epoch 423/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9050\n",
      "Epoch 424/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.9043\n",
      "Epoch 425/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9001\n",
      "Epoch 426/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.9014\n",
      "Epoch 427/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.9006\n",
      "Epoch 428/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8987\n",
      "Epoch 429/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8916\n",
      "Epoch 430/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8999\n",
      "Epoch 431/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8932\n",
      "Epoch 432/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8956\n",
      "Epoch 433/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8851\n",
      "Epoch 434/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8873\n",
      "Epoch 435/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8816\n",
      "Epoch 436/500\n",
      "400/400 [==============================] - 0s 49us/sample - loss: 0.8920\n",
      "Epoch 437/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8826\n",
      "Epoch 438/500\n",
      "400/400 [==============================] - 0s 47us/sample - loss: 0.8789\n",
      "Epoch 439/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.8772\n",
      "Epoch 440/500\n",
      "400/400 [==============================] - 0s 55us/sample - loss: 0.8804\n",
      "Epoch 441/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8731\n",
      "Epoch 442/500\n",
      "400/400 [==============================] - 0s 51us/sample - loss: 0.8866\n",
      "Epoch 443/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8699\n",
      "Epoch 444/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8685\n",
      "Epoch 445/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8703\n",
      "Epoch 446/500\n",
      "400/400 [==============================] - 0s 50us/sample - loss: 0.8610\n",
      "Epoch 447/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8694\n",
      "Epoch 448/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8718\n",
      "Epoch 449/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8711\n",
      "Epoch 450/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8619\n",
      "Epoch 451/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8598\n",
      "Epoch 452/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8654\n",
      "Epoch 453/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8550\n",
      "Epoch 454/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8670\n",
      "Epoch 455/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8543\n",
      "Epoch 456/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8596\n",
      "Epoch 457/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8478\n",
      "Epoch 458/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8501\n",
      "Epoch 459/500\n",
      "400/400 [==============================] - 0s 53us/sample - loss: 0.8450\n",
      "Epoch 460/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8562\n",
      "Epoch 461/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8471\n",
      "Epoch 462/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8407\n",
      "Epoch 463/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8414\n",
      "Epoch 464/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8442\n",
      "Epoch 465/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.8451\n",
      "Epoch 466/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8331\n",
      "Epoch 467/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8323\n",
      "Epoch 468/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8326\n",
      "Epoch 469/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8396\n",
      "Epoch 470/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8262\n",
      "Epoch 471/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8228\n",
      "Epoch 472/500\n",
      "400/400 [==============================] - 0s 65us/sample - loss: 0.8277\n",
      "Epoch 473/500\n",
      "400/400 [==============================] - 0s 67us/sample - loss: 0.8232\n",
      "Epoch 474/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.8273\n",
      "Epoch 475/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8190\n",
      "Epoch 476/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8195\n",
      "Epoch 477/500\n",
      "400/400 [==============================] - 0s 66us/sample - loss: 0.8224\n",
      "Epoch 478/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8269\n",
      "Epoch 479/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8198\n",
      "Epoch 480/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.8183\n",
      "Epoch 481/500\n",
      "400/400 [==============================] - 0s 48us/sample - loss: 0.8189\n",
      "Epoch 482/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8089\n",
      "Epoch 483/500\n",
      "400/400 [==============================] - 0s 63us/sample - loss: 0.8136\n",
      "Epoch 484/500\n",
      "400/400 [==============================] - 0s 59us/sample - loss: 0.8079\n",
      "Epoch 485/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.8122\n",
      "Epoch 486/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.8022\n",
      "Epoch 487/500\n",
      "400/400 [==============================] - 0s 64us/sample - loss: 0.8029\n",
      "Epoch 488/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.8067\n",
      "Epoch 489/500\n",
      "400/400 [==============================] - 0s 62us/sample - loss: 0.8048\n",
      "Epoch 490/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.8007\n",
      "Epoch 491/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7982\n",
      "Epoch 492/500\n",
      "400/400 [==============================] - 0s 56us/sample - loss: 0.7914\n",
      "Epoch 493/500\n",
      "400/400 [==============================] - 0s 43us/sample - loss: 0.7971\n",
      "Epoch 494/500\n",
      "400/400 [==============================] - 0s 54us/sample - loss: 0.7865\n",
      "Epoch 495/500\n",
      "400/400 [==============================] - 0s 60us/sample - loss: 0.7915\n",
      "Epoch 496/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7875\n",
      "Epoch 497/500\n",
      "400/400 [==============================] - 0s 61us/sample - loss: 0.7830\n",
      "Epoch 498/500\n",
      "400/400 [==============================] - 0s 57us/sample - loss: 0.7770\n",
      "Epoch 499/500\n",
      "400/400 [==============================] - 0s 52us/sample - loss: 0.7825\n",
      "Epoch 500/500\n",
      "400/400 [==============================] - 0s 58us/sample - loss: 0.7786\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([])\n",
    "r2s = np.array([])\n",
    "for al in np.linspace(0.001, 2, 5):\n",
    "    model = Sequential([selection_layer(units=X.shape[-1], alpha = al, norm=10000), layers.Dense(5, activation='relu'), layers.Dense(1)])\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=500)\n",
    "    weights = np.append(weights,tf.linalg.tensor_diag_part(model.layers[0].weights[0]).numpy())\n",
    "    r2s = np.append(r2s,r2_score(y_test,model.predict(X_test)))\n",
    "weights = weights.reshape(-1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure()\n",
    "ax = sns.heatmap((weights>0), cmap='Blues', cbar=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70451902, 0.66775074, 0.64500471, 0.62070525, 0.53477612])"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## classification data (sklearn dummy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 1200, n_informative=10,n_repeated=0, n_classes=3, class_sep=1., n_clusters_per_class=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:, 1], X[:, 3],marker='o', c=y, s=25, edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#y = (y-y.mean())/y.std()\n",
    "minmax = preprocessing.MinMaxScaler(feature_range=(0,10))\n",
    "minmax.fit(X)\n",
    "X = minmax.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0618 12:04:55.159354 139813652932416 deprecation.py:323] From /home/herfurtht/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 476us/sample - loss: 2.1471 - val_loss: 1.4300\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.3666 - val_loss: 1.2293\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 1.2663 - val_loss: 1.1859\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.2029 - val_loss: 1.1492\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.1691 - val_loss: 1.1408\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1628 - val_loss: 1.1343\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1619 - val_loss: 1.1157\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1450 - val_loss: 1.1068\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1208 - val_loss: 1.1044\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1263 - val_loss: 1.0844\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.1160 - val_loss: 1.0759\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.0888 - val_loss: 1.0660\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.0873 - val_loss: 1.0521\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.0796 - val_loss: 1.0470\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0738 - val_loss: 1.0312\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 1.0730 - val_loss: 1.0282\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.0628 - val_loss: 1.0191\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0497 - val_loss: 1.0027\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.0515 - val_loss: 0.9996\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0367 - val_loss: 0.9842\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0279 - val_loss: 0.9826\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 58us/sample - loss: 1.0490 - val_loss: 0.9753\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 1.0171 - val_loss: 0.9717\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.0160 - val_loss: 0.9564\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.0113 - val_loss: 0.9545\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0052 - val_loss: 0.9407\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 1.0019 - val_loss: 0.9434\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.0042 - val_loss: 0.9348\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9971 - val_loss: 0.9267\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9902 - val_loss: 0.9233\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9868 - val_loss: 0.9163\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9735 - val_loss: 0.9110\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.9746 - val_loss: 0.9047\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9767 - val_loss: 0.9028\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9696 - val_loss: 0.8998\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9595 - val_loss: 0.8875\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.9574 - val_loss: 0.8870\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9659 - val_loss: 0.8832\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.9401 - val_loss: 0.8753\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.9465 - val_loss: 0.8782\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9543 - val_loss: 0.8720\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.9316 - val_loss: 0.8634\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9471 - val_loss: 0.8668\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9420 - val_loss: 0.8683\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9170 - val_loss: 0.8509\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9303 - val_loss: 0.8459\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9386 - val_loss: 0.8440\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.9324 - val_loss: 0.8467\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9081 - val_loss: 0.8399\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.9224 - val_loss: 0.8451\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9127 - val_loss: 0.8324\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9128 - val_loss: 0.8492\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9139 - val_loss: 0.8290\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9073 - val_loss: 0.8318\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9018 - val_loss: 0.8170\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.9011 - val_loss: 0.8110\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8893 - val_loss: 0.8093\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9059 - val_loss: 0.8230\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9094 - val_loss: 0.8089\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9064 - val_loss: 0.8205\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8893 - val_loss: 0.8031\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8976 - val_loss: 0.8075\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8837 - val_loss: 0.8018\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8957 - val_loss: 0.8034\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9010 - val_loss: 0.8050\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9071 - val_loss: 0.7942\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8845 - val_loss: 0.7875\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8850 - val_loss: 0.7971\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8753 - val_loss: 0.7838\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8735 - val_loss: 0.7750\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8531 - val_loss: 0.7891\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8813 - val_loss: 0.7804\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8773 - val_loss: 0.7954\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8715 - val_loss: 0.7825\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8695 - val_loss: 0.7847\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8690 - val_loss: 0.7763\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8833 - val_loss: 0.7868\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8792 - val_loss: 0.7642\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8764 - val_loss: 0.7761\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8675 - val_loss: 0.7620\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8842 - val_loss: 0.7675\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8780 - val_loss: 0.7602\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8561 - val_loss: 0.7704\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8711 - val_loss: 0.7780\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8478 - val_loss: 0.7658\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8478 - val_loss: 0.7634\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8583 - val_loss: 0.7634\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8458 - val_loss: 0.7589\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8656 - val_loss: 0.7566\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8678 - val_loss: 0.7768\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8432 - val_loss: 0.7529\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8490 - val_loss: 0.7559\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8546 - val_loss: 0.7622\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8440 - val_loss: 0.7725\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8294 - val_loss: 0.7494\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8369 - val_loss: 0.7547\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8464 - val_loss: 0.7596\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8344 - val_loss: 0.7606\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8338 - val_loss: 0.7436\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8496 - val_loss: 0.7489\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8442 - val_loss: 0.7413\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8335 - val_loss: 0.7348\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8403 - val_loss: 0.7436\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8366 - val_loss: 0.7312\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8319 - val_loss: 0.7344\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8297 - val_loss: 0.7426\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8370 - val_loss: 0.7453\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8338 - val_loss: 0.7347\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7937 - val_loss: 0.7229\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8266 - val_loss: 0.7279\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8149 - val_loss: 0.7194\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8017 - val_loss: 0.7197\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8128 - val_loss: 0.7231\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8165 - val_loss: 0.7162\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8133 - val_loss: 0.7199\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8037 - val_loss: 0.7145\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8313 - val_loss: 0.7138\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8102 - val_loss: 0.7078\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7825 - val_loss: 0.7353\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8067 - val_loss: 0.7050\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7843 - val_loss: 0.7069\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7817 - val_loss: 0.6945\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7832 - val_loss: 0.7141\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7913 - val_loss: 0.7000\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7976 - val_loss: 0.7020\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7875 - val_loss: 0.7068\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7929 - val_loss: 0.7051\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7872 - val_loss: 0.6918\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7951 - val_loss: 0.6941\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7731 - val_loss: 0.7026\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7927 - val_loss: 0.7091\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7789 - val_loss: 0.6966\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7708 - val_loss: 0.6912\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7885 - val_loss: 0.6908\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7758 - val_loss: 0.6890\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7818 - val_loss: 0.6810\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7755 - val_loss: 0.6798\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7680 - val_loss: 0.6884\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7768 - val_loss: 0.6831\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7626 - val_loss: 0.6772\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7801 - val_loss: 0.7008\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7686 - val_loss: 0.7047\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7733 - val_loss: 0.6904\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7723 - val_loss: 0.6778\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7746 - val_loss: 0.6863\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7640 - val_loss: 0.6772\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7580 - val_loss: 0.6834\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7563 - val_loss: 0.6816\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7665 - val_loss: 0.6845\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7355 - val_loss: 0.6753\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7673 - val_loss: 0.6770\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.7569 - val_loss: 0.6855\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7582 - val_loss: 0.6639\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7605 - val_loss: 0.6826\n",
      "Epoch 155/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7541 - val_loss: 0.6716\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7458 - val_loss: 0.6750\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7709 - val_loss: 0.6721\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7443 - val_loss: 0.6909\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7616 - val_loss: 0.6610\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7613 - val_loss: 0.6750\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7621 - val_loss: 0.6785\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7476 - val_loss: 0.6653\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7306 - val_loss: 0.6713\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7397 - val_loss: 0.6646\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7473 - val_loss: 0.6662\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7534 - val_loss: 0.6696\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7304 - val_loss: 0.6836\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7598 - val_loss: 0.6708\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7251 - val_loss: 0.6615\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7516 - val_loss: 0.6667\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7425 - val_loss: 0.6709\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7393 - val_loss: 0.6606\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7347 - val_loss: 0.6808\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 69us/sample - loss: 0.7327 - val_loss: 0.6463\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7305 - val_loss: 0.6686\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7422 - val_loss: 0.6773\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7375 - val_loss: 0.6729\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7384 - val_loss: 0.6591\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7445 - val_loss: 0.6538\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7330 - val_loss: 0.6586\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7188 - val_loss: 0.6611\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7293 - val_loss: 0.6608\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7269 - val_loss: 0.6670\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7349 - val_loss: 0.6600\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7474 - val_loss: 0.6678\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7192 - val_loss: 0.6643\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7290 - val_loss: 0.6600\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7312 - val_loss: 0.6676\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7313 - val_loss: 0.6509\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7304 - val_loss: 0.6406\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7154 - val_loss: 0.6456\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7259 - val_loss: 0.6587\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7130 - val_loss: 0.6431\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7225 - val_loss: 0.6431\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7372 - val_loss: 0.6622\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7441 - val_loss: 0.6460\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7137 - val_loss: 0.6515\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7031 - val_loss: 0.6459\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7404 - val_loss: 0.6481\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.7359 - val_loss: 0.6473\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7048 - val_loss: 0.6410\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7311 - val_loss: 0.6591\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7120 - val_loss: 0.6417\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.7050 - val_loss: 0.6534\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7269 - val_loss: 0.6486\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 0.7214 - val_loss: 0.6627\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 66us/sample - loss: 0.7046 - val_loss: 0.6532\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 0.6867 - val_loss: 0.6589\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7170 - val_loss: 0.6509\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7197 - val_loss: 0.6562\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7087 - val_loss: 0.6343\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7226 - val_loss: 0.6279\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7061 - val_loss: 0.6373\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7275 - val_loss: 0.6581\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7277 - val_loss: 0.6431\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7209 - val_loss: 0.6429\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7047 - val_loss: 0.6403\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.6887 - val_loss: 0.6501\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 67us/sample - loss: 0.7098 - val_loss: 0.6395\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7145 - val_loss: 0.6326\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7210 - val_loss: 0.6482\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.6989 - val_loss: 0.6301\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.7103 - val_loss: 0.6315\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 0.6922 - val_loss: 0.6343\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7065 - val_loss: 0.6384\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7119 - val_loss: 0.6469\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7110 - val_loss: 0.6606\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7141 - val_loss: 0.6443\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7188 - val_loss: 0.6375\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7188 - val_loss: 0.6298\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.6963 - val_loss: 0.6288\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7055 - val_loss: 0.6240\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 0.7078 - val_loss: 0.6440\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 67us/sample - loss: 0.6848 - val_loss: 0.6406\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.6937 - val_loss: 0.6230\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.7068 - val_loss: 0.6428\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6901 - val_loss: 0.6393\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7008 - val_loss: 0.6242\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.6945 - val_loss: 0.6260\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.6856 - val_loss: 0.6456\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7020 - val_loss: 0.6432\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6926 - val_loss: 0.6321\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7117 - val_loss: 0.6289\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7030 - val_loss: 0.6253\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.7004 - val_loss: 0.6378\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.7196 - val_loss: 0.6347\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.7108 - val_loss: 0.6204\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 56us/sample - loss: 0.7072 - val_loss: 0.6347\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 0.6989 - val_loss: 0.6303\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 0.6864 - val_loss: 0.6469\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 78us/sample - loss: 0.6924 - val_loss: 0.6316\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.6896 - val_loss: 0.6071\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.7067 - val_loss: 0.6405\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7017 - val_loss: 0.6466\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7050 - val_loss: 0.6206\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.6749 - val_loss: 0.6290\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.6946 - val_loss: 0.6236\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.6922 - val_loss: 0.6241\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 0.6923 - val_loss: 0.6404\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 0.6898 - val_loss: 0.6125\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7041 - val_loss: 0.6363\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 0.6953 - val_loss: 0.6246\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.6750 - val_loss: 0.6153\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 51us/sample - loss: 0.6755 - val_loss: 0.6158\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 0.6807 - val_loss: 0.6174\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.6862 - val_loss: 0.6279\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 71us/sample - loss: 0.6968 - val_loss: 0.6224\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 0.6931 - val_loss: 0.6226\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 0.6837 - val_loss: 0.6114\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.6794 - val_loss: 0.6398\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.6834 - val_loss: 0.6088\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.6899 - val_loss: 0.6313\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 0.6652 - val_loss: 0.6296\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.6676 - val_loss: 0.6314\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.6660 - val_loss: 0.6166\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 78us/sample - loss: 0.6754 - val_loss: 0.6193\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 61us/sample - loss: 0.6913 - val_loss: 0.6197\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.6721 - val_loss: 0.6139\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6952 - val_loss: 0.6291\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.6837 - val_loss: 0.6108\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.6794 - val_loss: 0.6155\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6883 - val_loss: 0.6133\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.6827 - val_loss: 0.6218\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.6680 - val_loss: 0.6176\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.6635 - val_loss: 0.6190\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.6740 - val_loss: 0.6259\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.6985 - val_loss: 0.6311\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.6865 - val_loss: 0.6146\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.6749 - val_loss: 0.6251\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.6678 - val_loss: 0.6173\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.6714 - val_loss: 0.5957\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6823 - val_loss: 0.6183\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.6599 - val_loss: 0.6218\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.6830 - val_loss: 0.6052\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.6546 - val_loss: 0.6153\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.6687 - val_loss: 0.6180\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.6757 - val_loss: 0.6026\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.6622 - val_loss: 0.6136\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.6663 - val_loss: 0.6070\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6573 - val_loss: 0.6175\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.6732 - val_loss: 0.6298\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 0.6731 - val_loss: 0.6075\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.6873 - val_loss: 0.6121\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.6582 - val_loss: 0.6201\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.6745 - val_loss: 0.6127\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 0.6509 - val_loss: 0.5926\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.6794 - val_loss: 0.6102\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 0.6689 - val_loss: 0.6054\n",
      "Epoch 309/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 70us/sample - loss: 0.6858 - val_loss: 0.6006\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.6458 - val_loss: 0.6071\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6552 - val_loss: 0.5961\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.6587 - val_loss: 0.6148\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6575 - val_loss: 0.5984\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6463 - val_loss: 0.5905\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6676 - val_loss: 0.6092\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.6766 - val_loss: 0.6193\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.6700 - val_loss: 0.6089\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.6764 - val_loss: 0.6063\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.6492 - val_loss: 0.5927\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.6728 - val_loss: 0.6014\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.6528 - val_loss: 0.5859\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.6715 - val_loss: 0.6298\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.6564 - val_loss: 0.6080\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6504 - val_loss: 0.6089\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.6644 - val_loss: 0.5905\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.6631 - val_loss: 0.5989\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.6499 - val_loss: 0.6112\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.6480 - val_loss: 0.5945\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.6585 - val_loss: 0.5940\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.6536 - val_loss: 0.5952\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.6513 - val_loss: 0.5902\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.6590 - val_loss: 0.5922\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.6776 - val_loss: 0.5974\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.6513 - val_loss: 0.6079\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6479 - val_loss: 0.5856\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.6432 - val_loss: 0.5950\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.6452 - val_loss: 0.5851\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.6566 - val_loss: 0.6129\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.6477 - val_loss: 0.5942\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.6429 - val_loss: 0.5888\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 409us/sample - loss: 3.4342 - val_loss: 2.2262\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 2.1768 - val_loss: 2.0030\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.0063 - val_loss: 1.8393\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.7406 - val_loss: 1.5547\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4622 - val_loss: 1.3596\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3344 - val_loss: 1.3048\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.2967 - val_loss: 1.2823\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2824 - val_loss: 1.2707\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 110us/sample - loss: 1.2763 - val_loss: 1.2577\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2599 - val_loss: 1.2400\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2508 - val_loss: 1.2303\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.2454 - val_loss: 1.2113\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2408 - val_loss: 1.2008\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2231 - val_loss: 1.1908\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2094 - val_loss: 1.1782\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.2000 - val_loss: 1.1618\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1808 - val_loss: 1.1541\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1759 - val_loss: 1.1275\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1668 - val_loss: 1.1266\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.1531 - val_loss: 1.1050\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1380 - val_loss: 1.0810\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1212 - val_loss: 1.0776\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1064 - val_loss: 1.0521\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1052 - val_loss: 1.0372\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0925 - val_loss: 1.0225\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0871 - val_loss: 1.0165\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0660 - val_loss: 0.9891\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0753 - val_loss: 0.9815\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0603 - val_loss: 0.9716\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0484 - val_loss: 0.9555\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0549 - val_loss: 0.9516\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0297 - val_loss: 0.9409\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0298 - val_loss: 0.9247\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0079 - val_loss: 0.9158\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0076 - val_loss: 0.9055\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0021 - val_loss: 0.8903\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9949 - val_loss: 0.8898\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9908 - val_loss: 0.8752\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9891 - val_loss: 0.8982\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9681 - val_loss: 0.8625\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9641 - val_loss: 0.8604\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9743 - val_loss: 0.8534\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9555 - val_loss: 0.8570\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9850 - val_loss: 0.8552\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9580 - val_loss: 0.8518\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9438 - val_loss: 0.8553\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9442 - val_loss: 0.8278\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9380 - val_loss: 0.8408\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9326 - val_loss: 0.8619\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9207 - val_loss: 0.8343\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9385 - val_loss: 0.8278\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.9266 - val_loss: 0.8171\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.9329 - val_loss: 0.8220\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.9246 - val_loss: 0.8207\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9400 - val_loss: 0.8012\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8995 - val_loss: 0.8007\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9152 - val_loss: 0.8155\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9179 - val_loss: 0.7918\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8927 - val_loss: 0.7888\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 0.9065 - val_loss: 0.8008\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9131 - val_loss: 0.7852\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.9022 - val_loss: 0.7876\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9054 - val_loss: 0.7930\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8996 - val_loss: 0.7791\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.8891 - val_loss: 0.7832\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 63us/sample - loss: 0.8960 - val_loss: 0.7906\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8874 - val_loss: 0.7795\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8804 - val_loss: 0.7667\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8776 - val_loss: 0.7590\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8700 - val_loss: 0.7823\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9002 - val_loss: 0.7937\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8798 - val_loss: 0.7646\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8849 - val_loss: 0.7657\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 112us/sample - loss: 0.8622 - val_loss: 0.7671\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8805 - val_loss: 0.7713\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8785 - val_loss: 0.7559\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8630 - val_loss: 0.7671\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8691 - val_loss: 0.7636\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8709 - val_loss: 0.7508\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8744 - val_loss: 0.7526\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 112us/sample - loss: 0.8669 - val_loss: 0.7474\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 66us/sample - loss: 0.8680 - val_loss: 0.7515\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.8564 - val_loss: 0.7464\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8572 - val_loss: 0.7458\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8435 - val_loss: 0.7460\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8670 - val_loss: 0.7475\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8616 - val_loss: 0.7470\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.8563 - val_loss: 0.7517\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8628 - val_loss: 0.7544\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.8594 - val_loss: 0.7584\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.8533 - val_loss: 0.7678\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8608 - val_loss: 0.7432\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8509 - val_loss: 0.7392\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8591 - val_loss: 0.7336\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8391 - val_loss: 0.7613\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8643 - val_loss: 0.7506\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8455 - val_loss: 0.7310\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8412 - val_loss: 0.7516\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.8426 - val_loss: 0.7311\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8445 - val_loss: 0.7368\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8557 - val_loss: 0.7397\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8400 - val_loss: 0.7491\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8307 - val_loss: 0.7498\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8384 - val_loss: 0.7278\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.8293 - val_loss: 0.7468\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8238 - val_loss: 0.7505\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8439 - val_loss: 0.7421\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8492 - val_loss: 0.7427\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 67us/sample - loss: 0.8357 - val_loss: 0.7316\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 0.8397 - val_loss: 0.7342\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.8364 - val_loss: 0.7212\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8278 - val_loss: 0.7521\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8288 - val_loss: 0.7275\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8335 - val_loss: 0.7435\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8268 - val_loss: 0.7129\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 0.8366 - val_loss: 0.7244\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8299 - val_loss: 0.7451\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8157 - val_loss: 0.7183\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.8299 - val_loss: 0.7356\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8362 - val_loss: 0.7223\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8369 - val_loss: 0.7158\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8241 - val_loss: 0.7254\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8114 - val_loss: 0.7243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8263 - val_loss: 0.7292\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.8334 - val_loss: 0.7393\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.8096 - val_loss: 0.7241\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8216 - val_loss: 0.7091\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8256 - val_loss: 0.7121\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8223 - val_loss: 0.7124\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8172 - val_loss: 0.7266\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.8168 - val_loss: 0.7144\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8212 - val_loss: 0.7273\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8187 - val_loss: 0.7239\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8140 - val_loss: 0.7136\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8188 - val_loss: 0.7297\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8231 - val_loss: 0.7413\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8133 - val_loss: 0.7242\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 0.8072 - val_loss: 0.7292\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8108 - val_loss: 0.7170\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8115 - val_loss: 0.7011\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7963 - val_loss: 0.7057\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8201 - val_loss: 0.7470\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.8019 - val_loss: 0.7196\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 0.8210 - val_loss: 0.7237\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8070 - val_loss: 0.7170\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8041 - val_loss: 0.7189\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7937 - val_loss: 0.7056\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8174 - val_loss: 0.7103\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8102 - val_loss: 0.7031\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7972 - val_loss: 0.7264\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8029 - val_loss: 0.7374\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8114 - val_loss: 0.7064\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 0.7992 - val_loss: 0.6999\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8183 - val_loss: 0.7051\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8069 - val_loss: 0.7058\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.7922 - val_loss: 0.7091\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8010 - val_loss: 0.7043\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8212 - val_loss: 0.7069\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7956 - val_loss: 0.7230\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8014 - val_loss: 0.7225\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7872 - val_loss: 0.7272\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8123 - val_loss: 0.7132\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7993 - val_loss: 0.7399\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.7841 - val_loss: 0.7337\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8037 - val_loss: 0.7027\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7933 - val_loss: 0.7202\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8082 - val_loss: 0.7307\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 110us/sample - loss: 0.8056 - val_loss: 0.7141\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8190 - val_loss: 0.7178\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7793 - val_loss: 0.7160\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7963 - val_loss: 0.7095\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8063 - val_loss: 0.7228\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7802 - val_loss: 0.7118\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 0.7842 - val_loss: 0.7032\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7803 - val_loss: 0.7131\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7923 - val_loss: 0.7004\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8125 - val_loss: 0.7374\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7806 - val_loss: 0.7002\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7802 - val_loss: 0.7094\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7934 - val_loss: 0.7314\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7919 - val_loss: 0.6951\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8047 - val_loss: 0.7429\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7783 - val_loss: 0.7024\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7926 - val_loss: 0.7021\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7846 - val_loss: 0.7104\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7843 - val_loss: 0.7072\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7859 - val_loss: 0.7079\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7784 - val_loss: 0.6996\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7745 - val_loss: 0.7021\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7903 - val_loss: 0.7196\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8069 - val_loss: 0.7195\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7815 - val_loss: 0.7272\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7954 - val_loss: 0.7338\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8057 - val_loss: 0.7209\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7917 - val_loss: 0.7049\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7821 - val_loss: 0.6933\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7964 - val_loss: 0.7014\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 0.7754 - val_loss: 0.7091\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7650 - val_loss: 0.7037\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7932 - val_loss: 0.7036\n",
      "Epoch 201/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7910 - val_loss: 0.7125\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7784 - val_loss: 0.7177\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7995 - val_loss: 0.6928\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7937 - val_loss: 0.7247\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7961 - val_loss: 0.7119\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7832 - val_loss: 0.6959\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7788 - val_loss: 0.6964\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7984 - val_loss: 0.7104\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7788 - val_loss: 0.7084\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7863 - val_loss: 0.7300\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7886 - val_loss: 0.7263\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7870 - val_loss: 0.7430\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7815 - val_loss: 0.7005\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7790 - val_loss: 0.7168\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7875 - val_loss: 0.7288\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7833 - val_loss: 0.7113\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7772 - val_loss: 0.7151\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7765 - val_loss: 0.7250\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7754 - val_loss: 0.7263\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7938 - val_loss: 0.7018\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7855 - val_loss: 0.6951\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7925 - val_loss: 0.7203\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7838 - val_loss: 0.7208\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7815 - val_loss: 0.6981\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7849 - val_loss: 0.6975\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 71us/sample - loss: 0.7806 - val_loss: 0.7596\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7857 - val_loss: 0.7236\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7791 - val_loss: 0.7183\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7721 - val_loss: 0.6974\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7763 - val_loss: 0.7051\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7867 - val_loss: 0.6916\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7829 - val_loss: 0.7299\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7716 - val_loss: 0.7215\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7687 - val_loss: 0.6960\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 0.7804 - val_loss: 0.7049\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7648 - val_loss: 0.7138\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7613 - val_loss: 0.7054\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7574 - val_loss: 0.7275\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7946 - val_loss: 0.6971\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 242us/sample - loss: 0.7676 - val_loss: 0.7118\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.7673 - val_loss: 0.6953\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7756 - val_loss: 0.7194\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7745 - val_loss: 0.6906\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7760 - val_loss: 0.7249\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7754 - val_loss: 0.7108\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7838 - val_loss: 0.7052\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7818 - val_loss: 0.7201\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7738 - val_loss: 0.6973\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7629 - val_loss: 0.7019\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7679 - val_loss: 0.7266\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7730 - val_loss: 0.7293\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7807 - val_loss: 0.7474\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7750 - val_loss: 0.7183\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7722 - val_loss: 0.6959\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7845 - val_loss: 0.6977\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7696 - val_loss: 0.6830\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7674 - val_loss: 0.7178\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7688 - val_loss: 0.6997\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7648 - val_loss: 0.6944\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7765 - val_loss: 0.7079\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7733 - val_loss: 0.7019\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7657 - val_loss: 0.7328\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7785 - val_loss: 0.6869\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7634 - val_loss: 0.7003\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7666 - val_loss: 0.7267\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7740 - val_loss: 0.7127\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7597 - val_loss: 0.7418\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7715 - val_loss: 0.7129\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7644 - val_loss: 0.7058\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7707 - val_loss: 0.6826\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7776 - val_loss: 0.7056\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7593 - val_loss: 0.7425\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7821 - val_loss: 0.7104\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7779 - val_loss: 0.6936\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7687 - val_loss: 0.7107\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7776 - val_loss: 0.7190\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7698 - val_loss: 0.7354\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7566 - val_loss: 0.7075\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7660 - val_loss: 0.7155\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7750 - val_loss: 0.7036\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7695 - val_loss: 0.6935\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7616 - val_loss: 0.7229\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.7742 - val_loss: 0.7243\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7698 - val_loss: 0.7288\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7640 - val_loss: 0.6984\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7616 - val_loss: 0.7178\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7694 - val_loss: 0.7279\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7692 - val_loss: 0.6909\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7538 - val_loss: 0.7003\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7547 - val_loss: 0.7045\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7644 - val_loss: 0.7093\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7799 - val_loss: 0.7196\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7592 - val_loss: 0.6928\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.7684 - val_loss: 0.7046\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7660 - val_loss: 0.6982\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 71us/sample - loss: 0.7611 - val_loss: 0.7062\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7560 - val_loss: 0.6842\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7741 - val_loss: 0.6994\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7547 - val_loss: 0.7065\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7600 - val_loss: 0.7385\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7685 - val_loss: 0.7018\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7814 - val_loss: 0.7164\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7607 - val_loss: 0.6933\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7658 - val_loss: 0.7540\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7706 - val_loss: 0.7086\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7758 - val_loss: 0.7216\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7606 - val_loss: 0.7266\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7588 - val_loss: 0.7120\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7512 - val_loss: 0.7360\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7600 - val_loss: 0.7052\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7623 - val_loss: 0.7033\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7634 - val_loss: 0.7093\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.7793 - val_loss: 0.7404\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7426 - val_loss: 0.7083\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7599 - val_loss: 0.7282\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7807 - val_loss: 0.6969\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7600 - val_loss: 0.6998\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7600 - val_loss: 0.7067\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7497 - val_loss: 0.7281\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7676 - val_loss: 0.7218\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.7871 - val_loss: 0.7444\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7735 - val_loss: 0.7109\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7610 - val_loss: 0.7263\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7537 - val_loss: 0.7030\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7508 - val_loss: 0.6918\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7500 - val_loss: 0.6932\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7671 - val_loss: 0.7066\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7528 - val_loss: 0.7009\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7685 - val_loss: 0.7001\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7608 - val_loss: 0.6922\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7477 - val_loss: 0.7153\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7548 - val_loss: 0.7000\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.7845 - val_loss: 0.7013\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7569 - val_loss: 0.6982\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7606 - val_loss: 0.7408\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7551 - val_loss: 0.7122\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7466 - val_loss: 0.7019\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7717 - val_loss: 0.6999\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7865 - val_loss: 0.7623\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7547 - val_loss: 0.7220\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 417us/sample - loss: 2.8422 - val_loss: 1.7002\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 1.7055 - val_loss: 1.4616\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.5047 - val_loss: 1.4152\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4246 - val_loss: 1.3667\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3903 - val_loss: 1.3563\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3693 - val_loss: 1.3426\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3432 - val_loss: 1.3297\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.3351 - val_loss: 1.3255\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.3183 - val_loss: 1.3135\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.3148 - val_loss: 1.3006\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3143 - val_loss: 1.2953\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3008 - val_loss: 1.2851\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.2863 - val_loss: 1.2700\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2806 - val_loss: 1.2634\n",
      "Epoch 15/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2714 - val_loss: 1.2550\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2459 - val_loss: 1.2346\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.2538 - val_loss: 1.2245\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2479 - val_loss: 1.2143\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2309 - val_loss: 1.1959\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.2193 - val_loss: 1.1771\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.2079 - val_loss: 1.1646\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.1925 - val_loss: 1.1499\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.1906 - val_loss: 1.1519\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.1839 - val_loss: 1.1333\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.1842 - val_loss: 1.1248\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1784 - val_loss: 1.1102\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1639 - val_loss: 1.1004\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1608 - val_loss: 1.0885\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1387 - val_loss: 1.0792\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1573 - val_loss: 1.0758\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1389 - val_loss: 1.0645\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1404 - val_loss: 1.0596\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1143 - val_loss: 1.0504\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1197 - val_loss: 1.0386\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1377 - val_loss: 1.0521\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1189 - val_loss: 1.0266\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.1162 - val_loss: 1.0117\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0934 - val_loss: 1.0004\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0927 - val_loss: 0.9978\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0946 - val_loss: 0.9932\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0895 - val_loss: 0.9946\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0597 - val_loss: 0.9785\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0837 - val_loss: 0.9795\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0687 - val_loss: 0.9817\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0633 - val_loss: 0.9717\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0681 - val_loss: 0.9664\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0709 - val_loss: 0.9706\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0700 - val_loss: 0.9656\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0570 - val_loss: 0.9551\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0521 - val_loss: 0.9472\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0488 - val_loss: 0.9463\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0549 - val_loss: 0.9493\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.0440 - val_loss: 0.9340\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0428 - val_loss: 0.9353\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0501 - val_loss: 0.9370\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.0385 - val_loss: 0.9244\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0328 - val_loss: 0.9348\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0328 - val_loss: 0.9171\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0307 - val_loss: 0.9234\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0276 - val_loss: 0.9300\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0384 - val_loss: 0.9100\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0256 - val_loss: 0.9081\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0322 - val_loss: 0.9107\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0163 - val_loss: 0.9041\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0185 - val_loss: 0.9056\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0221 - val_loss: 0.9060\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0101 - val_loss: 0.8968\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0226 - val_loss: 0.9106\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0128 - val_loss: 0.8997\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0066 - val_loss: 0.8921\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0140 - val_loss: 0.8991\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9959 - val_loss: 0.8870\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 1.0017 - val_loss: 0.8790\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.0187 - val_loss: 0.8849\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9972 - val_loss: 0.8802\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0115 - val_loss: 0.8885\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0003 - val_loss: 0.8801\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9799 - val_loss: 0.8705\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9895 - val_loss: 0.8691\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9935 - val_loss: 0.8686\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0008 - val_loss: 0.8645\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9893 - val_loss: 0.8643\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9911 - val_loss: 0.8628\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9851 - val_loss: 0.8762\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9767 - val_loss: 0.8520\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9736 - val_loss: 0.8605\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9757 - val_loss: 0.8516\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9720 - val_loss: 0.8537\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9937 - val_loss: 0.8462\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9968 - val_loss: 0.8471\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9711 - val_loss: 0.8461\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9825 - val_loss: 0.8395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9722 - val_loss: 0.8407\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9897 - val_loss: 0.8553\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9744 - val_loss: 0.8349\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9672 - val_loss: 0.8365\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9590 - val_loss: 0.8308\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9577 - val_loss: 0.8366\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9648 - val_loss: 0.8501\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9594 - val_loss: 0.8314\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9396 - val_loss: 0.8249\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9573 - val_loss: 0.8420\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9496 - val_loss: 0.8403\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9428 - val_loss: 0.8237\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.9617 - val_loss: 0.8197\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9457 - val_loss: 0.8169\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9425 - val_loss: 0.8219\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9476 - val_loss: 0.8188\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9208 - val_loss: 0.8124\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9580 - val_loss: 0.8247\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9455 - val_loss: 0.8068\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9333 - val_loss: 0.8065\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.9416 - val_loss: 0.8066\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9600 - val_loss: 0.8226\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9242 - val_loss: 0.7981\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9373 - val_loss: 0.7994\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9380 - val_loss: 0.8166\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9434 - val_loss: 0.7979\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9315 - val_loss: 0.8100\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9230 - val_loss: 0.8025\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9391 - val_loss: 0.8059\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9163 - val_loss: 0.7875\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 0.9216 - val_loss: 0.7977\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9205 - val_loss: 0.7869\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9275 - val_loss: 0.8051\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9489 - val_loss: 0.8021\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9184 - val_loss: 0.7919\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9108 - val_loss: 0.7964\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.9195 - val_loss: 0.7924\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9229 - val_loss: 0.7903\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9233 - val_loss: 0.7788\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9076 - val_loss: 0.7761\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9148 - val_loss: 0.7736\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.9068 - val_loss: 0.7845\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9160 - val_loss: 0.7887\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9222 - val_loss: 0.7913\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9046 - val_loss: 0.7785\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9027 - val_loss: 0.7762\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9113 - val_loss: 0.7726\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8921 - val_loss: 0.7713\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8991 - val_loss: 0.7832\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9016 - val_loss: 0.7793\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9158 - val_loss: 0.7699\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8895 - val_loss: 0.7657\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8870 - val_loss: 0.7613\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9112 - val_loss: 0.7652\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9136 - val_loss: 0.7814\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8928 - val_loss: 0.7791\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8942 - val_loss: 0.7734\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8985 - val_loss: 0.7689\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8927 - val_loss: 0.7709\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 0.8987 - val_loss: 0.7644\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8926 - val_loss: 0.7634\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8783 - val_loss: 0.7694\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8756 - val_loss: 0.7674\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8921 - val_loss: 0.7610\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8880 - val_loss: 0.7709\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8839 - val_loss: 0.7680\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8929 - val_loss: 0.7736\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8896 - val_loss: 0.7696\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8888 - val_loss: 0.7791\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8782 - val_loss: 0.7518\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8955 - val_loss: 0.7729\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8913 - val_loss: 0.7651\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8849 - val_loss: 0.7697\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8671 - val_loss: 0.7639\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8688 - val_loss: 0.7607\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8743 - val_loss: 0.7663\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8738 - val_loss: 0.7665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8813 - val_loss: 0.7692\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8757 - val_loss: 0.7869\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8724 - val_loss: 0.7684\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8763 - val_loss: 0.7700\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8503 - val_loss: 0.7507\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8678 - val_loss: 0.7644\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8778 - val_loss: 0.7543\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8716 - val_loss: 0.7653\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8671 - val_loss: 0.7628\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8531 - val_loss: 0.7671\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8573 - val_loss: 0.7527\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8476 - val_loss: 0.7634\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8412 - val_loss: 0.7475\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8552 - val_loss: 0.7673\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8603 - val_loss: 0.7509\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8498 - val_loss: 0.7502\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8395 - val_loss: 0.7491\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8358 - val_loss: 0.7479\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8541 - val_loss: 0.7449\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8613 - val_loss: 0.7561\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8435 - val_loss: 0.7381\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8388 - val_loss: 0.7550\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8531 - val_loss: 0.7532\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8406 - val_loss: 0.7506\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8350 - val_loss: 0.7583\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8274 - val_loss: 0.7425\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.8279 - val_loss: 0.7394\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8278 - val_loss: 0.7386\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.8381 - val_loss: 0.7353\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8294 - val_loss: 0.7292\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8152 - val_loss: 0.7341\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8195 - val_loss: 0.7415\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8236 - val_loss: 0.7294\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8191 - val_loss: 0.7334\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8315 - val_loss: 0.7286\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8282 - val_loss: 0.7300\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8333 - val_loss: 0.7347\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8383 - val_loss: 0.7348\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8088 - val_loss: 0.7189\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8218 - val_loss: 0.7338\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8041 - val_loss: 0.7259\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8249 - val_loss: 0.7310\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7985 - val_loss: 0.7255\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8118 - val_loss: 0.7347\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8130 - val_loss: 0.7369\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8116 - val_loss: 0.7266\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8097 - val_loss: 0.7216\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8078 - val_loss: 0.7173\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8059 - val_loss: 0.7302\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8188 - val_loss: 0.7332\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8002 - val_loss: 0.7106\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8003 - val_loss: 0.7210\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7963 - val_loss: 0.7078\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8202 - val_loss: 0.7144\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8219 - val_loss: 0.7198\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7856 - val_loss: 0.7153\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7951 - val_loss: 0.7136\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8131 - val_loss: 0.7104\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8152 - val_loss: 0.7105\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7985 - val_loss: 0.7151\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8093 - val_loss: 0.7247\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7790 - val_loss: 0.7198\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7978 - val_loss: 0.7074\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8024 - val_loss: 0.7025\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7643 - val_loss: 0.7109\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7851 - val_loss: 0.7165\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7868 - val_loss: 0.7070\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7819 - val_loss: 0.7064\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7994 - val_loss: 0.7260\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.7639 - val_loss: 0.7116\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7830 - val_loss: 0.7247\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7894 - val_loss: 0.7141\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8037 - val_loss: 0.7119\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7875 - val_loss: 0.7094\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7741 - val_loss: 0.7063\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7964 - val_loss: 0.7079\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7879 - val_loss: 0.7124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7729 - val_loss: 0.7191\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7827 - val_loss: 0.7100\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7890 - val_loss: 0.7141\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7699 - val_loss: 0.7012\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7950 - val_loss: 0.7058\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.7734 - val_loss: 0.7096\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7825 - val_loss: 0.7140\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7766 - val_loss: 0.7028\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7540 - val_loss: 0.6990\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7640 - val_loss: 0.7052\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7810 - val_loss: 0.7112\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7744 - val_loss: 0.7108\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7673 - val_loss: 0.7102\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7658 - val_loss: 0.6942\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7724 - val_loss: 0.7084\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7754 - val_loss: 0.7165\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7531 - val_loss: 0.7000\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7700 - val_loss: 0.7059\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7616 - val_loss: 0.6971\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7722 - val_loss: 0.7005\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7602 - val_loss: 0.7103\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7543 - val_loss: 0.6938\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7653 - val_loss: 0.7095\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7747 - val_loss: 0.6886\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7685 - val_loss: 0.7084\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7699 - val_loss: 0.7062\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7434 - val_loss: 0.6966\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.7548 - val_loss: 0.7072\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7632 - val_loss: 0.7142\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7394 - val_loss: 0.6910\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7610 - val_loss: 0.6973\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7497 - val_loss: 0.7123\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7482 - val_loss: 0.6974\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7594 - val_loss: 0.7082\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7669 - val_loss: 0.7132\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7539 - val_loss: 0.6974\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7553 - val_loss: 0.7013\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7408 - val_loss: 0.6827\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7597 - val_loss: 0.6895\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7458 - val_loss: 0.7133\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7331 - val_loss: 0.6890\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7519 - val_loss: 0.6900\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.7473 - val_loss: 0.6930\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.7516 - val_loss: 0.6975\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7479 - val_loss: 0.6882\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7725 - val_loss: 0.6905\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7698 - val_loss: 0.7009\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7589 - val_loss: 0.6936\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7370 - val_loss: 0.6886\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7442 - val_loss: 0.6984\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7509 - val_loss: 0.7056\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7395 - val_loss: 0.6817\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7450 - val_loss: 0.6997\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7371 - val_loss: 0.6911\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.7494 - val_loss: 0.6854\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7464 - val_loss: 0.6882\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7454 - val_loss: 0.6866\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7388 - val_loss: 0.6885\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7438 - val_loss: 0.6732\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7551 - val_loss: 0.6974\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7406 - val_loss: 0.7014\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7454 - val_loss: 0.6948\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7353 - val_loss: 0.6822\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7348 - val_loss: 0.6891\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7326 - val_loss: 0.6912\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7299 - val_loss: 0.6984\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7445 - val_loss: 0.6831\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7247 - val_loss: 0.6849\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.7355 - val_loss: 0.6846\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7361 - val_loss: 0.6759\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 0.7272 - val_loss: 0.6837\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.7267 - val_loss: 0.6955\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7164 - val_loss: 0.6857\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.7452 - val_loss: 0.6798\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7409 - val_loss: 0.7029\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7419 - val_loss: 0.6760\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.7292 - val_loss: 0.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7381 - val_loss: 0.6850\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.7324 - val_loss: 0.6756\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7130 - val_loss: 0.6759\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7361 - val_loss: 0.6888\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7130 - val_loss: 0.6912\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.6998 - val_loss: 0.6853\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7243 - val_loss: 0.6872\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7363 - val_loss: 0.6795\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.7347 - val_loss: 0.6909\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7066 - val_loss: 0.6849\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7353 - val_loss: 0.6855\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.7119 - val_loss: 0.6930\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.7174 - val_loss: 0.6929\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.7092 - val_loss: 0.6912\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7008 - val_loss: 0.6775\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7262 - val_loss: 0.6824\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.7150 - val_loss: 0.6813\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 421us/sample - loss: 2.2548 - val_loss: 1.6343\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.5671 - val_loss: 1.5469\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.4987 - val_loss: 1.5109\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4725 - val_loss: 1.5005\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4524 - val_loss: 1.4918\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.4478 - val_loss: 1.4830\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4419 - val_loss: 1.4788\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4333 - val_loss: 1.4710\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4240 - val_loss: 1.4631\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4186 - val_loss: 1.4570\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4186 - val_loss: 1.4500\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4055 - val_loss: 1.4412\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3852 - val_loss: 1.4313\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3769 - val_loss: 1.4189\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3698 - val_loss: 1.4102\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.3489 - val_loss: 1.4015\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.3576 - val_loss: 1.3912\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.3420 - val_loss: 1.3838\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3298 - val_loss: 1.3696\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3206 - val_loss: 1.3612\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.3025 - val_loss: 1.3512\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3064 - val_loss: 1.3459\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.2875 - val_loss: 1.3386\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.2954 - val_loss: 1.3233\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2879 - val_loss: 1.3141\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2852 - val_loss: 1.3075\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2703 - val_loss: 1.3007\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.2675 - val_loss: 1.2922\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.2546 - val_loss: 1.2832\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2399 - val_loss: 1.2794\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2462 - val_loss: 1.2684\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2471 - val_loss: 1.2617\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.2250 - val_loss: 1.2545\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2314 - val_loss: 1.2495\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.2192 - val_loss: 1.2367\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2300 - val_loss: 1.2349\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2249 - val_loss: 1.2276\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2260 - val_loss: 1.2218\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2123 - val_loss: 1.2187\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1978 - val_loss: 1.2074\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1858 - val_loss: 1.1991\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.1931 - val_loss: 1.1909\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1744 - val_loss: 1.1863\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1720 - val_loss: 1.1709\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1576 - val_loss: 1.1538\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1673 - val_loss: 1.1506\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1527 - val_loss: 1.1505\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1351 - val_loss: 1.1339\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1499 - val_loss: 1.1263\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1454 - val_loss: 1.1340\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.1129 - val_loss: 1.1176\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1247 - val_loss: 1.1135\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1060 - val_loss: 1.1028\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1213 - val_loss: 1.1058\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1195 - val_loss: 1.0901\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0927 - val_loss: 1.0913\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.0957 - val_loss: 1.0773\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0932 - val_loss: 1.0747\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0869 - val_loss: 1.0725\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0898 - val_loss: 1.0691\n",
      "Epoch 61/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0963 - val_loss: 1.0604\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0963 - val_loss: 1.0580\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0808 - val_loss: 1.0568\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0545 - val_loss: 1.0474\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0688 - val_loss: 1.0396\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0697 - val_loss: 1.0397\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0527 - val_loss: 1.0267\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0517 - val_loss: 1.0248\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0575 - val_loss: 1.0220\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0557 - val_loss: 1.0252\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0324 - val_loss: 1.0095\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0388 - val_loss: 1.0091\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0352 - val_loss: 1.0141\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 1.0415 - val_loss: 1.0068\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0534 - val_loss: 1.0197\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0400 - val_loss: 1.0038\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0378 - val_loss: 1.0019\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0137 - val_loss: 0.9909\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0292 - val_loss: 0.9913\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0255 - val_loss: 1.0023\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0238 - val_loss: 0.9822\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0235 - val_loss: 0.9831\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9910 - val_loss: 0.9784\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.9958 - val_loss: 0.9804\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0092 - val_loss: 0.9662\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0108 - val_loss: 0.9690\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0116 - val_loss: 0.9677\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0107 - val_loss: 0.9804\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9971 - val_loss: 0.9646\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0045 - val_loss: 0.9648\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9968 - val_loss: 0.9487\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9929 - val_loss: 0.9529\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9823 - val_loss: 0.9489\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9808 - val_loss: 0.9551\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9779 - val_loss: 0.9434\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9867 - val_loss: 0.9407\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9849 - val_loss: 0.9338\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9507 - val_loss: 0.9430\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9756 - val_loss: 0.9334\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0012 - val_loss: 0.9415\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9843 - val_loss: 0.9327\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9688 - val_loss: 0.9403\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9777 - val_loss: 0.9305\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9677 - val_loss: 0.9249\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.9649 - val_loss: 0.9148\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9731 - val_loss: 0.9221\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9533 - val_loss: 0.9127\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9584 - val_loss: 0.9130\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9675 - val_loss: 0.9118\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9719 - val_loss: 0.9248\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9762 - val_loss: 0.9112\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9604 - val_loss: 0.9162\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9649 - val_loss: 0.9063\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9775 - val_loss: 0.9107\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9819 - val_loss: 0.9058\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9526 - val_loss: 0.8976\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9643 - val_loss: 0.8968\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9614 - val_loss: 0.9007\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9556 - val_loss: 0.9022\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9558 - val_loss: 0.9019\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9514 - val_loss: 0.8917\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9487 - val_loss: 0.9053\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9486 - val_loss: 0.8881\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9568 - val_loss: 0.8882\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9526 - val_loss: 0.8933\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9639 - val_loss: 0.8922\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9349 - val_loss: 0.8786\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9355 - val_loss: 0.8766\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9460 - val_loss: 0.8794\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9352 - val_loss: 0.8757\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9334 - val_loss: 0.8787\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9487 - val_loss: 0.8804\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9348 - val_loss: 0.8729\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9267 - val_loss: 0.8784\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9226 - val_loss: 0.8677\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9385 - val_loss: 0.8741\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9468 - val_loss: 0.8680\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9234 - val_loss: 0.8601\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9335 - val_loss: 0.8591\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9419 - val_loss: 0.8682\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9199 - val_loss: 0.8682\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9226 - val_loss: 0.8820\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9288 - val_loss: 0.8656\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9300 - val_loss: 0.8579\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9140 - val_loss: 0.8586\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9193 - val_loss: 0.8702\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.9321 - val_loss: 0.8734\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9257 - val_loss: 0.8663\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9102 - val_loss: 0.8657\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9321 - val_loss: 0.8492\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.9159 - val_loss: 0.8479\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9080 - val_loss: 0.8437\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8952 - val_loss: 0.8403\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9183 - val_loss: 0.8476\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9214 - val_loss: 0.8361\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8976 - val_loss: 0.8454\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9364 - val_loss: 0.8374\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8977 - val_loss: 0.8511\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9234 - val_loss: 0.8343\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9092 - val_loss: 0.8415\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8979 - val_loss: 0.8347\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9174 - val_loss: 0.8377\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8916 - val_loss: 0.8330\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8893 - val_loss: 0.8300\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9006 - val_loss: 0.8439\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8949 - val_loss: 0.8370\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 0.8986 - val_loss: 0.8294\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8977 - val_loss: 0.8413\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9026 - val_loss: 0.8317\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9190 - val_loss: 0.8237\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8974 - val_loss: 0.8265\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9079 - val_loss: 0.8222\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9234 - val_loss: 0.8446\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8885 - val_loss: 0.8339\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9077 - val_loss: 0.8255\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9200 - val_loss: 0.8318\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9001 - val_loss: 0.8222\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8900 - val_loss: 0.8184\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8815 - val_loss: 0.8078\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8807 - val_loss: 0.8190\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8910 - val_loss: 0.8118\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8822 - val_loss: 0.8158\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8991 - val_loss: 0.8046\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8883 - val_loss: 0.8112\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9005 - val_loss: 0.8258\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8890 - val_loss: 0.8133\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8924 - val_loss: 0.8087\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8933 - val_loss: 0.8081\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8788 - val_loss: 0.8106\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8916 - val_loss: 0.8144\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9205 - val_loss: 0.8123\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8738 - val_loss: 0.8151\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8932 - val_loss: 0.8067\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8709 - val_loss: 0.7972\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8836 - val_loss: 0.8047\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8882 - val_loss: 0.8040\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8738 - val_loss: 0.8182\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8739 - val_loss: 0.8062\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8789 - val_loss: 0.8052\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8641 - val_loss: 0.8007\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8617 - val_loss: 0.8040\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8671 - val_loss: 0.7924\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 0.8696 - val_loss: 0.7991\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8682 - val_loss: 0.7887\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8723 - val_loss: 0.7876\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8552 - val_loss: 0.7909\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8625 - val_loss: 0.7873\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8728 - val_loss: 0.7932\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8714 - val_loss: 0.7977\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8775 - val_loss: 0.7953\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8830 - val_loss: 0.7893\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8691 - val_loss: 0.7939\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8570 - val_loss: 0.7944\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8554 - val_loss: 0.7816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8506 - val_loss: 0.7847\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8743 - val_loss: 0.7884\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8674 - val_loss: 0.7998\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.8748 - val_loss: 0.7916\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8860 - val_loss: 0.7897\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8394 - val_loss: 0.7861\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8629 - val_loss: 0.7833\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8568 - val_loss: 0.7929\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.8602 - val_loss: 0.7831\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8531 - val_loss: 0.7781\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8613 - val_loss: 0.7813\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8659 - val_loss: 0.7833\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8578 - val_loss: 0.7807\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8630 - val_loss: 0.7699\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8557 - val_loss: 0.7732\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8442 - val_loss: 0.7804\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8721 - val_loss: 0.7798\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8517 - val_loss: 0.7937\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8713 - val_loss: 0.7804\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8461 - val_loss: 0.7776\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8596 - val_loss: 0.7827\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8534 - val_loss: 0.7872\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8647 - val_loss: 0.7709\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8439 - val_loss: 0.7799\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8452 - val_loss: 0.7671\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8448 - val_loss: 0.7628\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8566 - val_loss: 0.7750\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8548 - val_loss: 0.7710\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8654 - val_loss: 0.7737\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8394 - val_loss: 0.7682\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.8485 - val_loss: 0.7659\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8664 - val_loss: 0.7734\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8477 - val_loss: 0.7678\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8270 - val_loss: 0.7593\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8571 - val_loss: 0.7629\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8382 - val_loss: 0.7674\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8416 - val_loss: 0.7583\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8436 - val_loss: 0.7659\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8388 - val_loss: 0.7533\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8421 - val_loss: 0.7809\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 0.8494 - val_loss: 0.7603\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8357 - val_loss: 0.7668\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8317 - val_loss: 0.7572\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8230 - val_loss: 0.7486\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8379 - val_loss: 0.7505\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8376 - val_loss: 0.7522\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8520 - val_loss: 0.7658\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8186 - val_loss: 0.7620\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8316 - val_loss: 0.7489\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8134 - val_loss: 0.7518\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8217 - val_loss: 0.7495\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.8140 - val_loss: 0.7494\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.8231 - val_loss: 0.7480\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8132 - val_loss: 0.7474\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8228 - val_loss: 0.7463\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8294 - val_loss: 0.7498\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8230 - val_loss: 0.7516\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 0.8294 - val_loss: 0.7437\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8309 - val_loss: 0.7430\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8255 - val_loss: 0.7454\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8354 - val_loss: 0.7545\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8454 - val_loss: 0.7565\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8378 - val_loss: 0.7484\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8234 - val_loss: 0.7444\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8208 - val_loss: 0.7592\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8371 - val_loss: 0.7542\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8274 - val_loss: 0.7512\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.8352 - val_loss: 0.7561\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8304 - val_loss: 0.7736\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8086 - val_loss: 0.7593\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8150 - val_loss: 0.7469\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8209 - val_loss: 0.7421\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8179 - val_loss: 0.7445\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8292 - val_loss: 0.7509\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8200 - val_loss: 0.7415\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8031 - val_loss: 0.7358\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8251 - val_loss: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 0.8164 - val_loss: 0.7404\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.7940 - val_loss: 0.7446\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8222 - val_loss: 0.7367\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8268 - val_loss: 0.7522\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8247 - val_loss: 0.7387\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8266 - val_loss: 0.7460\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7929 - val_loss: 0.7406\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8220 - val_loss: 0.7397\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8287 - val_loss: 0.7486\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8001 - val_loss: 0.7537\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8395 - val_loss: 0.7444\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8169 - val_loss: 0.7500\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8118 - val_loss: 0.7408\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 0.8045 - val_loss: 0.7432\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 0.8146 - val_loss: 0.7417\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8335 - val_loss: 0.7429\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8282 - val_loss: 0.7407\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8224 - val_loss: 0.7472\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8190 - val_loss: 0.7439\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8170 - val_loss: 0.7389\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.7981 - val_loss: 0.7470\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.7991 - val_loss: 0.7455\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7962 - val_loss: 0.7362\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 0.8073 - val_loss: 0.7584\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8014 - val_loss: 0.7445\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8044 - val_loss: 0.7468\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8184 - val_loss: 0.7371\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8273 - val_loss: 0.7373\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.7984 - val_loss: 0.7374\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8132 - val_loss: 0.7462\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.8138 - val_loss: 0.7458\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8005 - val_loss: 0.7492\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8142 - val_loss: 0.7307\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.8158 - val_loss: 0.7475\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8119 - val_loss: 0.7368\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8179 - val_loss: 0.7321\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8243 - val_loss: 0.7487\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.7796 - val_loss: 0.7397\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8010 - val_loss: 0.7390\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8191 - val_loss: 0.7346\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8174 - val_loss: 0.7361\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8052 - val_loss: 0.7364\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8254 - val_loss: 0.7426\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8149 - val_loss: 0.7365\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 0.7998 - val_loss: 0.7330\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.7830 - val_loss: 0.7246\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.8051 - val_loss: 0.7245\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8003 - val_loss: 0.7337\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8073 - val_loss: 0.7270\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 399us/sample - loss: 3.1263 - val_loss: 1.8496\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 1.9506 - val_loss: 1.7703\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.7980 - val_loss: 1.6521\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.6824 - val_loss: 1.5909\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6373 - val_loss: 1.5612\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6070 - val_loss: 1.5337\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5770 - val_loss: 1.5219\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5713 - val_loss: 1.5180\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.5628 - val_loss: 1.5063\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5471 - val_loss: 1.4687\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5350 - val_loss: 1.4550\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5273 - val_loss: 1.4349\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.5062 - val_loss: 1.4030\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.4991 - val_loss: 1.4074\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4910 - val_loss: 1.3871\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4725 - val_loss: 1.3670\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4532 - val_loss: 1.3513\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4347 - val_loss: 1.3357\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 1.4359 - val_loss: 1.3333\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4285 - val_loss: 1.3123\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4137 - val_loss: 1.3151\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4011 - val_loss: 1.2837\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4015 - val_loss: 1.2918\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.3935 - val_loss: 1.2738\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.3657 - val_loss: 1.2560\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.3495 - val_loss: 1.2429\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3506 - val_loss: 1.2292\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3409 - val_loss: 1.2226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3432 - val_loss: 1.2271\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3206 - val_loss: 1.2067\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3087 - val_loss: 1.1945\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.2957 - val_loss: 1.2199\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2996 - val_loss: 1.1792\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2985 - val_loss: 1.1786\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2845 - val_loss: 1.1631\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2768 - val_loss: 1.1520\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.2848 - val_loss: 1.1486\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.2596 - val_loss: 1.1392\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2698 - val_loss: 1.1344\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.2444 - val_loss: 1.1216\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2408 - val_loss: 1.1183\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2471 - val_loss: 1.1199\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2436 - val_loss: 1.1127\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2175 - val_loss: 1.1146\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.2290 - val_loss: 1.1023\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.2157 - val_loss: 1.1133\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2029 - val_loss: 1.0999\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2031 - val_loss: 1.0830\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1917 - val_loss: 1.0815\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2000 - val_loss: 1.0818\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1811 - val_loss: 1.0666\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1863 - val_loss: 1.0704\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1676 - val_loss: 1.0712\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1768 - val_loss: 1.0622\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.1730 - val_loss: 1.0532\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1640 - val_loss: 1.0543\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.1465 - val_loss: 1.0609\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1271 - val_loss: 1.0500\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1435 - val_loss: 1.0457\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1437 - val_loss: 1.0467\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1395 - val_loss: 1.0429\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.1463 - val_loss: 1.0332\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1300 - val_loss: 1.0464\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1224 - val_loss: 1.0443\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1243 - val_loss: 1.0160\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1275 - val_loss: 1.0289\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1212 - val_loss: 1.0202\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.1372 - val_loss: 1.0257\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1163 - val_loss: 1.0252\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1114 - val_loss: 1.0275\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1155 - val_loss: 1.0182\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1076 - val_loss: 1.0132\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1047 - val_loss: 1.0138\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.1068 - val_loss: 1.0091\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.1008 - val_loss: 1.0149\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0850 - val_loss: 1.0114\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0865 - val_loss: 0.9936\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1020 - val_loss: 1.0175\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0952 - val_loss: 0.9958\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0917 - val_loss: 0.9973\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0870 - val_loss: 0.9977\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0738 - val_loss: 1.0085\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0665 - val_loss: 1.0096\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0600 - val_loss: 0.9926\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0750 - val_loss: 1.0034\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0774 - val_loss: 0.9845\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0704 - val_loss: 0.9778\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0686 - val_loss: 0.9870\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.0522 - val_loss: 0.9664\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0580 - val_loss: 0.9879\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0544 - val_loss: 0.9970\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0722 - val_loss: 0.9723\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.0343 - val_loss: 0.9724\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0563 - val_loss: 0.9650\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0554 - val_loss: 0.9734\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0320 - val_loss: 0.9719\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0387 - val_loss: 0.9656\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0403 - val_loss: 0.9802\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0441 - val_loss: 0.9701\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0594 - val_loss: 0.9821\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0360 - val_loss: 0.9769\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0436 - val_loss: 0.9727\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0264 - val_loss: 0.9752\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.0493 - val_loss: 0.9701\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.0359 - val_loss: 0.9707\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.0435 - val_loss: 0.9516\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.0316 - val_loss: 0.9583\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0247 - val_loss: 0.9563\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0471 - val_loss: 0.9650\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0155 - val_loss: 0.9544\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0305 - val_loss: 0.9790\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0330 - val_loss: 0.9604\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0179 - val_loss: 0.9540\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.0348 - val_loss: 0.9488\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0203 - val_loss: 0.9503\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0430 - val_loss: 0.9496\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0059 - val_loss: 0.9544\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0142 - val_loss: 0.9467\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0157 - val_loss: 0.9488\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0106 - val_loss: 0.9435\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0143 - val_loss: 0.9394\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0212 - val_loss: 0.9422\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9954 - val_loss: 0.9320\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0042 - val_loss: 0.9373\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0065 - val_loss: 0.9441\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0158 - val_loss: 0.9499\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0057 - val_loss: 0.9369\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0223 - val_loss: 0.9584\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9893 - val_loss: 0.9511\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.0214 - val_loss: 0.9363\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0004 - val_loss: 0.9352\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0091 - val_loss: 0.9304\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0013 - val_loss: 0.9506\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0240 - val_loss: 0.9264\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0000 - val_loss: 0.9180\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9824 - val_loss: 0.9297\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9823 - val_loss: 0.9204\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0014 - val_loss: 0.9316\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9878 - val_loss: 0.9208\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9905 - val_loss: 0.9240\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0029 - val_loss: 0.9199\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9961 - val_loss: 0.9107\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9710 - val_loss: 0.9099\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9807 - val_loss: 0.9112\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9578 - val_loss: 0.9136\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9699 - val_loss: 0.9099\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9859 - val_loss: 0.9253\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9719 - val_loss: 0.9057\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9652 - val_loss: 0.9086\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9819 - val_loss: 0.9060\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9622 - val_loss: 0.9082\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9681 - val_loss: 0.9081\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9947 - val_loss: 0.9175\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9613 - val_loss: 0.9131\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9814 - val_loss: 0.9034\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9550 - val_loss: 0.9044\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9731 - val_loss: 0.9087\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9570 - val_loss: 0.9075\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 0.9677 - val_loss: 0.8884\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9439 - val_loss: 0.8964\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9858 - val_loss: 0.9065\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9588 - val_loss: 0.9029\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9438 - val_loss: 0.9099\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9751 - val_loss: 0.8998\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9599 - val_loss: 0.8992\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9652 - val_loss: 0.8951\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9424 - val_loss: 0.9142\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9582 - val_loss: 0.8944\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9698 - val_loss: 0.9065\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9683 - val_loss: 0.8916\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.9531 - val_loss: 0.9008\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9284 - val_loss: 0.8840\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9433 - val_loss: 0.8838\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9382 - val_loss: 0.8949\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9384 - val_loss: 0.8831\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9523 - val_loss: 0.8747\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9387 - val_loss: 0.8832\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.9284 - val_loss: 0.9068\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9517 - val_loss: 0.8863\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 0.9559 - val_loss: 0.8913\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9294 - val_loss: 0.8816\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9394 - val_loss: 0.8786\n",
      "Epoch 183/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9378 - val_loss: 0.8793\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9395 - val_loss: 0.9048\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9363 - val_loss: 0.8864\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9320 - val_loss: 0.8766\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9173 - val_loss: 0.8807\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9475 - val_loss: 0.8704\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9487 - val_loss: 0.8798\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9092 - val_loss: 0.8668\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9352 - val_loss: 0.8713\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9119 - val_loss: 0.8719\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9159 - val_loss: 0.8602\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9469 - val_loss: 0.8621\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9449 - val_loss: 0.8719\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9224 - val_loss: 0.8683\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9376 - val_loss: 0.8790\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9224 - val_loss: 0.8650\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9112 - val_loss: 0.8670\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9170 - val_loss: 0.8879\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9302 - val_loss: 0.8644\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9154 - val_loss: 0.8721\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9420 - val_loss: 0.8699\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9172 - val_loss: 0.8571\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9126 - val_loss: 0.8639\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9159 - val_loss: 0.8546\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9399 - val_loss: 0.8763\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.9078 - val_loss: 0.8803\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9229 - val_loss: 0.8631\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9054 - val_loss: 0.8494\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9312 - val_loss: 0.8725\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9125 - val_loss: 0.8623\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9150 - val_loss: 0.8589\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9096 - val_loss: 0.8755\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9077 - val_loss: 0.8531\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 0.9263 - val_loss: 0.8596\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 0.8991 - val_loss: 0.8540\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9268 - val_loss: 0.8586\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9265 - val_loss: 0.8543\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9044 - val_loss: 0.8710\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9111 - val_loss: 0.8441\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9057 - val_loss: 0.8656\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.9205 - val_loss: 0.8705\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8943 - val_loss: 0.8605\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9293 - val_loss: 0.8609\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9090 - val_loss: 0.8535\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8886 - val_loss: 0.8557\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8999 - val_loss: 0.8382\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9274 - val_loss: 0.8568\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9089 - val_loss: 0.8396\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8898 - val_loss: 0.8409\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8918 - val_loss: 0.8519\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9002 - val_loss: 0.8445\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9133 - val_loss: 0.8512\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9229 - val_loss: 0.8550\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9085 - val_loss: 0.8427\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9049 - val_loss: 0.8481\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9100 - val_loss: 0.8379\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9213 - val_loss: 0.8538\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8781 - val_loss: 0.8432\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8912 - val_loss: 0.8489\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8859 - val_loss: 0.8572\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9280 - val_loss: 0.8562\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8893 - val_loss: 0.8371\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9002 - val_loss: 0.8369\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9003 - val_loss: 0.8424\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9091 - val_loss: 0.8548\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9237 - val_loss: 0.8497\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9049 - val_loss: 0.8364\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8756 - val_loss: 0.8436\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9091 - val_loss: 0.8433\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 0.9193 - val_loss: 0.8422\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.9210 - val_loss: 0.8408\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 0.9063 - val_loss: 0.8475\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8949 - val_loss: 0.8462\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 0.9156 - val_loss: 0.8631\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8987 - val_loss: 0.8330\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8841 - val_loss: 0.8469\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9207 - val_loss: 0.8540\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9027 - val_loss: 0.8432\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.8894 - val_loss: 0.8371\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8849 - val_loss: 0.8474\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8885 - val_loss: 0.8587\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8669 - val_loss: 0.8286\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9141 - val_loss: 0.8309\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8876 - val_loss: 0.8355\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8892 - val_loss: 0.8386\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8885 - val_loss: 0.8284\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8915 - val_loss: 0.8358\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8869 - val_loss: 0.8382\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 0.8922 - val_loss: 0.8500\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8848 - val_loss: 0.8289\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8944 - val_loss: 0.8231\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8833 - val_loss: 0.8501\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8899 - val_loss: 0.8378\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.8841 - val_loss: 0.8280\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8822 - val_loss: 0.8379\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8707 - val_loss: 0.8397\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8598 - val_loss: 0.8395\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9120 - val_loss: 0.8584\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8825 - val_loss: 0.8274\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8975 - val_loss: 0.8308\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8635 - val_loss: 0.8222\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8612 - val_loss: 0.8246\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8951 - val_loss: 0.8306\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 0.8754 - val_loss: 0.8332\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8896 - val_loss: 0.8261\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9030 - val_loss: 0.8372\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8645 - val_loss: 0.8292\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8863 - val_loss: 0.8339\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8924 - val_loss: 0.8287\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8935 - val_loss: 0.8399\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8988 - val_loss: 0.8328\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8661 - val_loss: 0.8305\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8850 - val_loss: 0.8256\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8730 - val_loss: 0.8328\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8737 - val_loss: 0.8339\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.8872 - val_loss: 0.8270\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8865 - val_loss: 0.8352\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9113 - val_loss: 0.8257\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8739 - val_loss: 0.8312\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8681 - val_loss: 0.8241\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.8703 - val_loss: 0.8279\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8725 - val_loss: 0.8438\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8960 - val_loss: 0.8309\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8958 - val_loss: 0.8323\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8693 - val_loss: 0.8206\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8765 - val_loss: 0.8312\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 0.8661 - val_loss: 0.8228\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 69us/sample - loss: 0.8737 - val_loss: 0.8350\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8621 - val_loss: 0.8266\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8736 - val_loss: 0.8367\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8679 - val_loss: 0.8281\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8823 - val_loss: 0.8332\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8780 - val_loss: 0.8311\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.8771 - val_loss: 0.8209\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8514 - val_loss: 0.8276\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9036 - val_loss: 0.8305\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8683 - val_loss: 0.8369\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9155 - val_loss: 0.8333\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8980 - val_loss: 0.8309\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8760 - val_loss: 0.8420\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8655 - val_loss: 0.8288\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8333 - val_loss: 0.8234\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8728 - val_loss: 0.8217\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8619 - val_loss: 0.8200\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.8595 - val_loss: 0.8228\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.8723 - val_loss: 0.8150\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8670 - val_loss: 0.8181\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.8717 - val_loss: 0.8218\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.8760 - val_loss: 0.8107\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8680 - val_loss: 0.8020\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.8674 - val_loss: 0.8207\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 0.8788 - val_loss: 0.8179\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.8440 - val_loss: 0.8150\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 0.8636 - val_loss: 0.8316\n",
      "Epoch 337/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8656 - val_loss: 0.8196\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.8795 - val_loss: 0.8184\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.8744 - val_loss: 0.8190\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.8665 - val_loss: 0.8168\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 402us/sample - loss: 3.7826 - val_loss: 2.5854\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 2.1546 - val_loss: 2.0631\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.8902 - val_loss: 1.8957\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8356 - val_loss: 1.8484\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8191 - val_loss: 1.8252\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8124 - val_loss: 1.8131\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8027 - val_loss: 1.8069\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7961 - val_loss: 1.7970\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7894 - val_loss: 1.7928\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7830 - val_loss: 1.7847\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7750 - val_loss: 1.7769\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7687 - val_loss: 1.7697\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7604 - val_loss: 1.7641\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7531 - val_loss: 1.7575\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7482 - val_loss: 1.7524\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.7416 - val_loss: 1.7473\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7341 - val_loss: 1.7407\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7296 - val_loss: 1.7339\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7237 - val_loss: 1.7307\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7176 - val_loss: 1.7280\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7125 - val_loss: 1.7190\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.7063 - val_loss: 1.7142\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.7014 - val_loss: 1.7112\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6966 - val_loss: 1.7029\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6899 - val_loss: 1.6999\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6859 - val_loss: 1.6913\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6797 - val_loss: 1.6871\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6739 - val_loss: 1.6865\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6690 - val_loss: 1.6861\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6655 - val_loss: 1.6750\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.6600 - val_loss: 1.6729\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6531 - val_loss: 1.6649\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6511 - val_loss: 1.6616\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6446 - val_loss: 1.6605\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6402 - val_loss: 1.6602\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6378 - val_loss: 1.6521\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6308 - val_loss: 1.6540\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6264 - val_loss: 1.6383\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6238 - val_loss: 1.6338\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6204 - val_loss: 1.6370\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6126 - val_loss: 1.6284\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6073 - val_loss: 1.6189\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6063 - val_loss: 1.6181\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5968 - val_loss: 1.6062\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5976 - val_loss: 1.6018\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5920 - val_loss: 1.5923\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5862 - val_loss: 1.5859\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5828 - val_loss: 1.5794\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5741 - val_loss: 1.5741\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5746 - val_loss: 1.5736\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5653 - val_loss: 1.5644\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5635 - val_loss: 1.5569\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5555 - val_loss: 1.5516\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.5472 - val_loss: 1.5465\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5499 - val_loss: 1.5440\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.5379 - val_loss: 1.5261\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5324 - val_loss: 1.5204\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5306 - val_loss: 1.5149\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5198 - val_loss: 1.5062\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5094 - val_loss: 1.5023\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5096 - val_loss: 1.4939\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5005 - val_loss: 1.4879\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4930 - val_loss: 1.4794\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.4915 - val_loss: 1.4710\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4888 - val_loss: 1.4683\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4761 - val_loss: 1.4514\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4612 - val_loss: 1.4411\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4557 - val_loss: 1.4335\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4474 - val_loss: 1.4201\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.4417 - val_loss: 1.4198\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4317 - val_loss: 1.4014\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4240 - val_loss: 1.3986\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4070 - val_loss: 1.3768\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4110 - val_loss: 1.3789\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4019 - val_loss: 1.3676\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3889 - val_loss: 1.3725\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3814 - val_loss: 1.3528\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3826 - val_loss: 1.3467\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3807 - val_loss: 1.3461\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3721 - val_loss: 1.3343\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3493 - val_loss: 1.3273\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3570 - val_loss: 1.3305\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3458 - val_loss: 1.3122\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3290 - val_loss: 1.3040\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3342 - val_loss: 1.3037\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3197 - val_loss: 1.2898\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3153 - val_loss: 1.2820\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.3123 - val_loss: 1.2820\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3021 - val_loss: 1.2779\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2991 - val_loss: 1.2895\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3067 - val_loss: 1.2685\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3105 - val_loss: 1.2669\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2845 - val_loss: 1.2709\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2862 - val_loss: 1.2511\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2659 - val_loss: 1.2543\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.2764 - val_loss: 1.2482\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2696 - val_loss: 1.2412\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2769 - val_loss: 1.2416\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2713 - val_loss: 1.2387\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 1.2542 - val_loss: 1.2205\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.2546 - val_loss: 1.2210\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2571 - val_loss: 1.2166\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.2488 - val_loss: 1.2047\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2385 - val_loss: 1.2098\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.2421 - val_loss: 1.1954\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.2493 - val_loss: 1.2188\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.2366 - val_loss: 1.1875\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.2302 - val_loss: 1.1923\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2329 - val_loss: 1.1884\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.2208 - val_loss: 1.1794\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.2261 - val_loss: 1.1866\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.2152 - val_loss: 1.1793\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2119 - val_loss: 1.1701\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.2216 - val_loss: 1.1657\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2103 - val_loss: 1.1681\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2084 - val_loss: 1.1596\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1907 - val_loss: 1.1562\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1907 - val_loss: 1.1556\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1780 - val_loss: 1.1573\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1965 - val_loss: 1.1502\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1942 - val_loss: 1.1485\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1709 - val_loss: 1.1445\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1806 - val_loss: 1.1507\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.1810 - val_loss: 1.1348\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1740 - val_loss: 1.1293\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1633 - val_loss: 1.1288\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1741 - val_loss: 1.1333\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1755 - val_loss: 1.1189\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1693 - val_loss: 1.1352\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1750 - val_loss: 1.1286\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.1548 - val_loss: 1.1213\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1513 - val_loss: 1.1252\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1514 - val_loss: 1.1091\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1509 - val_loss: 1.1133\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1545 - val_loss: 1.1078\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1417 - val_loss: 1.1056\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1508 - val_loss: 1.1080\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1407 - val_loss: 1.1147\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1506 - val_loss: 1.0963\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1435 - val_loss: 1.1030\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1358 - val_loss: 1.1100\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1344 - val_loss: 1.0999\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1342 - val_loss: 1.0918\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1291 - val_loss: 1.0993\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1412 - val_loss: 1.0948\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1181 - val_loss: 1.0891\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1205 - val_loss: 1.0869\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1381 - val_loss: 1.0834\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1237 - val_loss: 1.0831\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1187 - val_loss: 1.0889\n",
      "Epoch 151/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1157 - val_loss: 1.0949\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1122 - val_loss: 1.0810\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1118 - val_loss: 1.0787\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1170 - val_loss: 1.0848\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1232 - val_loss: 1.0798\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.1043 - val_loss: 1.0643\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1071 - val_loss: 1.0680\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1109 - val_loss: 1.0622\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0947 - val_loss: 1.0653\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1066 - val_loss: 1.0766\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1224 - val_loss: 1.0679\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1123 - val_loss: 1.0861\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1009 - val_loss: 1.0682\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1013 - val_loss: 1.0586\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0978 - val_loss: 1.0593\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1035 - val_loss: 1.0617\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1086 - val_loss: 1.0756\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1002 - val_loss: 1.0717\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1079 - val_loss: 1.0538\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0924 - val_loss: 1.0480\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.1105 - val_loss: 1.0560\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0994 - val_loss: 1.0509\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1018 - val_loss: 1.0602\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0950 - val_loss: 1.0524\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0940 - val_loss: 1.0650\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0911 - val_loss: 1.0594\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0917 - val_loss: 1.0581\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1019 - val_loss: 1.0530\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0764 - val_loss: 1.0403\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.0767 - val_loss: 1.0675\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.0751 - val_loss: 1.0503\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0739 - val_loss: 1.0349\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0740 - val_loss: 1.0462\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0750 - val_loss: 1.0463\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0746 - val_loss: 1.0552\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0849 - val_loss: 1.0547\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0683 - val_loss: 1.0595\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0632 - val_loss: 1.0429\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0709 - val_loss: 1.0413\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0712 - val_loss: 1.0363\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.0716 - val_loss: 1.0428\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0593 - val_loss: 1.0410\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0680 - val_loss: 1.0365\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.0741 - val_loss: 1.0435\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0583 - val_loss: 1.0505\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0754 - val_loss: 1.0464\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.0721 - val_loss: 1.0303\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0780 - val_loss: 1.0488\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.0676 - val_loss: 1.0417\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0692 - val_loss: 1.0308\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0538 - val_loss: 1.0384\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0678 - val_loss: 1.0301\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0594 - val_loss: 1.0411\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0661 - val_loss: 1.0380\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0581 - val_loss: 1.0303\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0637 - val_loss: 1.0272\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0532 - val_loss: 1.0289\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0739 - val_loss: 1.0133\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0451 - val_loss: 1.0342\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0547 - val_loss: 1.0170\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0652 - val_loss: 1.0347\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0534 - val_loss: 1.0191\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0437 - val_loss: 1.0254\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0425 - val_loss: 1.0143\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0556 - val_loss: 1.0225\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.0616 - val_loss: 1.0099\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0425 - val_loss: 1.0239\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0458 - val_loss: 1.0132\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0355 - val_loss: 1.0193\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0615 - val_loss: 1.0178\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0467 - val_loss: 1.0181\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0372 - val_loss: 1.0134\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0414 - val_loss: 1.0233\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0461 - val_loss: 1.0146\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.0466 - val_loss: 1.0180\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0314 - val_loss: 1.0075\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0486 - val_loss: 1.0225\n",
      "Epoch 228/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0498 - val_loss: 1.0122\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.0407 - val_loss: 1.0242\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0207 - val_loss: 1.0158\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0500 - val_loss: 1.0243\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0308 - val_loss: 1.0159\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0398 - val_loss: 1.0140\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0157 - val_loss: 1.0055\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0209 - val_loss: 1.0021\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0426 - val_loss: 1.0028\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0332 - val_loss: 1.0149\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0235 - val_loss: 1.0081\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0413 - val_loss: 1.0142\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0378 - val_loss: 0.9998\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0265 - val_loss: 1.0025\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0234 - val_loss: 1.0159\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0348 - val_loss: 1.0156\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0279 - val_loss: 1.0163\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0107 - val_loss: 1.0193\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0249 - val_loss: 1.0079\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0484 - val_loss: 1.0045\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.0266 - val_loss: 1.0054\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0371 - val_loss: 1.0002\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0164 - val_loss: 1.0047\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0220 - val_loss: 0.9907\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0237 - val_loss: 0.9878\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0171 - val_loss: 1.0086\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0145 - val_loss: 0.9892\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0281 - val_loss: 0.9883\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0219 - val_loss: 0.9856\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0158 - val_loss: 0.9931\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0362 - val_loss: 0.9878\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0300 - val_loss: 0.9959\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0340 - val_loss: 1.0023\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0120 - val_loss: 0.9915\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0142 - val_loss: 1.0093\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0180 - val_loss: 1.0014\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0157 - val_loss: 0.9816\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0279 - val_loss: 0.9995\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0296 - val_loss: 0.9840\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0206 - val_loss: 0.9915\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0098 - val_loss: 0.9978\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0128 - val_loss: 0.9807\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.0075 - val_loss: 0.9903\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0094 - val_loss: 0.9958\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.0203 - val_loss: 0.9935\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0324 - val_loss: 0.9801\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9969 - val_loss: 0.9869\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0207 - val_loss: 0.9841\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9985 - val_loss: 0.9853\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0118 - val_loss: 0.9995\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0227 - val_loss: 0.9821\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0299 - val_loss: 0.9775\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 1.0062 - val_loss: 0.9857\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9931 - val_loss: 0.9663\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.0214 - val_loss: 0.9922\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9931 - val_loss: 0.9803\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0036 - val_loss: 0.9912\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0138 - val_loss: 0.9786\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0239 - val_loss: 0.9709\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.0150 - val_loss: 0.9771\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0177 - val_loss: 0.9702\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0161 - val_loss: 0.9702\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0039 - val_loss: 0.9836\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 0.9989 - val_loss: 0.9752\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0089 - val_loss: 0.9850\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0180 - val_loss: 0.9726\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0146 - val_loss: 0.9729\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 110us/sample - loss: 1.0305 - val_loss: 0.9763\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9847 - val_loss: 0.9725\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9933 - val_loss: 0.9683\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9911 - val_loss: 0.9893\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9848 - val_loss: 0.9776\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0002 - val_loss: 0.9551\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9925 - val_loss: 0.9769\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9981 - val_loss: 0.9642\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9887 - val_loss: 0.9628\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9953 - val_loss: 0.9830\n",
      "Epoch 305/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9942 - val_loss: 0.9776\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9863 - val_loss: 0.9609\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9961 - val_loss: 0.9604\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9981 - val_loss: 0.9677\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9771 - val_loss: 0.9587\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0037 - val_loss: 0.9661\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9831 - val_loss: 0.9613\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9975 - val_loss: 0.9557\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9837 - val_loss: 0.9697\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 0.9970 - val_loss: 0.9681\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 0.9869 - val_loss: 0.9587\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9888 - val_loss: 0.9635\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9767 - val_loss: 0.9796\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9908 - val_loss: 0.9613\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9912 - val_loss: 0.9717\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9860 - val_loss: 0.9554\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9932 - val_loss: 0.9544\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 0.9943 - val_loss: 0.9444\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9835 - val_loss: 0.9558\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9902 - val_loss: 0.9556\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9698 - val_loss: 0.9613\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 0.9740 - val_loss: 0.9549\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9841 - val_loss: 0.9597\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9673 - val_loss: 0.9618\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9991 - val_loss: 0.9584\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 0.9915 - val_loss: 0.9546\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 0.9842 - val_loss: 0.9652\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 0.9924 - val_loss: 0.9582\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 0.9677 - val_loss: 0.9567\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 0.9821 - val_loss: 0.9551\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 0.9814 - val_loss: 0.9461\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9729 - val_loss: 0.9526\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 0.9632 - val_loss: 0.9629\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 0.9706 - val_loss: 0.9814\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 0.9672 - val_loss: 0.9514\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0009 - val_loss: 0.9542\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 391us/sample - loss: 4.5632 - val_loss: 2.6873\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 3.2655 - val_loss: 2.5564\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.0851 - val_loss: 2.5006\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.8612 - val_loss: 2.3808\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.6818 - val_loss: 2.2968\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 2.5851 - val_loss: 2.2143\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4088 - val_loss: 2.1468\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.3235 - val_loss: 2.1055\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.1643 - val_loss: 2.0250\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.1052 - val_loss: 1.9827\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0475 - val_loss: 1.9314\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0084 - val_loss: 1.9080\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9643 - val_loss: 1.8807\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.9157 - val_loss: 1.8616\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8846 - val_loss: 1.8375\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8799 - val_loss: 1.8049\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8495 - val_loss: 1.7893\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8450 - val_loss: 1.7702\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8409 - val_loss: 1.7541\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8083 - val_loss: 1.7332\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.7931 - val_loss: 1.7277\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7977 - val_loss: 1.7104\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.7748 - val_loss: 1.7038\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7737 - val_loss: 1.6923\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.7447 - val_loss: 1.6760\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.7345 - val_loss: 1.6637\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.7291 - val_loss: 1.6441\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7325 - val_loss: 1.6383\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7184 - val_loss: 1.6384\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6990 - val_loss: 1.6339\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.6909 - val_loss: 1.6138\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6884 - val_loss: 1.6022\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.6792 - val_loss: 1.5997\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6765 - val_loss: 1.5869\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6739 - val_loss: 1.5770\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6550 - val_loss: 1.5698\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6522 - val_loss: 1.5597\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6455 - val_loss: 1.5634\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.6393 - val_loss: 1.5450\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6409 - val_loss: 1.5435\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.6190 - val_loss: 1.5278\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6175 - val_loss: 1.5221\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6111 - val_loss: 1.5054\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6121 - val_loss: 1.5131\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5920 - val_loss: 1.4985\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5544 - val_loss: 1.4806\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5900 - val_loss: 1.4740\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5499 - val_loss: 1.4655\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5698 - val_loss: 1.4622\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.5483 - val_loss: 1.4616\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5446 - val_loss: 1.4516\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5322 - val_loss: 1.4336\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5368 - val_loss: 1.4334\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5307 - val_loss: 1.4225\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5283 - val_loss: 1.4233\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5131 - val_loss: 1.4205\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5056 - val_loss: 1.4139\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5211 - val_loss: 1.4167\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5030 - val_loss: 1.4038\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4938 - val_loss: 1.3925\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4963 - val_loss: 1.3940\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5018 - val_loss: 1.3867\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4928 - val_loss: 1.3802\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4807 - val_loss: 1.3687\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4954 - val_loss: 1.3616\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4736 - val_loss: 1.3638\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4746 - val_loss: 1.3586\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4539 - val_loss: 1.3492\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4631 - val_loss: 1.3563\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4465 - val_loss: 1.3393\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4237 - val_loss: 1.3425\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4540 - val_loss: 1.3424\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4425 - val_loss: 1.3426\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.4322 - val_loss: 1.3280\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4394 - val_loss: 1.3337\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4165 - val_loss: 1.3142\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4265 - val_loss: 1.3204\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4051 - val_loss: 1.3078\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4157 - val_loss: 1.3080\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.4011 - val_loss: 1.3060\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.3972 - val_loss: 1.2992\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3967 - val_loss: 1.2950\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4118 - val_loss: 1.2921\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.3853 - val_loss: 1.2880\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4062 - val_loss: 1.2892\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.3818 - val_loss: 1.2784\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.3828 - val_loss: 1.2779\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4011 - val_loss: 1.2757\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3618 - val_loss: 1.2697\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3672 - val_loss: 1.2620\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3577 - val_loss: 1.2640\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.3637 - val_loss: 1.2565\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3630 - val_loss: 1.2616\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3699 - val_loss: 1.2601\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3515 - val_loss: 1.2469\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3690 - val_loss: 1.2482\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3463 - val_loss: 1.2480\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.3564 - val_loss: 1.2389\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.3316 - val_loss: 1.2289\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3404 - val_loss: 1.2335\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.3378 - val_loss: 1.2359\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3392 - val_loss: 1.2265\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3241 - val_loss: 1.2192\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3169 - val_loss: 1.2189\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3292 - val_loss: 1.2160\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3215 - val_loss: 1.2188\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3139 - val_loss: 1.2150\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.3111 - val_loss: 1.2184\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.2959 - val_loss: 1.2158\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.2974 - val_loss: 1.2096\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3119 - val_loss: 1.2078\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3140 - val_loss: 1.2054\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.2753 - val_loss: 1.1965\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3109 - val_loss: 1.2027\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.2922 - val_loss: 1.1905\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.2876 - val_loss: 1.1903\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 1.2958 - val_loss: 1.1900\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2848 - val_loss: 1.1865\n",
      "Epoch 119/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2836 - val_loss: 1.1818\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.2698 - val_loss: 1.1903\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.2827 - val_loss: 1.1788\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2660 - val_loss: 1.1825\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2764 - val_loss: 1.1826\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.2702 - val_loss: 1.1716\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.2797 - val_loss: 1.1722\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2659 - val_loss: 1.1713\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2414 - val_loss: 1.1620\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2606 - val_loss: 1.1655\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2464 - val_loss: 1.1581\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2566 - val_loss: 1.1595\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2508 - val_loss: 1.1510\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2625 - val_loss: 1.1594\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2449 - val_loss: 1.1516\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2554 - val_loss: 1.1572\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2505 - val_loss: 1.1554\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2610 - val_loss: 1.1488\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.2518 - val_loss: 1.1480\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.2454 - val_loss: 1.1528\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2265 - val_loss: 1.1491\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.2349 - val_loss: 1.1407\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 1.2403 - val_loss: 1.1395\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.2320 - val_loss: 1.1450\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2243 - val_loss: 1.1345\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.2241 - val_loss: 1.1406\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2292 - val_loss: 1.1310\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2407 - val_loss: 1.1349\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2245 - val_loss: 1.1294\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2352 - val_loss: 1.1363\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2191 - val_loss: 1.1362\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2224 - val_loss: 1.1249\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2159 - val_loss: 1.1228\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.2161 - val_loss: 1.1285\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.2221 - val_loss: 1.1261\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.2169 - val_loss: 1.1172\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.2157 - val_loss: 1.1251\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.2047 - val_loss: 1.1194\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1895 - val_loss: 1.1186\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.2185 - val_loss: 1.1170\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2067 - val_loss: 1.1166\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.2014 - val_loss: 1.1144\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.2027 - val_loss: 1.1084\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1967 - val_loss: 1.1184\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1987 - val_loss: 1.1204\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.1919 - val_loss: 1.1064\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1896 - val_loss: 1.1022\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.2002 - val_loss: 1.1015\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.2015 - val_loss: 1.0995\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1842 - val_loss: 1.1036\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1874 - val_loss: 1.0989\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1985 - val_loss: 1.0963\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1904 - val_loss: 1.1093\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1879 - val_loss: 1.0926\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 1.1939 - val_loss: 1.0935\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1802 - val_loss: 1.0981\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1715 - val_loss: 1.0946\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1992 - val_loss: 1.0942\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.1890 - val_loss: 1.0990\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1726 - val_loss: 1.0945\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.1785 - val_loss: 1.0844\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1777 - val_loss: 1.0939\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1833 - val_loss: 1.0884\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1983 - val_loss: 1.0853\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1776 - val_loss: 1.0804\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1756 - val_loss: 1.0746\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1843 - val_loss: 1.0898\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1788 - val_loss: 1.0888\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1548 - val_loss: 1.0760\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1672 - val_loss: 1.0846\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1798 - val_loss: 1.0891\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1999 - val_loss: 1.0777\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1642 - val_loss: 1.0788\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1576 - val_loss: 1.0780\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1570 - val_loss: 1.0713\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1652 - val_loss: 1.0874\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1679 - val_loss: 1.0694\n",
      "Epoch 196/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1578 - val_loss: 1.0781\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1613 - val_loss: 1.0681\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1457 - val_loss: 1.0880\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1594 - val_loss: 1.0750\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1594 - val_loss: 1.0727\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1729 - val_loss: 1.0660\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1566 - val_loss: 1.0680\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1565 - val_loss: 1.0678\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1531 - val_loss: 1.0667\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1441 - val_loss: 1.0851\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1456 - val_loss: 1.0648\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1631 - val_loss: 1.0587\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1509 - val_loss: 1.0643\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1710 - val_loss: 1.0624\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1477 - val_loss: 1.0641\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1333 - val_loss: 1.0556\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1425 - val_loss: 1.0541\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1622 - val_loss: 1.0513\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.1607 - val_loss: 1.0583\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1211 - val_loss: 1.0563\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1536 - val_loss: 1.0558\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1415 - val_loss: 1.0606\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1441 - val_loss: 1.0516\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1351 - val_loss: 1.0492\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.1434 - val_loss: 1.0511\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.1433 - val_loss: 1.0573\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1331 - val_loss: 1.0468\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1428 - val_loss: 1.0501\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1387 - val_loss: 1.0459\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1341 - val_loss: 1.0520\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1466 - val_loss: 1.0450\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1361 - val_loss: 1.0518\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1352 - val_loss: 1.0412\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.1379 - val_loss: 1.0487\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1397 - val_loss: 1.0455\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1381 - val_loss: 1.0465\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1336 - val_loss: 1.0410\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1367 - val_loss: 1.0431\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.1288 - val_loss: 1.0381\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1484 - val_loss: 1.0393\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1214 - val_loss: 1.0451\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1315 - val_loss: 1.0414\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1199 - val_loss: 1.0438\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1212 - val_loss: 1.0381\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1153 - val_loss: 1.0345\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1178 - val_loss: 1.0403\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.1146 - val_loss: 1.0339\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1276 - val_loss: 1.0349\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.1275 - val_loss: 1.0349\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.1350 - val_loss: 1.0360\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1191 - val_loss: 1.0305\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1309 - val_loss: 1.0300\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1185 - val_loss: 1.0316\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1464 - val_loss: 1.0331\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1128 - val_loss: 1.0257\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1075 - val_loss: 1.0276\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.1330 - val_loss: 1.0339\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0980 - val_loss: 1.0262\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1183 - val_loss: 1.0356\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1132 - val_loss: 1.0300\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1152 - val_loss: 1.0221\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.1331 - val_loss: 1.0247\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1070 - val_loss: 1.0218\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1283 - val_loss: 1.0306\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.1136 - val_loss: 1.0283\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.1001 - val_loss: 1.0262\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0860 - val_loss: 1.0223\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0994 - val_loss: 1.0241\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0915 - val_loss: 1.0175\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0939 - val_loss: 1.0279\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1028 - val_loss: 1.0241\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0928 - val_loss: 1.0183\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1053 - val_loss: 1.0174\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.1266 - val_loss: 1.0166\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1062 - val_loss: 1.0171\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.1074 - val_loss: 1.0187\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0999 - val_loss: 1.0085\n",
      "Epoch 273/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0972 - val_loss: 1.0254\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.1018 - val_loss: 1.0261\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1165 - val_loss: 1.0228\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0861 - val_loss: 1.0203\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0974 - val_loss: 1.0207\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0913 - val_loss: 1.0076\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1031 - val_loss: 1.0119\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0965 - val_loss: 1.0072\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1011 - val_loss: 1.0122\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0888 - val_loss: 1.0074\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.1174 - val_loss: 1.0193\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1005 - val_loss: 1.0188\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1108 - val_loss: 1.0154\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.1120 - val_loss: 1.0111\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0998 - val_loss: 1.0066\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0995 - val_loss: 1.0125\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0975 - val_loss: 1.0013\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0872 - val_loss: 1.0105\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.1031 - val_loss: 1.0047\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.1115 - val_loss: 1.0036\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0707 - val_loss: 1.0108\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.1034 - val_loss: 1.0041\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0793 - val_loss: 1.0168\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.1009 - val_loss: 1.0031\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.1025 - val_loss: 1.0041\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0784 - val_loss: 1.0043\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0747 - val_loss: 0.9997\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0973 - val_loss: 1.0112\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.0788 - val_loss: 1.0100\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0929 - val_loss: 1.0049\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.1022 - val_loss: 0.9986\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.0826 - val_loss: 1.0002\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0986 - val_loss: 0.9973\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0776 - val_loss: 1.0090\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0832 - val_loss: 1.0036\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.0957 - val_loss: 1.0080\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0843 - val_loss: 0.9983\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.0884 - val_loss: 1.0061\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0747 - val_loss: 0.9934\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0824 - val_loss: 0.9934\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.0926 - val_loss: 0.9930\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0857 - val_loss: 0.9998\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.0660 - val_loss: 0.9993\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.0706 - val_loss: 0.9939\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.0798 - val_loss: 0.9976\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0864 - val_loss: 0.9990\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0894 - val_loss: 0.9902\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0949 - val_loss: 0.9872\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0881 - val_loss: 0.9973\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0825 - val_loss: 0.9967\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.0784 - val_loss: 0.9893\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0888 - val_loss: 0.9936\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0892 - val_loss: 0.9933\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0548 - val_loss: 0.9955\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.0766 - val_loss: 0.9907\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.0954 - val_loss: 0.9973\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0920 - val_loss: 0.9942\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0671 - val_loss: 0.9914\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0782 - val_loss: 0.9936\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0825 - val_loss: 0.9920\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0674 - val_loss: 0.9849\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.0712 - val_loss: 0.9839\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0665 - val_loss: 1.0010\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0683 - val_loss: 0.9843\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.0639 - val_loss: 0.9920\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.0501 - val_loss: 0.9930\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.0768 - val_loss: 0.9917\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.0711 - val_loss: 0.9922\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 379us/sample - loss: 3.7902 - val_loss: 2.7632\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 2.6926 - val_loss: 2.5039\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.5028 - val_loss: 2.3700\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.4155 - val_loss: 2.3326\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3696 - val_loss: 2.3060\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.3421 - val_loss: 2.2823\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3245 - val_loss: 2.2557\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.3135 - val_loss: 2.2389\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.3007 - val_loss: 2.2232\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.2776 - val_loss: 2.2023\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.2557 - val_loss: 2.1817\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.2538 - val_loss: 2.1690\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.2257 - val_loss: 2.1524\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.2158 - val_loss: 2.1342\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.1906 - val_loss: 2.1132\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.1781 - val_loss: 2.0967\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.1671 - val_loss: 2.0838\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.1558 - val_loss: 2.0685\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.1377 - val_loss: 2.0525\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.1239 - val_loss: 2.0398\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0986 - val_loss: 2.0202\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0945 - val_loss: 2.0118\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 2.0696 - val_loss: 1.9866\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0828 - val_loss: 1.9767\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0502 - val_loss: 1.9612\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.0472 - val_loss: 1.9512\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.0286 - val_loss: 1.9380\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.0006 - val_loss: 1.9207\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0054 - val_loss: 1.9166\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9950 - val_loss: 1.9083\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9845 - val_loss: 1.8889\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9748 - val_loss: 1.8844\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9713 - val_loss: 1.8733\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9541 - val_loss: 1.8602\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9428 - val_loss: 1.8479\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9336 - val_loss: 1.8371\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9246 - val_loss: 1.8289\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9047 - val_loss: 1.8189\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9086 - val_loss: 1.8186\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8827 - val_loss: 1.8032\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.8937 - val_loss: 1.7943\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.8783 - val_loss: 1.7864\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8650 - val_loss: 1.7768\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.8710 - val_loss: 1.7664\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8473 - val_loss: 1.7599\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.8413 - val_loss: 1.7520\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8329 - val_loss: 1.7415\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8189 - val_loss: 1.7337\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.8155 - val_loss: 1.7223\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.8152 - val_loss: 1.7167\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7977 - val_loss: 1.7112\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7897 - val_loss: 1.7012\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7809 - val_loss: 1.6932\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.7781 - val_loss: 1.6855\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.7732 - val_loss: 1.6826\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 78us/sample - loss: 1.7695 - val_loss: 1.6729\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.7661 - val_loss: 1.6658\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 1.7561 - val_loss: 1.6608\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.7517 - val_loss: 1.6526\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.7386 - val_loss: 1.6448\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7309 - val_loss: 1.6423\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.7236 - val_loss: 1.6348\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.7094 - val_loss: 1.6352\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7316 - val_loss: 1.6195\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7233 - val_loss: 1.6181\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7144 - val_loss: 1.6221\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6922 - val_loss: 1.6131\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6963 - val_loss: 1.6057\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6933 - val_loss: 1.5935\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6770 - val_loss: 1.5937\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6875 - val_loss: 1.5878\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6814 - val_loss: 1.5861\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6694 - val_loss: 1.5741\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6665 - val_loss: 1.5678\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6537 - val_loss: 1.5708\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.6704 - val_loss: 1.5609\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.6524 - val_loss: 1.5537\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6485 - val_loss: 1.5572\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6569 - val_loss: 1.5463\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6411 - val_loss: 1.5436\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6393 - val_loss: 1.5451\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6356 - val_loss: 1.5370\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6330 - val_loss: 1.5370\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6307 - val_loss: 1.5435\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6290 - val_loss: 1.5311\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6116 - val_loss: 1.5259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.6117 - val_loss: 1.5201\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6189 - val_loss: 1.5225\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6215 - val_loss: 1.5208\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6130 - val_loss: 1.5087\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6069 - val_loss: 1.5196\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6021 - val_loss: 1.5091\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6029 - val_loss: 1.5068\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5850 - val_loss: 1.4983\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6054 - val_loss: 1.4965\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5857 - val_loss: 1.4931\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5806 - val_loss: 1.4890\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5917 - val_loss: 1.4826\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5802 - val_loss: 1.4847\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5705 - val_loss: 1.4794\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5733 - val_loss: 1.4763\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5715 - val_loss: 1.4784\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5857 - val_loss: 1.4731\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5787 - val_loss: 1.4699\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5724 - val_loss: 1.4683\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5805 - val_loss: 1.4706\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5631 - val_loss: 1.4672\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5670 - val_loss: 1.4655\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5656 - val_loss: 1.4709\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.5498 - val_loss: 1.4606\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.5732 - val_loss: 1.4632\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5556 - val_loss: 1.4601\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5521 - val_loss: 1.4492\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5433 - val_loss: 1.4496\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5442 - val_loss: 1.4522\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5541 - val_loss: 1.4484\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.5448 - val_loss: 1.4395\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5543 - val_loss: 1.4443\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5461 - val_loss: 1.4439\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5366 - val_loss: 1.4437\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5438 - val_loss: 1.4414\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5394 - val_loss: 1.4396\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5273 - val_loss: 1.4385\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5434 - val_loss: 1.4381\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5319 - val_loss: 1.4341\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.5286 - val_loss: 1.4332\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5236 - val_loss: 1.4292\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5374 - val_loss: 1.4306\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5280 - val_loss: 1.4343\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.5313 - val_loss: 1.4345\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5261 - val_loss: 1.4284\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.5186 - val_loss: 1.4136\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5349 - val_loss: 1.4172\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5149 - val_loss: 1.4134\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.5146 - val_loss: 1.4196\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5190 - val_loss: 1.4161\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5164 - val_loss: 1.4117\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5124 - val_loss: 1.4162\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5098 - val_loss: 1.4134\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5109 - val_loss: 1.4060\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5054 - val_loss: 1.4005\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5071 - val_loss: 1.4031\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5118 - val_loss: 1.4063\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5027 - val_loss: 1.3947\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5038 - val_loss: 1.3961\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4998 - val_loss: 1.3953\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4900 - val_loss: 1.4024\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4939 - val_loss: 1.3986\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4991 - val_loss: 1.3935\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4930 - val_loss: 1.3965\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5038 - val_loss: 1.3930\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4983 - val_loss: 1.3936\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.5052 - val_loss: 1.3915\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4894 - val_loss: 1.3856\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5031 - val_loss: 1.3843\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4885 - val_loss: 1.3838\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4812 - val_loss: 1.3868\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4771 - val_loss: 1.3928\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4992 - val_loss: 1.3886\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4868 - val_loss: 1.3864\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4919 - val_loss: 1.3789\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4984 - val_loss: 1.3779\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4768 - val_loss: 1.3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4810 - val_loss: 1.3748\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4850 - val_loss: 1.3811\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4855 - val_loss: 1.3845\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4839 - val_loss: 1.3810\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4882 - val_loss: 1.3733\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4724 - val_loss: 1.3706\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4779 - val_loss: 1.3722\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4898 - val_loss: 1.3757\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4673 - val_loss: 1.3690\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4756 - val_loss: 1.3697\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4829 - val_loss: 1.3642\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4872 - val_loss: 1.3575\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.4575 - val_loss: 1.3631\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4695 - val_loss: 1.3648\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4663 - val_loss: 1.3636\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4615 - val_loss: 1.3572\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4787 - val_loss: 1.3659\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.4630 - val_loss: 1.3628\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4672 - val_loss: 1.3536\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4823 - val_loss: 1.3612\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4685 - val_loss: 1.3580\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4647 - val_loss: 1.3555\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4567 - val_loss: 1.3528\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4598 - val_loss: 1.3571\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4617 - val_loss: 1.3505\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4631 - val_loss: 1.3514\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4575 - val_loss: 1.3491\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4520 - val_loss: 1.3505\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4544 - val_loss: 1.3445\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.4556 - val_loss: 1.3419\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4484 - val_loss: 1.3482\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4625 - val_loss: 1.3444\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4704 - val_loss: 1.3455\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4473 - val_loss: 1.3441\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4513 - val_loss: 1.3462\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4637 - val_loss: 1.3397\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.4631 - val_loss: 1.3481\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4644 - val_loss: 1.3455\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4489 - val_loss: 1.3450\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4412 - val_loss: 1.3422\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.4527 - val_loss: 1.3509\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4380 - val_loss: 1.3418\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4480 - val_loss: 1.3480\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4391 - val_loss: 1.3366\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4505 - val_loss: 1.3362\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4386 - val_loss: 1.3346\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4534 - val_loss: 1.3325\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.4295 - val_loss: 1.3331\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.4361 - val_loss: 1.3368\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4389 - val_loss: 1.3411\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4514 - val_loss: 1.3359\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4295 - val_loss: 1.3316\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4223 - val_loss: 1.3257\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4583 - val_loss: 1.3312\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4329 - val_loss: 1.3356\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.4317 - val_loss: 1.3287\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 110us/sample - loss: 1.4380 - val_loss: 1.3263\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4408 - val_loss: 1.3330\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4192 - val_loss: 1.3258\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.4510 - val_loss: 1.3290\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4489 - val_loss: 1.3290\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.4501 - val_loss: 1.3247\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.4330 - val_loss: 1.3252\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4421 - val_loss: 1.3319\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4429 - val_loss: 1.3229\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4414 - val_loss: 1.3285\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4223 - val_loss: 1.3276\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4325 - val_loss: 1.3270\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4258 - val_loss: 1.3185\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4330 - val_loss: 1.3227\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4438 - val_loss: 1.3145\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4356 - val_loss: 1.3193\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4485 - val_loss: 1.3238\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4378 - val_loss: 1.3293\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4463 - val_loss: 1.3236\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.4173 - val_loss: 1.3273\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.4349 - val_loss: 1.3131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4286 - val_loss: 1.3171\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4260 - val_loss: 1.3141\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4141 - val_loss: 1.3192\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.4280 - val_loss: 1.3122\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4313 - val_loss: 1.3291\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4356 - val_loss: 1.3139\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.4364 - val_loss: 1.3122\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4188 - val_loss: 1.3163\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4210 - val_loss: 1.3113\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4223 - val_loss: 1.3073\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4205 - val_loss: 1.3101\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4269 - val_loss: 1.3147\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4227 - val_loss: 1.3064\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4168 - val_loss: 1.3098\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4166 - val_loss: 1.3005\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4146 - val_loss: 1.3051\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4296 - val_loss: 1.3124\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.4163 - val_loss: 1.3171\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.4094 - val_loss: 1.3087\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4158 - val_loss: 1.3138\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4318 - val_loss: 1.3016\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4155 - val_loss: 1.3002\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4099 - val_loss: 1.3059\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3974 - val_loss: 1.3088\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4287 - val_loss: 1.3076\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4241 - val_loss: 1.3074\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4008 - val_loss: 1.3020\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3962 - val_loss: 1.3201\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3928 - val_loss: 1.2994\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.4115 - val_loss: 1.3087\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4127 - val_loss: 1.3010\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3974 - val_loss: 1.3029\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.4094 - val_loss: 1.3035\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.4175 - val_loss: 1.3019\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4142 - val_loss: 1.3060\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.4084 - val_loss: 1.3001\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4198 - val_loss: 1.3028\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.4025 - val_loss: 1.2963\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.4145 - val_loss: 1.2943\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.4145 - val_loss: 1.2996\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.3970 - val_loss: 1.2974\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3890 - val_loss: 1.2995\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4047 - val_loss: 1.3034\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4073 - val_loss: 1.2966\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.4065 - val_loss: 1.2986\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.4056 - val_loss: 1.2983\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.4147 - val_loss: 1.3114\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4064 - val_loss: 1.3129\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.4070 - val_loss: 1.3010\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3936 - val_loss: 1.2918\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3978 - val_loss: 1.2974\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4112 - val_loss: 1.2996\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4020 - val_loss: 1.2989\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.4028 - val_loss: 1.2949\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3903 - val_loss: 1.2993\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.4079 - val_loss: 1.2945\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4022 - val_loss: 1.2997\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.4006 - val_loss: 1.3002\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.3881 - val_loss: 1.2967\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3865 - val_loss: 1.2869\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3781 - val_loss: 1.2943\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3998 - val_loss: 1.2978\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.3925 - val_loss: 1.2933\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3964 - val_loss: 1.2936\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.3962 - val_loss: 1.3083\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3928 - val_loss: 1.2886\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3979 - val_loss: 1.3033\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3953 - val_loss: 1.2995\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3899 - val_loss: 1.2945\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.4003 - val_loss: 1.3021\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3961 - val_loss: 1.2903\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3925 - val_loss: 1.2902\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.3890 - val_loss: 1.2877\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3985 - val_loss: 1.2852\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.3861 - val_loss: 1.3064\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3827 - val_loss: 1.2882\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3833 - val_loss: 1.2932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3833 - val_loss: 1.2894\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.3706 - val_loss: 1.2979\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3807 - val_loss: 1.2861\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.3942 - val_loss: 1.3045\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.3969 - val_loss: 1.2985\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.4009 - val_loss: 1.2833\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.3827 - val_loss: 1.2982\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.3868 - val_loss: 1.2856\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.3753 - val_loss: 1.2830\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.3876 - val_loss: 1.2856\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.3808 - val_loss: 1.2998\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.3823 - val_loss: 1.2894\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 1.3773 - val_loss: 1.2794\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.3663 - val_loss: 1.2928\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3787 - val_loss: 1.2924\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.3879 - val_loss: 1.2810\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.3736 - val_loss: 1.2748\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.3834 - val_loss: 1.2733\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.3830 - val_loss: 1.2771\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.3727 - val_loss: 1.2884\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.3793 - val_loss: 1.2870\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.3787 - val_loss: 1.2828\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.3702 - val_loss: 1.2768\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 414us/sample - loss: 4.3459 - val_loss: 3.0418\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 3.0428 - val_loss: 2.9727\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.9520 - val_loss: 2.9261\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8865 - val_loss: 2.8843\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.8530 - val_loss: 2.8460\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 2.8209 - val_loss: 2.8144\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.7980 - val_loss: 2.7842\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.7685 - val_loss: 2.7591\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.7444 - val_loss: 2.7334\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.7174 - val_loss: 2.7070\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.6922 - val_loss: 2.6790\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.6691 - val_loss: 2.6561\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.6448 - val_loss: 2.6294\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6190 - val_loss: 2.6036\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.5935 - val_loss: 2.5784\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5698 - val_loss: 2.5510\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.5422 - val_loss: 2.5260\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.5209 - val_loss: 2.5039\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.4913 - val_loss: 2.4752\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4631 - val_loss: 2.4444\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4422 - val_loss: 2.4238\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4212 - val_loss: 2.3945\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.3896 - val_loss: 2.3698\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3617 - val_loss: 2.3451\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.3234 - val_loss: 2.3172\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.3041 - val_loss: 2.3000\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.2791 - val_loss: 2.2751\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.2657 - val_loss: 2.2558\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.2542 - val_loss: 2.2359\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.2308 - val_loss: 2.2214\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.2181 - val_loss: 2.2014\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.1954 - val_loss: 2.1801\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.1754 - val_loss: 2.1572\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.1656 - val_loss: 2.1447\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.1418 - val_loss: 2.1280\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.1332 - val_loss: 2.1119\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.1164 - val_loss: 2.0950\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0967 - val_loss: 2.0864\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0993 - val_loss: 2.0633\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0809 - val_loss: 2.0482\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0668 - val_loss: 2.0383\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0604 - val_loss: 2.0241\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.0426 - val_loss: 2.0091\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0340 - val_loss: 1.9951\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0215 - val_loss: 1.9811\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0085 - val_loss: 1.9734\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 2.0082 - val_loss: 1.9596\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9879 - val_loss: 1.9473\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.9676 - val_loss: 1.9335\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9635 - val_loss: 1.9248\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9557 - val_loss: 1.9164\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9444 - val_loss: 1.9059\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9413 - val_loss: 1.8969\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9326 - val_loss: 1.8871\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9289 - val_loss: 1.8826\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9179 - val_loss: 1.8790\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9131 - val_loss: 1.8703\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9044 - val_loss: 1.8627\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8824 - val_loss: 1.8588\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8988 - val_loss: 1.8494\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8930 - val_loss: 1.8411\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8702 - val_loss: 1.8326\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8578 - val_loss: 1.8226\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8731 - val_loss: 1.8211\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8504 - val_loss: 1.8134\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8446 - val_loss: 1.8039\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8400 - val_loss: 1.7965\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.8427 - val_loss: 1.7934\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8425 - val_loss: 1.7945\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8193 - val_loss: 1.7811\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8074 - val_loss: 1.7769\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8205 - val_loss: 1.7738\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8157 - val_loss: 1.7642\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8130 - val_loss: 1.7590\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7945 - val_loss: 1.7526\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7999 - val_loss: 1.7517\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8053 - val_loss: 1.7488\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.7961 - val_loss: 1.7451\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 1.8010 - val_loss: 1.7359\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7963 - val_loss: 1.7359\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7914 - val_loss: 1.7289\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7811 - val_loss: 1.7240\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7841 - val_loss: 1.7237\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7713 - val_loss: 1.7183\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7772 - val_loss: 1.7187\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7744 - val_loss: 1.7187\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7698 - val_loss: 1.7160\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7681 - val_loss: 1.7108\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7544 - val_loss: 1.7044\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7562 - val_loss: 1.7067\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7604 - val_loss: 1.7071\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.7716 - val_loss: 1.7055\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7615 - val_loss: 1.6958\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7458 - val_loss: 1.6945\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 1.7579 - val_loss: 1.7046\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7480 - val_loss: 1.6923\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7472 - val_loss: 1.6874\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7441 - val_loss: 1.6950\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7344 - val_loss: 1.6862\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7391 - val_loss: 1.6845\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.7278 - val_loss: 1.6801\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7323 - val_loss: 1.6841\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7373 - val_loss: 1.6830\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.7375 - val_loss: 1.6791\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7380 - val_loss: 1.6789\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7330 - val_loss: 1.6846\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7263 - val_loss: 1.6820\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.7281 - val_loss: 1.6654\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.7187 - val_loss: 1.6668\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7254 - val_loss: 1.6674\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7169 - val_loss: 1.6738\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6908 - val_loss: 1.6628\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.7299 - val_loss: 1.6576\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7195 - val_loss: 1.6678\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.7162 - val_loss: 1.6543\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.7128 - val_loss: 1.6507\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7144 - val_loss: 1.6517\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.7071 - val_loss: 1.6524\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.7073 - val_loss: 1.6492\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7110 - val_loss: 1.6594\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.7146 - val_loss: 1.6570\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.7133 - val_loss: 1.6539\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6952 - val_loss: 1.6487\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6968 - val_loss: 1.6377\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.7070 - val_loss: 1.6536\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6841 - val_loss: 1.6427\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.7047 - val_loss: 1.6477\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.7018 - val_loss: 1.6481\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6811 - val_loss: 1.6405\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.7036 - val_loss: 1.6450\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6956 - val_loss: 1.6399\n",
      "Epoch 132/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6897 - val_loss: 1.6313\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6743 - val_loss: 1.6261\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6927 - val_loss: 1.6363\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.7023 - val_loss: 1.6285\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6881 - val_loss: 1.6274\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6889 - val_loss: 1.6245\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6790 - val_loss: 1.6263\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6780 - val_loss: 1.6237\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.6847 - val_loss: 1.6160\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6666 - val_loss: 1.6171\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6696 - val_loss: 1.6198\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6902 - val_loss: 1.6124\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6596 - val_loss: 1.6193\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6929 - val_loss: 1.6160\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6531 - val_loss: 1.6379\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6799 - val_loss: 1.6160\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6735 - val_loss: 1.6181\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6806 - val_loss: 1.6126\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6739 - val_loss: 1.6118\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6738 - val_loss: 1.6069\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.6505 - val_loss: 1.6123\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6596 - val_loss: 1.6143\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.6633 - val_loss: 1.6112\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6634 - val_loss: 1.6006\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6790 - val_loss: 1.6202\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6598 - val_loss: 1.6042\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6544 - val_loss: 1.6048\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6550 - val_loss: 1.5968\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6721 - val_loss: 1.6005\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6731 - val_loss: 1.5997\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6637 - val_loss: 1.5959\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6469 - val_loss: 1.5953\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 1.6481 - val_loss: 1.5979\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6648 - val_loss: 1.5999\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6546 - val_loss: 1.6146\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6612 - val_loss: 1.5890\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.6485 - val_loss: 1.6209\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6631 - val_loss: 1.5939\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6716 - val_loss: 1.5971\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6566 - val_loss: 1.5886\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6460 - val_loss: 1.5992\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 117us/sample - loss: 1.6609 - val_loss: 1.5809\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6485 - val_loss: 1.5969\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6574 - val_loss: 1.5978\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6441 - val_loss: 1.5873\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6564 - val_loss: 1.5975\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6532 - val_loss: 1.5881\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6506 - val_loss: 1.5850\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6356 - val_loss: 1.5832\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6280 - val_loss: 1.5783\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.6400 - val_loss: 1.5959\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6299 - val_loss: 1.5912\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6437 - val_loss: 1.5812\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6475 - val_loss: 1.5717\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6459 - val_loss: 1.5700\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6455 - val_loss: 1.5742\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.6258 - val_loss: 1.5659\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.6304 - val_loss: 1.5812\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6259 - val_loss: 1.5649\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6422 - val_loss: 1.5615\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6269 - val_loss: 1.5690\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6479 - val_loss: 1.5775\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6377 - val_loss: 1.5630\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6346 - val_loss: 1.5731\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6341 - val_loss: 1.5673\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.6306 - val_loss: 1.5610\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6234 - val_loss: 1.5582\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6329 - val_loss: 1.5682\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6481 - val_loss: 1.5587\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6305 - val_loss: 1.5658\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.6337 - val_loss: 1.5646\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6105 - val_loss: 1.5599\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.6064 - val_loss: 1.5608\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.6180 - val_loss: 1.5626\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.6157 - val_loss: 1.5527\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.6299 - val_loss: 1.5557\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6354 - val_loss: 1.5501\n",
      "Epoch 209/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6152 - val_loss: 1.5549\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6182 - val_loss: 1.5479\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6189 - val_loss: 1.5701\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6192 - val_loss: 1.5468\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6164 - val_loss: 1.5605\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6116 - val_loss: 1.5629\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.6171 - val_loss: 1.5620\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6069 - val_loss: 1.5443\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6037 - val_loss: 1.5418\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6277 - val_loss: 1.5396\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.6204 - val_loss: 1.5419\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6186 - val_loss: 1.5488\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6133 - val_loss: 1.5439\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6255 - val_loss: 1.5475\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6232 - val_loss: 1.5546\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6152 - val_loss: 1.5514\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.6111 - val_loss: 1.5489\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.6109 - val_loss: 1.5426\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.6356 - val_loss: 1.5405\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6010 - val_loss: 1.5374\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5982 - val_loss: 1.5348\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6021 - val_loss: 1.5460\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6027 - val_loss: 1.5455\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6085 - val_loss: 1.5309\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6143 - val_loss: 1.5329\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6076 - val_loss: 1.5471\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.6005 - val_loss: 1.5414\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5922 - val_loss: 1.5299\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5954 - val_loss: 1.5284\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5919 - val_loss: 1.5396\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.6085 - val_loss: 1.5475\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5874 - val_loss: 1.5336\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.5855 - val_loss: 1.5294\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.6048 - val_loss: 1.5355\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.6127 - val_loss: 1.5257\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.6161 - val_loss: 1.5359\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.6029 - val_loss: 1.5284\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.6129 - val_loss: 1.5283\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.5964 - val_loss: 1.5211\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 1.5810 - val_loss: 1.5324\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 1.5946 - val_loss: 1.5207\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 1.5896 - val_loss: 1.5162\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.5899 - val_loss: 1.5167\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 1.5825 - val_loss: 1.5214\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 1.5788 - val_loss: 1.5326\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 1.5856 - val_loss: 1.5235\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5944 - val_loss: 1.5184\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5939 - val_loss: 1.5412\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5884 - val_loss: 1.5194\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.5900 - val_loss: 1.5409\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.6102 - val_loss: 1.5142\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5772 - val_loss: 1.5048\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.5862 - val_loss: 1.5184\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.6014 - val_loss: 1.5088\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5813 - val_loss: 1.5147\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5855 - val_loss: 1.5059\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.6032 - val_loss: 1.5121\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5820 - val_loss: 1.5066\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.5682 - val_loss: 1.5187\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.5788 - val_loss: 1.5157\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5852 - val_loss: 1.5121\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5760 - val_loss: 1.5046\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.5860 - val_loss: 1.5039\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.5704 - val_loss: 1.5088\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5917 - val_loss: 1.5002\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5882 - val_loss: 1.5110\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5785 - val_loss: 1.5043\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5887 - val_loss: 1.5131\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5726 - val_loss: 1.5097\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5885 - val_loss: 1.4992\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5837 - val_loss: 1.5281\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5740 - val_loss: 1.5005\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5949 - val_loss: 1.5129\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5833 - val_loss: 1.5083\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5827 - val_loss: 1.5027\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5509 - val_loss: 1.5008\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5743 - val_loss: 1.4975\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5663 - val_loss: 1.4984\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5799 - val_loss: 1.5002\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5789 - val_loss: 1.4976\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5739 - val_loss: 1.5032\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5556 - val_loss: 1.5106\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 1.5728 - val_loss: 1.4998\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5743 - val_loss: 1.5040\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5653 - val_loss: 1.5069\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.5774 - val_loss: 1.4999\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5558 - val_loss: 1.4932\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.5469 - val_loss: 1.4992\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5597 - val_loss: 1.5017\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5594 - val_loss: 1.4934\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5713 - val_loss: 1.5033\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5665 - val_loss: 1.5091\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5553 - val_loss: 1.4973\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.5559 - val_loss: 1.4988\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.5644 - val_loss: 1.5021\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5764 - val_loss: 1.4926\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5622 - val_loss: 1.4946\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.5716 - val_loss: 1.5113\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5578 - val_loss: 1.5033\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5860 - val_loss: 1.4926\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5675 - val_loss: 1.4941\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5485 - val_loss: 1.4908\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5677 - val_loss: 1.5109\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5681 - val_loss: 1.4937\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.5589 - val_loss: 1.4904\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5583 - val_loss: 1.4818\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.5526 - val_loss: 1.4910\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5790 - val_loss: 1.4858\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5507 - val_loss: 1.4998\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.5768 - val_loss: 1.4855\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5652 - val_loss: 1.4928\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5751 - val_loss: 1.4894\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5672 - val_loss: 1.4864\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5615 - val_loss: 1.4920\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5535 - val_loss: 1.5031\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.5597 - val_loss: 1.5023\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5428 - val_loss: 1.4874\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5524 - val_loss: 1.4932\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.5473 - val_loss: 1.4835\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5639 - val_loss: 1.5104\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.5655 - val_loss: 1.4823\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5434 - val_loss: 1.4859\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5523 - val_loss: 1.4876\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.5496 - val_loss: 1.4876\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.5529 - val_loss: 1.4937\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.5509 - val_loss: 1.4830\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5635 - val_loss: 1.4864\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.5483 - val_loss: 1.4810\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.5651 - val_loss: 1.5037\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.5452 - val_loss: 1.4882\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5521 - val_loss: 1.4819\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.5683 - val_loss: 1.4865\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 401us/sample - loss: 5.3291 - val_loss: 3.8031\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 3.7210 - val_loss: 3.6221\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.5656 - val_loss: 3.5104\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.4902 - val_loss: 3.4657\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.4461 - val_loss: 3.4288\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.4082 - val_loss: 3.3931\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.3734 - val_loss: 3.3584\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 3.3515 - val_loss: 3.3199\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.3106 - val_loss: 3.2862\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 3.2690 - val_loss: 3.2529\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.2517 - val_loss: 3.2172\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.2076 - val_loss: 3.1840\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 3.1773 - val_loss: 3.1432\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.1535 - val_loss: 3.1205\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1188 - val_loss: 3.0841\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.0952 - val_loss: 3.0501\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.0574 - val_loss: 3.0190\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.0365 - val_loss: 2.9984\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0005 - val_loss: 2.9656\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.9859 - val_loss: 2.9386\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9516 - val_loss: 2.9115\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9334 - val_loss: 2.8717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9014 - val_loss: 2.8462\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8953 - val_loss: 2.8271\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8431 - val_loss: 2.7934\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8345 - val_loss: 2.7710\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8261 - val_loss: 2.7498\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8042 - val_loss: 2.7303\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.7776 - val_loss: 2.7121\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.7558 - val_loss: 2.6821\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.7229 - val_loss: 2.6575\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.7127 - val_loss: 2.6452\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.6941 - val_loss: 2.6246\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.6814 - val_loss: 2.6020\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.6578 - val_loss: 2.5850\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.6272 - val_loss: 2.5636\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6281 - val_loss: 2.5441\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5890 - val_loss: 2.5416\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5832 - val_loss: 2.5038\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.5572 - val_loss: 2.4893\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5475 - val_loss: 2.4670\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.5339 - val_loss: 2.4615\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5253 - val_loss: 2.4459\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4961 - val_loss: 2.4231\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4873 - val_loss: 2.4071\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.4808 - val_loss: 2.3944\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4491 - val_loss: 2.3750\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 111us/sample - loss: 2.4459 - val_loss: 2.3772\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.4431 - val_loss: 2.3609\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4120 - val_loss: 2.3457\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.3992 - val_loss: 2.3180\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.3869 - val_loss: 2.3063\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3844 - val_loss: 2.3173\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3773 - val_loss: 2.2835\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.3574 - val_loss: 2.2731\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.3398 - val_loss: 2.2580\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.3371 - val_loss: 2.2470\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.3178 - val_loss: 2.2399\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.3169 - val_loss: 2.2314\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.3093 - val_loss: 2.2191\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.2990 - val_loss: 2.2133\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.2908 - val_loss: 2.2181\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.2723 - val_loss: 2.1931\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.2770 - val_loss: 2.1800\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.2588 - val_loss: 2.1789\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.2576 - val_loss: 2.1761\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.2460 - val_loss: 2.1595\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.2287 - val_loss: 2.1548\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.2314 - val_loss: 2.1430\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.2235 - val_loss: 2.1286\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.2106 - val_loss: 2.1352\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.2162 - val_loss: 2.1173\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.2056 - val_loss: 2.1118\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.1956 - val_loss: 2.1021\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.1901 - val_loss: 2.0913\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.1924 - val_loss: 2.0917\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.1715 - val_loss: 2.0861\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.1793 - val_loss: 2.0696\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.1727 - val_loss: 2.0740\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.1526 - val_loss: 2.0584\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.1559 - val_loss: 2.0506\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.1640 - val_loss: 2.0490\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.1457 - val_loss: 2.0413\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.1604 - val_loss: 2.0437\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 2.1489 - val_loss: 2.0348\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.1385 - val_loss: 2.0332\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.1460 - val_loss: 2.0386\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.1237 - val_loss: 2.0260\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.1286 - val_loss: 2.0224\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.1033 - val_loss: 2.0176\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.1059 - val_loss: 2.0042\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 2.1211 - val_loss: 2.0072\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.1149 - val_loss: 2.0109\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.1051 - val_loss: 2.0079\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.1058 - val_loss: 1.9992\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0979 - val_loss: 1.9927\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.0904 - val_loss: 1.9950\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0987 - val_loss: 1.9876\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0869 - val_loss: 1.9946\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0910 - val_loss: 1.9830\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.0912 - val_loss: 1.9812\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.0762 - val_loss: 1.9822\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.0665 - val_loss: 1.9707\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.0676 - val_loss: 1.9696\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0768 - val_loss: 1.9758\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.0603 - val_loss: 1.9675\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.0652 - val_loss: 1.9669\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0624 - val_loss: 1.9576\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0661 - val_loss: 1.9656\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 2.0495 - val_loss: 1.9535\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.0549 - val_loss: 1.9514\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0459 - val_loss: 1.9453\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.0577 - val_loss: 1.9629\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.0497 - val_loss: 1.9567\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0512 - val_loss: 1.9492\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0455 - val_loss: 1.9430\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0444 - val_loss: 1.9439\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0484 - val_loss: 1.9490\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.0419 - val_loss: 1.9423\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0406 - val_loss: 1.9488\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.0332 - val_loss: 1.9469\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.0349 - val_loss: 1.9308\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0305 - val_loss: 1.9317\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0257 - val_loss: 1.9257\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0319 - val_loss: 1.9308\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0161 - val_loss: 1.9262\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0263 - val_loss: 1.9318\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.0158 - val_loss: 1.9243\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.0238 - val_loss: 1.9230\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.0163 - val_loss: 1.9284\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.0156 - val_loss: 1.9269\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.0053 - val_loss: 1.9139\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.0192 - val_loss: 1.9188\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.0199 - val_loss: 1.9143\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.0123 - val_loss: 1.9110\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.0069 - val_loss: 1.9069\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.0038 - val_loss: 1.9048\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9966 - val_loss: 1.9163\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 111us/sample - loss: 1.9937 - val_loss: 1.9119\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.0059 - val_loss: 1.9018\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9970 - val_loss: 1.9031\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.0012 - val_loss: 1.9056\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9971 - val_loss: 1.9075\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9995 - val_loss: 1.9038\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9936 - val_loss: 1.9096\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9932 - val_loss: 1.9003\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9785 - val_loss: 1.8943\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9803 - val_loss: 1.8955\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.9866 - val_loss: 1.8936\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.9965 - val_loss: 1.9009\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.9823 - val_loss: 1.8965\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9985 - val_loss: 1.8888\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9835 - val_loss: 1.8845\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9736 - val_loss: 1.8770\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9748 - val_loss: 1.8902\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9685 - val_loss: 1.8872\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9737 - val_loss: 1.8942\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 1.9787 - val_loss: 1.8777\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9606 - val_loss: 1.8833\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9769 - val_loss: 1.8852\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.9663 - val_loss: 1.8831\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9637 - val_loss: 1.8858\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9605 - val_loss: 1.8762\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.9616 - val_loss: 1.8751\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9682 - val_loss: 1.8725\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9637 - val_loss: 1.8782\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9494 - val_loss: 1.8745\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.9591 - val_loss: 1.8794\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9708 - val_loss: 1.8677\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9702 - val_loss: 1.8740\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9668 - val_loss: 1.8651\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9586 - val_loss: 1.8687\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9565 - val_loss: 1.8712\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9399 - val_loss: 1.8639\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.9700 - val_loss: 1.8707\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9391 - val_loss: 1.8673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9406 - val_loss: 1.8655\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9480 - val_loss: 1.8547\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.9668 - val_loss: 1.8795\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9591 - val_loss: 1.8631\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9470 - val_loss: 1.8590\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.9510 - val_loss: 1.8692\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9413 - val_loss: 1.8620\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 1.9460 - val_loss: 1.8602\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9445 - val_loss: 1.8600\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.9452 - val_loss: 1.8555\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9436 - val_loss: 1.8530\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9394 - val_loss: 1.8596\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9541 - val_loss: 1.8669\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9343 - val_loss: 1.8469\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9421 - val_loss: 1.8526\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9414 - val_loss: 1.8554\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9425 - val_loss: 1.8555\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9379 - val_loss: 1.8464\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9303 - val_loss: 1.8490\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.9347 - val_loss: 1.8476\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.9353 - val_loss: 1.8437\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9257 - val_loss: 1.8673\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9262 - val_loss: 1.8418\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9327 - val_loss: 1.8515\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9330 - val_loss: 1.8389\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9302 - val_loss: 1.8437\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9373 - val_loss: 1.8431\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9189 - val_loss: 1.8488\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9256 - val_loss: 1.8449\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9190 - val_loss: 1.8357\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9311 - val_loss: 1.8405\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9217 - val_loss: 1.8388\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9053 - val_loss: 1.8350\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9210 - val_loss: 1.8421\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 1.9198 - val_loss: 1.8393\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9224 - val_loss: 1.8352\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 1.9108 - val_loss: 1.8269\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9158 - val_loss: 1.8377\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9134 - val_loss: 1.8435\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9182 - val_loss: 1.8436\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9278 - val_loss: 1.8323\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9211 - val_loss: 1.8292\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9082 - val_loss: 1.8387\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.9300 - val_loss: 1.8362\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9081 - val_loss: 1.8280\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8969 - val_loss: 1.8357\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9012 - val_loss: 1.8168\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9199 - val_loss: 1.8377\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9099 - val_loss: 1.8404\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9025 - val_loss: 1.8419\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.9068 - val_loss: 1.8240\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9037 - val_loss: 1.8236\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9140 - val_loss: 1.8247\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9003 - val_loss: 1.8280\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9244 - val_loss: 1.8195\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.9012 - val_loss: 1.8153\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.9009 - val_loss: 1.8119\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.9013 - val_loss: 1.8336\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.9004 - val_loss: 1.8108\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9004 - val_loss: 1.8144\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8969 - val_loss: 1.8145\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9004 - val_loss: 1.8129\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.9037 - val_loss: 1.8159\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.9107 - val_loss: 1.8196\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8930 - val_loss: 1.8110\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.9181 - val_loss: 1.8197\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.9098 - val_loss: 1.8199\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.9056 - val_loss: 1.8123\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8864 - val_loss: 1.8145\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.8967 - val_loss: 1.8102\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.8896 - val_loss: 1.8046\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8828 - val_loss: 1.8015\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 1.8920 - val_loss: 1.8179\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 1.8939 - val_loss: 1.8165\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 1.9004 - val_loss: 1.8245\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8753 - val_loss: 1.8084\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 1.9012 - val_loss: 1.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8890 - val_loss: 1.8007\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8929 - val_loss: 1.8039\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8767 - val_loss: 1.8083\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.9002 - val_loss: 1.8033\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8747 - val_loss: 1.7952\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8709 - val_loss: 1.7992\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8875 - val_loss: 1.8084\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8777 - val_loss: 1.7976\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8744 - val_loss: 1.8070\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 1.8758 - val_loss: 1.8053\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8644 - val_loss: 1.8084\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.8850 - val_loss: 1.8159\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8716 - val_loss: 1.7948\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8815 - val_loss: 1.7985\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8829 - val_loss: 1.7980\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8812 - val_loss: 1.7979\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.8803 - val_loss: 1.8024\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8814 - val_loss: 1.7944\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.8868 - val_loss: 1.7898\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8707 - val_loss: 1.7940\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8788 - val_loss: 1.7943\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8760 - val_loss: 1.8088\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8741 - val_loss: 1.7920\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.8621 - val_loss: 1.7818\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8941 - val_loss: 1.7974\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8753 - val_loss: 1.7845\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8938 - val_loss: 1.8007\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8815 - val_loss: 1.7936\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8624 - val_loss: 1.7868\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.8726 - val_loss: 1.7831\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8591 - val_loss: 1.7920\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8521 - val_loss: 1.8018\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8739 - val_loss: 1.7828\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8683 - val_loss: 1.7824\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 1.8636 - val_loss: 1.7815\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.8471 - val_loss: 1.7884\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8847 - val_loss: 1.7847\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8511 - val_loss: 1.7898\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8573 - val_loss: 1.7815\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8569 - val_loss: 1.7750\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8682 - val_loss: 1.7810\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 1.8621 - val_loss: 1.7851\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8611 - val_loss: 1.7813\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8482 - val_loss: 1.7704\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8532 - val_loss: 1.7754\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8598 - val_loss: 1.7906\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 1.8776 - val_loss: 1.7703\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8600 - val_loss: 1.7764\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.8460 - val_loss: 1.7787\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8644 - val_loss: 1.7691\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8375 - val_loss: 1.7613\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 1.8575 - val_loss: 1.8030\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8455 - val_loss: 1.7753\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8477 - val_loss: 1.7909\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 1.8504 - val_loss: 1.7761\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 1.8791 - val_loss: 1.7857\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 1.8649 - val_loss: 1.7794\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8763 - val_loss: 1.7878\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8537 - val_loss: 1.7948\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8435 - val_loss: 1.7788\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8613 - val_loss: 1.7857\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8384 - val_loss: 1.7651\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8514 - val_loss: 1.7752\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8595 - val_loss: 1.7698\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8458 - val_loss: 1.7839\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 1.8634 - val_loss: 1.7900\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8477 - val_loss: 1.7808\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.8449 - val_loss: 1.7783\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8533 - val_loss: 1.7823\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8538 - val_loss: 1.7664\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8593 - val_loss: 1.7768\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8457 - val_loss: 1.7689\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8516 - val_loss: 1.7929\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8340 - val_loss: 1.7829\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8468 - val_loss: 1.7756\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 1.8589 - val_loss: 1.7805\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 1.8383 - val_loss: 1.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8404 - val_loss: 1.7650\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 1.8442 - val_loss: 1.7708\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8447 - val_loss: 1.7670\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 1.8507 - val_loss: 1.7711\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 1.8634 - val_loss: 1.7741\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 1.8342 - val_loss: 1.7732\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 1.8434 - val_loss: 1.7633\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 1.8551 - val_loss: 1.7624\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 1.8538 - val_loss: 1.7579\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 1.8411 - val_loss: 1.7781\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 396us/sample - loss: 6.4132 - val_loss: 4.5320\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 4.4348 - val_loss: 4.3650\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 4.3330 - val_loss: 4.2889\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.2732 - val_loss: 4.2360\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.2167 - val_loss: 4.1942\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.1739 - val_loss: 4.1444\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.1421 - val_loss: 4.1102\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.0989 - val_loss: 4.0700\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.0619 - val_loss: 4.0316\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.0147 - val_loss: 3.9963\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.9728 - val_loss: 3.9482\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.9381 - val_loss: 3.9080\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.8971 - val_loss: 3.8704\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.8458 - val_loss: 3.8183\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.8104 - val_loss: 3.7831\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.7788 - val_loss: 3.7540\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.7359 - val_loss: 3.7130\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7058 - val_loss: 3.6716\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.6595 - val_loss: 3.6337\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.6214 - val_loss: 3.5958\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.5845 - val_loss: 3.5556\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.5561 - val_loss: 3.5198\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.5120 - val_loss: 3.4836\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.4808 - val_loss: 3.4504\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.4373 - val_loss: 3.4143\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.3987 - val_loss: 3.3794\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.3758 - val_loss: 3.3461\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.3401 - val_loss: 3.3175\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.3106 - val_loss: 3.2821\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 3.2795 - val_loss: 3.2529\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.2418 - val_loss: 3.2179\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.2110 - val_loss: 3.1879\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1791 - val_loss: 3.1570\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.1622 - val_loss: 3.1281\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.1229 - val_loss: 3.0975\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.0883 - val_loss: 3.0726\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.0671 - val_loss: 3.0429\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 3.0400 - val_loss: 3.0177\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.0087 - val_loss: 2.9952\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9864 - val_loss: 2.9730\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9565 - val_loss: 2.9497\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9443 - val_loss: 2.9342\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9076 - val_loss: 2.9050\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.8868 - val_loss: 2.8902\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8670 - val_loss: 2.8729\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8543 - val_loss: 2.8545\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.8406 - val_loss: 2.8322\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8233 - val_loss: 2.8198\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8033 - val_loss: 2.8083\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.7988 - val_loss: 2.7945\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.7875 - val_loss: 2.7831\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.7609 - val_loss: 2.7702\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.7451 - val_loss: 2.7604\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.7349 - val_loss: 2.7598\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.7351 - val_loss: 2.7396\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.7130 - val_loss: 2.7344\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.6999 - val_loss: 2.7259\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.7088 - val_loss: 2.7134\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.6933 - val_loss: 2.7123\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.6894 - val_loss: 2.7028\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.6845 - val_loss: 2.7035\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.6837 - val_loss: 2.6993\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6716 - val_loss: 2.6919\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.6767 - val_loss: 2.6883\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6564 - val_loss: 2.6820\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.6519 - val_loss: 2.6785\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.6548 - val_loss: 2.6707\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.6519 - val_loss: 2.6682\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 2.6468 - val_loss: 2.6655\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.6430 - val_loss: 2.6708\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.6412 - val_loss: 2.6594\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.6282 - val_loss: 2.6620\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.6392 - val_loss: 2.6534\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.6333 - val_loss: 2.6495\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.6289 - val_loss: 2.6475\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.6322 - val_loss: 2.6477\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.6238 - val_loss: 2.6485\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.6228 - val_loss: 2.6460\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.6289 - val_loss: 2.6422\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6191 - val_loss: 2.6421\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.6191 - val_loss: 2.6394\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6130 - val_loss: 2.6402\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.6080 - val_loss: 2.6318\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.6090 - val_loss: 2.6275\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5962 - val_loss: 2.6286\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.5944 - val_loss: 2.6293\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.5897 - val_loss: 2.6246\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5948 - val_loss: 2.6241\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5916 - val_loss: 2.6124\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5938 - val_loss: 2.6104\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5847 - val_loss: 2.6074\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5732 - val_loss: 2.6127\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5809 - val_loss: 2.6100\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5817 - val_loss: 2.5999\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5820 - val_loss: 2.6010\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.5764 - val_loss: 2.5991\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5692 - val_loss: 2.5985\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.5727 - val_loss: 2.6005\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5609 - val_loss: 2.5933\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5626 - val_loss: 2.5875\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5559 - val_loss: 2.5903\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5517 - val_loss: 2.5884\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5650 - val_loss: 2.5922\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5583 - val_loss: 2.5812\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.5507 - val_loss: 2.5829\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.5535 - val_loss: 2.5860\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5459 - val_loss: 2.5867\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.5529 - val_loss: 2.5744\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5523 - val_loss: 2.5743\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.5495 - val_loss: 2.5724\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.5433 - val_loss: 2.5762\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5418 - val_loss: 2.5762\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5468 - val_loss: 2.5708\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.5432 - val_loss: 2.5632\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.5298 - val_loss: 2.5650\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5446 - val_loss: 2.5624\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5386 - val_loss: 2.5691\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.5421 - val_loss: 2.5622\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5382 - val_loss: 2.5695\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5357 - val_loss: 2.5577\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.5378 - val_loss: 2.5582\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5364 - val_loss: 2.5542\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5313 - val_loss: 2.5523\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.5285 - val_loss: 2.5539\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5300 - val_loss: 2.5584\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5310 - val_loss: 2.5577\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5298 - val_loss: 2.5478\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5310 - val_loss: 2.5575\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5343 - val_loss: 2.5460\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.5273 - val_loss: 2.5492\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.5268 - val_loss: 2.5507\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.5262 - val_loss: 2.5499\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5129 - val_loss: 2.5632\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5264 - val_loss: 2.5438\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5165 - val_loss: 2.5510\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 2.5188 - val_loss: 2.5454\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5223 - val_loss: 2.5430\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5157 - val_loss: 2.5449\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5155 - val_loss: 2.5431\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.5190 - val_loss: 2.5385\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5100 - val_loss: 2.5418\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5107 - val_loss: 2.5384\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.5056 - val_loss: 2.5396\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.5012 - val_loss: 2.5297\n",
      "Epoch 145/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5082 - val_loss: 2.5345\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.5047 - val_loss: 2.5347\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.5125 - val_loss: 2.5315\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4994 - val_loss: 2.5341\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.4918 - val_loss: 2.5317\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.5066 - val_loss: 2.5266\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.5022 - val_loss: 2.5317\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.5006 - val_loss: 2.5248\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.5056 - val_loss: 2.5298\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4930 - val_loss: 2.5290\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.5022 - val_loss: 2.5272\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4932 - val_loss: 2.5242\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4919 - val_loss: 2.5277\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5044 - val_loss: 2.5249\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4883 - val_loss: 2.5360\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.5001 - val_loss: 2.5238\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4914 - val_loss: 2.5293\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4922 - val_loss: 2.5257\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.4853 - val_loss: 2.5168\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4833 - val_loss: 2.5164\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4948 - val_loss: 2.5192\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4845 - val_loss: 2.5246\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4871 - val_loss: 2.5320\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4933 - val_loss: 2.5278\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4871 - val_loss: 2.5184\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4935 - val_loss: 2.5191\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4886 - val_loss: 2.5161\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4848 - val_loss: 2.5101\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4839 - val_loss: 2.5235\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4895 - val_loss: 2.5133\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4886 - val_loss: 2.5140\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4893 - val_loss: 2.5161\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 2.4905 - val_loss: 2.5101\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4812 - val_loss: 2.5254\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4851 - val_loss: 2.5197\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4828 - val_loss: 2.5118\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.4830 - val_loss: 2.5164\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4785 - val_loss: 2.5057\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4823 - val_loss: 2.5050\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4818 - val_loss: 2.5212\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.4727 - val_loss: 2.5096\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4768 - val_loss: 2.5020\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4736 - val_loss: 2.5021\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4739 - val_loss: 2.5108\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.4685 - val_loss: 2.5124\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.4759 - val_loss: 2.5086\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4791 - val_loss: 2.5061\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4767 - val_loss: 2.5066\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4778 - val_loss: 2.5094\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4779 - val_loss: 2.4979\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4874 - val_loss: 2.4986\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4674 - val_loss: 2.5076\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4692 - val_loss: 2.5073\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4717 - val_loss: 2.5071\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4703 - val_loss: 2.4967\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.4756 - val_loss: 2.5041\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4723 - val_loss: 2.4996\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.4637 - val_loss: 2.5085\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4749 - val_loss: 2.5005\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4689 - val_loss: 2.5096\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4763 - val_loss: 2.5030\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4747 - val_loss: 2.5005\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4749 - val_loss: 2.5102\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4639 - val_loss: 2.5067\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4686 - val_loss: 2.4960\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.4683 - val_loss: 2.4971\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.4674 - val_loss: 2.4934\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4634 - val_loss: 2.4972\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4610 - val_loss: 2.4955\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4582 - val_loss: 2.4920\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4727 - val_loss: 2.5055\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4659 - val_loss: 2.4958\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.4650 - val_loss: 2.4915\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.4636 - val_loss: 2.4899\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4626 - val_loss: 2.4907\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4661 - val_loss: 2.5082\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.4679 - val_loss: 2.4884\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4600 - val_loss: 2.5023\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4517 - val_loss: 2.4953\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4520 - val_loss: 2.4923\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4654 - val_loss: 2.4981\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4554 - val_loss: 2.4911\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 2.4552 - val_loss: 2.5002\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4616 - val_loss: 2.4880\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4616 - val_loss: 2.4879\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4532 - val_loss: 2.4847\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4537 - val_loss: 2.4879\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4501 - val_loss: 2.4947\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4602 - val_loss: 2.4908\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4646 - val_loss: 2.4920\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4528 - val_loss: 2.4924\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4580 - val_loss: 2.4821\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4577 - val_loss: 2.4903\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4601 - val_loss: 2.4966\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4519 - val_loss: 2.4982\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4563 - val_loss: 2.4957\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4536 - val_loss: 2.4868\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.4660 - val_loss: 2.4874\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 2.4541 - val_loss: 2.4953\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4551 - val_loss: 2.4774\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4473 - val_loss: 2.4894\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4524 - val_loss: 2.4864\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4543 - val_loss: 2.4800\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4578 - val_loss: 2.4803\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4519 - val_loss: 2.4818\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4540 - val_loss: 2.4747\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4559 - val_loss: 2.4830\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.4460 - val_loss: 2.4766\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4522 - val_loss: 2.4845\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4551 - val_loss: 2.4834\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4514 - val_loss: 2.4747\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4523 - val_loss: 2.4791\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4497 - val_loss: 2.4804\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4479 - val_loss: 2.4800\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4458 - val_loss: 2.4800\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4485 - val_loss: 2.4779\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4457 - val_loss: 2.4707\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4426 - val_loss: 2.4962\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.4497 - val_loss: 2.4715\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 2.4523 - val_loss: 2.4798\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 2.4525 - val_loss: 2.4815\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 2.4478 - val_loss: 2.4771\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 2.4500 - val_loss: 2.4744\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 2.4516 - val_loss: 2.4793\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4376 - val_loss: 2.4731\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.4515 - val_loss: 2.4797\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 2.4399 - val_loss: 2.4781\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.4455 - val_loss: 2.4802\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4392 - val_loss: 2.4706\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.4502 - val_loss: 2.4741\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4452 - val_loss: 2.4816\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4478 - val_loss: 2.4852\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4451 - val_loss: 2.4821\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4464 - val_loss: 2.4772\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4366 - val_loss: 2.4681\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4431 - val_loss: 2.4766\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4356 - val_loss: 2.4744\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4451 - val_loss: 2.4851\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4385 - val_loss: 2.4651\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4507 - val_loss: 2.4733\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4480 - val_loss: 2.4639\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4475 - val_loss: 2.4734\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.4367 - val_loss: 2.4909\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4479 - val_loss: 2.4711\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4420 - val_loss: 2.4688\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4498 - val_loss: 2.4634\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4488 - val_loss: 2.4830\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4389 - val_loss: 2.4767\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.4365 - val_loss: 2.4765\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4440 - val_loss: 2.4786\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4401 - val_loss: 2.4724\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4413 - val_loss: 2.4623\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4354 - val_loss: 2.4767\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4420 - val_loss: 2.4784\n",
      "Epoch 299/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 89us/sample - loss: 2.4402 - val_loss: 2.4802\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4410 - val_loss: 2.4698\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4359 - val_loss: 2.4623\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4341 - val_loss: 2.4691\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4346 - val_loss: 2.4596\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4381 - val_loss: 2.4602\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4429 - val_loss: 2.4601\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4401 - val_loss: 2.4757\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4373 - val_loss: 2.4639\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.4357 - val_loss: 2.4653\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4460 - val_loss: 2.4641\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.4346 - val_loss: 2.4648\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4379 - val_loss: 2.4577\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4451 - val_loss: 2.4702\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4308 - val_loss: 2.4846\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.4347 - val_loss: 2.4602\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.4416 - val_loss: 2.4633\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.4328 - val_loss: 2.4716\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.4335 - val_loss: 2.4639\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4361 - val_loss: 2.4603\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4419 - val_loss: 2.4613\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4389 - val_loss: 2.4633\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4322 - val_loss: 2.4598\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4377 - val_loss: 2.4723\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4327 - val_loss: 2.4655\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.4350 - val_loss: 2.4659\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.4357 - val_loss: 2.4653\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4330 - val_loss: 2.4813\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4393 - val_loss: 2.4666\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4317 - val_loss: 2.4618\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.4377 - val_loss: 2.4610\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.4344 - val_loss: 2.4608\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.4343 - val_loss: 2.4576\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.4365 - val_loss: 2.4571\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.4300 - val_loss: 2.4613\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.4301 - val_loss: 2.4578\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.4347 - val_loss: 2.4671\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.4251 - val_loss: 2.4609\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4308 - val_loss: 2.4642\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.4260 - val_loss: 2.4583\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.4316 - val_loss: 2.4605\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 2.4288 - val_loss: 2.4551\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 400us/sample - loss: 9.2084 - val_loss: 6.2134\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 6.7471 - val_loss: 6.0200\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 6.5123 - val_loss: 5.8313\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1520 - val_loss: 5.7013\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 5.9328 - val_loss: 5.5999\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 5.7816 - val_loss: 5.4016\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 5.5570 - val_loss: 5.2844\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 5.3705 - val_loss: 5.2026\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 5.2591 - val_loss: 5.1377\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 5.1913 - val_loss: 5.0642\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.1056 - val_loss: 5.0033\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 5.0466 - val_loss: 4.9443\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.9795 - val_loss: 4.8962\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.9183 - val_loss: 4.8303\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8666 - val_loss: 4.7739\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8129 - val_loss: 4.7234\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.7459 - val_loss: 4.6613\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.6830 - val_loss: 4.5990\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.6300 - val_loss: 4.5518\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 4.5865 - val_loss: 4.4983\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.5355 - val_loss: 4.4529\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 4.4850 - val_loss: 4.3942\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.4344 - val_loss: 4.3365\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.3869 - val_loss: 4.2917\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.3373 - val_loss: 4.2381\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.2910 - val_loss: 4.1942\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.2558 - val_loss: 4.1521\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.2138 - val_loss: 4.1095\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.1549 - val_loss: 4.0615\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.1157 - val_loss: 4.0158\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 4.0723 - val_loss: 3.9751\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.0471 - val_loss: 3.9281\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.9935 - val_loss: 3.8850\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.9359 - val_loss: 3.8494\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.8874 - val_loss: 3.8019\n",
      "Epoch 36/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 102us/sample - loss: 3.8544 - val_loss: 3.7761\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.8175 - val_loss: 3.7230\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7943 - val_loss: 3.6893\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7502 - val_loss: 3.6554\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.7320 - val_loss: 3.6174\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.6796 - val_loss: 3.5833\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.6437 - val_loss: 3.5489\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6006 - val_loss: 3.5124\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.5832 - val_loss: 3.4998\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.5354 - val_loss: 3.4570\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.5230 - val_loss: 3.4282\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.4846 - val_loss: 3.3993\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.4414 - val_loss: 3.3688\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.4327 - val_loss: 3.3414\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.3858 - val_loss: 3.3109\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.3577 - val_loss: 3.2758\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.3408 - val_loss: 3.2540\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.3242 - val_loss: 3.2363\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.2920 - val_loss: 3.2165\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.2801 - val_loss: 3.2030\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.2743 - val_loss: 3.1979\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.2634 - val_loss: 3.1893\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.2464 - val_loss: 3.1705\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.2290 - val_loss: 3.1657\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.2344 - val_loss: 3.1587\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.2194 - val_loss: 3.1422\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.2102 - val_loss: 3.1290\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.2013 - val_loss: 3.1187\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.1857 - val_loss: 3.1129\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.1914 - val_loss: 3.1065\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.1844 - val_loss: 3.1035\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.1724 - val_loss: 3.0934\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.1760 - val_loss: 3.0929\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1625 - val_loss: 3.0832\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.1425 - val_loss: 3.0698\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1577 - val_loss: 3.0652\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1363 - val_loss: 3.0687\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1292 - val_loss: 3.0509\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.1263 - val_loss: 3.0411\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.1183 - val_loss: 3.0477\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.1138 - val_loss: 3.0304\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.1122 - val_loss: 3.0266\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.1119 - val_loss: 3.0283\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.1085 - val_loss: 3.0280\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.1016 - val_loss: 3.0150\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.1098 - val_loss: 3.0151\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.0968 - val_loss: 3.0188\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 3.1061 - val_loss: 3.0057\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.0946 - val_loss: 2.9997\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.0848 - val_loss: 3.0038\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0798 - val_loss: 2.9966\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0736 - val_loss: 3.0014\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0760 - val_loss: 2.9877\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.0689 - val_loss: 2.9782\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.0676 - val_loss: 2.9758\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.0610 - val_loss: 2.9877\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.0660 - val_loss: 2.9722\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.0493 - val_loss: 2.9619\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0720 - val_loss: 2.9653\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.0527 - val_loss: 2.9660\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.0516 - val_loss: 2.9785\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0480 - val_loss: 2.9537\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.0373 - val_loss: 2.9525\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0392 - val_loss: 2.9584\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.0574 - val_loss: 2.9523\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.0382 - val_loss: 2.9502\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.0388 - val_loss: 2.9446\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0410 - val_loss: 2.9408\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0363 - val_loss: 2.9364\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.0374 - val_loss: 2.9416\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.0167 - val_loss: 2.9331\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0309 - val_loss: 2.9333\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.0268 - val_loss: 2.9316\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.0377 - val_loss: 2.9274\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.0305 - val_loss: 2.9246\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.0222 - val_loss: 2.9242\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.0117 - val_loss: 2.9158\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.0143 - val_loss: 2.9178\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.0135 - val_loss: 2.9230\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.0081 - val_loss: 2.9156\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.0052 - val_loss: 2.9066\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.0011 - val_loss: 2.9129\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.0067 - val_loss: 2.9033\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.0020 - val_loss: 2.9051\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9967 - val_loss: 2.9007\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9960 - val_loss: 2.9040\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9998 - val_loss: 2.9016\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.9990 - val_loss: 2.8997\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9925 - val_loss: 2.8977\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9912 - val_loss: 2.9135\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.9948 - val_loss: 2.9104\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9975 - val_loss: 2.9028\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9871 - val_loss: 2.8911\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.9971 - val_loss: 2.8952\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9965 - val_loss: 2.8872\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9852 - val_loss: 2.8833\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9745 - val_loss: 2.8946\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.9865 - val_loss: 2.8854\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.9816 - val_loss: 2.8953\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9733 - val_loss: 2.8766\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9624 - val_loss: 2.8758\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9807 - val_loss: 2.8788\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9791 - val_loss: 2.8821\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.9742 - val_loss: 2.8819\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9679 - val_loss: 2.8947\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9719 - val_loss: 2.8721\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9684 - val_loss: 2.8684\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9707 - val_loss: 2.8923\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9685 - val_loss: 2.8735\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9638 - val_loss: 2.8678\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9615 - val_loss: 2.8693\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9650 - val_loss: 2.8855\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9638 - val_loss: 2.8630\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9599 - val_loss: 2.8823\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9611 - val_loss: 2.8649\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.9583 - val_loss: 2.8615\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9600 - val_loss: 2.8605\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9468 - val_loss: 2.8583\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9498 - val_loss: 2.8751\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9582 - val_loss: 2.8552\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9500 - val_loss: 2.8608\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 2.9634 - val_loss: 2.8583\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9505 - val_loss: 2.8538\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.9555 - val_loss: 2.8621\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9468 - val_loss: 2.8502\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 2.9541 - val_loss: 2.8516\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.9545 - val_loss: 2.8460\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.9444 - val_loss: 2.8448\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.9481 - val_loss: 2.8494\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9460 - val_loss: 2.8498\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9379 - val_loss: 2.8463\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9433 - val_loss: 2.8431\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.9498 - val_loss: 2.8476\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9448 - val_loss: 2.8548\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9572 - val_loss: 2.8509\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.9356 - val_loss: 2.8436\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9401 - val_loss: 2.8523\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9320 - val_loss: 2.8383\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 2.9324 - val_loss: 2.8494\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 2.9320 - val_loss: 2.8384\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.9425 - val_loss: 2.8359\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.9376 - val_loss: 2.8351\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9255 - val_loss: 2.8371\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9410 - val_loss: 2.8308\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.9284 - val_loss: 2.8326\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.9289 - val_loss: 2.8295\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.9248 - val_loss: 2.8329\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9248 - val_loss: 2.8319\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9239 - val_loss: 2.8328\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9324 - val_loss: 2.8298\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9267 - val_loss: 2.8524\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9287 - val_loss: 2.8333\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9337 - val_loss: 2.8340\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.9139 - val_loss: 2.8501\n",
      "Epoch 190/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 96us/sample - loss: 2.9493 - val_loss: 2.8282\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9226 - val_loss: 2.8340\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.9186 - val_loss: 2.8211\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.9256 - val_loss: 2.8216\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 2.9356 - val_loss: 2.8212\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9185 - val_loss: 2.8293\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.9160 - val_loss: 2.8169\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.9143 - val_loss: 2.8167\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9198 - val_loss: 2.8254\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9172 - val_loss: 2.8183\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9165 - val_loss: 2.8219\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.9236 - val_loss: 2.8201\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9087 - val_loss: 2.8310\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.9099 - val_loss: 2.8197\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9283 - val_loss: 2.8165\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9154 - val_loss: 2.8200\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.9256 - val_loss: 2.8164\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9076 - val_loss: 2.8190\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.9201 - val_loss: 2.8107\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9081 - val_loss: 2.8147\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9066 - val_loss: 2.8272\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.9099 - val_loss: 2.8131\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9163 - val_loss: 2.8086\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.9061 - val_loss: 2.8090\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.9107 - val_loss: 2.8108\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.9031 - val_loss: 2.8043\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9184 - val_loss: 2.8112\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.9123 - val_loss: 2.8127\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.8973 - val_loss: 2.8139\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.9152 - val_loss: 2.8049\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 2.8955 - val_loss: 2.8079\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.9114 - val_loss: 2.8079\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.9077 - val_loss: 2.8085\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8962 - val_loss: 2.8128\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 2.8968 - val_loss: 2.8113\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9015 - val_loss: 2.8070\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9044 - val_loss: 2.7995\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8997 - val_loss: 2.7991\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9096 - val_loss: 2.8002\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.9094 - val_loss: 2.8013\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 2.8998 - val_loss: 2.7970\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 2.9066 - val_loss: 2.8061\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9045 - val_loss: 2.7998\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8960 - val_loss: 2.7986\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8791 - val_loss: 2.7962\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8965 - val_loss: 2.8001\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.8862 - val_loss: 2.7937\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.9039 - val_loss: 2.7988\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.9003 - val_loss: 2.8023\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8939 - val_loss: 2.7992\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8849 - val_loss: 2.7930\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8944 - val_loss: 2.8094\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8950 - val_loss: 2.7974\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8860 - val_loss: 2.8209\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8867 - val_loss: 2.7904\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8947 - val_loss: 2.7994\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.8934 - val_loss: 2.7975\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8790 - val_loss: 2.7850\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8874 - val_loss: 2.7924\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.8779 - val_loss: 2.7813\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8845 - val_loss: 2.7917\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8861 - val_loss: 2.7884\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8846 - val_loss: 2.7865\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8877 - val_loss: 2.8074\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8812 - val_loss: 2.7919\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8890 - val_loss: 2.7906\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8870 - val_loss: 2.7805\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8802 - val_loss: 2.7834\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8850 - val_loss: 2.7809\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8852 - val_loss: 2.7876\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8834 - val_loss: 2.7837\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 2.8850 - val_loss: 2.7800\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8817 - val_loss: 2.7823\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8751 - val_loss: 2.7870\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8759 - val_loss: 2.8005\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8786 - val_loss: 2.7799\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8772 - val_loss: 2.7782\n",
      "Epoch 267/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8891 - val_loss: 2.7783\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8748 - val_loss: 2.7803\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.8826 - val_loss: 2.7753\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8735 - val_loss: 2.7820\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8880 - val_loss: 2.7810\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8867 - val_loss: 2.7794\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8844 - val_loss: 2.7834\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8771 - val_loss: 2.7754\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8718 - val_loss: 2.7796\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8665 - val_loss: 2.7791\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8650 - val_loss: 2.7905\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8866 - val_loss: 2.7745\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8724 - val_loss: 2.8040\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8765 - val_loss: 2.7889\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8788 - val_loss: 2.7799\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8746 - val_loss: 2.7722\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8856 - val_loss: 2.7959\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8720 - val_loss: 2.7812\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8758 - val_loss: 2.7764\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.8750 - val_loss: 2.7902\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8881 - val_loss: 2.7746\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 2.8717 - val_loss: 2.7754\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8805 - val_loss: 2.7681\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8640 - val_loss: 2.7777\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8743 - val_loss: 2.7757\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 2.8616 - val_loss: 2.7664\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8730 - val_loss: 2.7858\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 2.8782 - val_loss: 2.7643\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8613 - val_loss: 2.7970\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8571 - val_loss: 2.7726\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8611 - val_loss: 2.7632\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 2.8528 - val_loss: 2.7669\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8626 - val_loss: 2.7649\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8668 - val_loss: 2.7619\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8585 - val_loss: 2.7784\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 2.8574 - val_loss: 2.7654\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8786 - val_loss: 2.7698\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8567 - val_loss: 2.7672\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 2.8558 - val_loss: 2.7615\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8647 - val_loss: 2.7668\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.8673 - val_loss: 2.7658\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8529 - val_loss: 2.7633\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8549 - val_loss: 2.7634\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8628 - val_loss: 2.7778\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8557 - val_loss: 2.7640\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8600 - val_loss: 2.7573\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 2.8516 - val_loss: 2.7567\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8531 - val_loss: 2.7566\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 2.8661 - val_loss: 2.7611\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8599 - val_loss: 2.7807\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8538 - val_loss: 2.7597\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8532 - val_loss: 2.7588\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 2.8696 - val_loss: 2.7625\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8440 - val_loss: 2.7824\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8594 - val_loss: 2.7602\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.8603 - val_loss: 2.7551\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8413 - val_loss: 2.7647\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8510 - val_loss: 2.7554\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8613 - val_loss: 2.7535\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 2.8415 - val_loss: 2.7596\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 2.8500 - val_loss: 2.7597\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8519 - val_loss: 2.7586\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 2.8458 - val_loss: 2.7574\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8505 - val_loss: 2.7478\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 2.8519 - val_loss: 2.7657\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 2.8399 - val_loss: 2.7489\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 2.8473 - val_loss: 2.7752\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8491 - val_loss: 2.7698\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8499 - val_loss: 2.7481\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8610 - val_loss: 2.7512\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 2.8587 - val_loss: 2.7493\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8429 - val_loss: 2.7629\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 2.8490 - val_loss: 2.7512\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 2.8485 - val_loss: 2.7478\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 380us/sample - loss: 11.1998 - val_loss: 7.3882\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 7.5459 - val_loss: 7.1602\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 7.3203 - val_loss: 7.0282\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 65us/sample - loss: 7.1072 - val_loss: 6.9004\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 7.0063 - val_loss: 6.8051\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 6.9091 - val_loss: 6.7422\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.7872 - val_loss: 6.6534\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 6.6850 - val_loss: 6.5678\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.6110 - val_loss: 6.4909\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.5197 - val_loss: 6.4057\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.4120 - val_loss: 6.3293\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.3304 - val_loss: 6.2578\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.2616 - val_loss: 6.1718\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.2038 - val_loss: 6.0974\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.1117 - val_loss: 6.0261\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.0388 - val_loss: 5.9489\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 5.9824 - val_loss: 5.8756\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.8914 - val_loss: 5.8075\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 5.8643 - val_loss: 5.7499\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 5.7844 - val_loss: 5.6802\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 5.6859 - val_loss: 5.6080\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.6178 - val_loss: 5.5463\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 5.5709 - val_loss: 5.4777\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 5.5127 - val_loss: 5.4197\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 5.4504 - val_loss: 5.3504\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 5.3761 - val_loss: 5.2876\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 5.3126 - val_loss: 5.2270\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 5.2568 - val_loss: 5.1680\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 5.2020 - val_loss: 5.1122\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.1384 - val_loss: 5.0551\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 5.0810 - val_loss: 4.9997\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 5.0246 - val_loss: 4.9441\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9744 - val_loss: 4.8919\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.9153 - val_loss: 4.8426\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8621 - val_loss: 4.7823\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8080 - val_loss: 4.7266\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7566 - val_loss: 4.6740\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.6990 - val_loss: 4.6240\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 4.6400 - val_loss: 4.5790\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.6107 - val_loss: 4.5294\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.5663 - val_loss: 4.4840\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.5115 - val_loss: 4.4375\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.4543 - val_loss: 4.3861\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.4036 - val_loss: 4.3448\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 4.3777 - val_loss: 4.3121\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 4.3273 - val_loss: 4.2708\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 4.2990 - val_loss: 4.2341\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.2514 - val_loss: 4.2004\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 4.2280 - val_loss: 4.1693\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.1940 - val_loss: 4.1563\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.1799 - val_loss: 4.1202\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.1521 - val_loss: 4.0977\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.1320 - val_loss: 4.0764\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.1167 - val_loss: 4.0574\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.0879 - val_loss: 4.0354\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.0628 - val_loss: 4.0176\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 4.0404 - val_loss: 3.9997\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.0526 - val_loss: 3.9889\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.0214 - val_loss: 3.9668\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 4.0036 - val_loss: 3.9482\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.0037 - val_loss: 3.9396\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.9903 - val_loss: 3.9311\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 3.9873 - val_loss: 3.9319\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.9725 - val_loss: 3.9161\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.9699 - val_loss: 3.9121\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.9669 - val_loss: 3.8981\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.9664 - val_loss: 3.8905\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.9454 - val_loss: 3.8840\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.9447 - val_loss: 3.8758\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.9344 - val_loss: 3.8722\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.9302 - val_loss: 3.8618\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.9260 - val_loss: 3.8563\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.9267 - val_loss: 3.8490\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 3.9216 - val_loss: 3.8438\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 3.9066 - val_loss: 3.8357\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.9139 - val_loss: 3.8335\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 3.9072 - val_loss: 3.8319\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.8903 - val_loss: 3.8235\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.8946 - val_loss: 3.8296\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.8944 - val_loss: 3.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.8877 - val_loss: 3.8093\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 3.8863 - val_loss: 3.8055\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8697 - val_loss: 3.7997\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8781 - val_loss: 3.7970\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8730 - val_loss: 3.8053\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.8727 - val_loss: 3.7978\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.8682 - val_loss: 3.7886\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.8618 - val_loss: 3.7816\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 3.8613 - val_loss: 3.7845\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.8574 - val_loss: 3.7756\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8505 - val_loss: 3.7859\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8538 - val_loss: 3.7775\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.8516 - val_loss: 3.7695\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.8526 - val_loss: 3.7689\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.8457 - val_loss: 3.7701\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.8471 - val_loss: 3.7634\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.8468 - val_loss: 3.7613\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.8384 - val_loss: 3.7622\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.8440 - val_loss: 3.7550\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.8237 - val_loss: 3.7521\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 77us/sample - loss: 3.8295 - val_loss: 3.7482\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8292 - val_loss: 3.7509\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.8260 - val_loss: 3.7503\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.8205 - val_loss: 3.7460\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.8151 - val_loss: 3.7527\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.8165 - val_loss: 3.7372\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.8249 - val_loss: 3.7369\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8113 - val_loss: 3.7464\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.8169 - val_loss: 3.7291\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.8148 - val_loss: 3.7346\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.8156 - val_loss: 3.7353\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.8191 - val_loss: 3.7238\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8168 - val_loss: 3.7206\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.8040 - val_loss: 3.7187\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.8081 - val_loss: 3.7212\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.8161 - val_loss: 3.7248\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.7941 - val_loss: 3.7119\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.8110 - val_loss: 3.7090\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.8038 - val_loss: 3.7083\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7989 - val_loss: 3.7120\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.7855 - val_loss: 3.7087\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.8062 - val_loss: 3.7165\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.7952 - val_loss: 3.7016\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7947 - val_loss: 3.7048\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7994 - val_loss: 3.7000\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.7823 - val_loss: 3.6968\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7859 - val_loss: 3.7041\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7918 - val_loss: 3.6933\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 3.7933 - val_loss: 3.6947\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7820 - val_loss: 3.6911\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7988 - val_loss: 3.6901\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.7763 - val_loss: 3.6996\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7814 - val_loss: 3.6903\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7872 - val_loss: 3.6897\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7751 - val_loss: 3.6889\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7664 - val_loss: 3.6870\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.7957 - val_loss: 3.6830\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7829 - val_loss: 3.6885\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7805 - val_loss: 3.6988\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7749 - val_loss: 3.6747\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7784 - val_loss: 3.6731\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7750 - val_loss: 3.6765\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.7633 - val_loss: 3.6743\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7665 - val_loss: 3.6712\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7613 - val_loss: 3.6726\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.7686 - val_loss: 3.6797\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7638 - val_loss: 3.6786\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7710 - val_loss: 3.6665\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7698 - val_loss: 3.6652\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7783 - val_loss: 3.6713\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.7753 - val_loss: 3.6842\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7611 - val_loss: 3.6648\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7688 - val_loss: 3.6632\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.7690 - val_loss: 3.6664\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.7605 - val_loss: 3.6586\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7497 - val_loss: 3.6591\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7667 - val_loss: 3.6571\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7468 - val_loss: 3.6585\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7611 - val_loss: 3.6603\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7468 - val_loss: 3.6646\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7513 - val_loss: 3.6571\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7696 - val_loss: 3.6574\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7561 - val_loss: 3.6624\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7353 - val_loss: 3.6548\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.7389 - val_loss: 3.6526\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7452 - val_loss: 3.6549\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7455 - val_loss: 3.6486\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7462 - val_loss: 3.6512\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7394 - val_loss: 3.6452\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7501 - val_loss: 3.6527\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.7442 - val_loss: 3.6507\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.7472 - val_loss: 3.6562\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7432 - val_loss: 3.6467\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 3.7570 - val_loss: 3.6493\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 3.7474 - val_loss: 3.6547\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7441 - val_loss: 3.6468\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 3.7374 - val_loss: 3.6477\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7293 - val_loss: 3.6665\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7331 - val_loss: 3.6528\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7478 - val_loss: 3.6398\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.7346 - val_loss: 3.6383\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.7370 - val_loss: 3.6419\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7434 - val_loss: 3.6581\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.7455 - val_loss: 3.6394\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7258 - val_loss: 3.6344\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7302 - val_loss: 3.6366\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.7418 - val_loss: 3.6368\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7343 - val_loss: 3.6361\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7402 - val_loss: 3.6412\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7381 - val_loss: 3.6318\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7259 - val_loss: 3.6319\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7363 - val_loss: 3.6356\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.7299 - val_loss: 3.6349\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7261 - val_loss: 3.6284\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7257 - val_loss: 3.6306\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7332 - val_loss: 3.6309\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7219 - val_loss: 3.6319\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7184 - val_loss: 3.6454\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 3.7257 - val_loss: 3.6313\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.7290 - val_loss: 3.6381\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 3.7387 - val_loss: 3.6295\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 69us/sample - loss: 3.7187 - val_loss: 3.6346\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.7274 - val_loss: 3.6286\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 68us/sample - loss: 3.7221 - val_loss: 3.6444\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 3.7242 - val_loss: 3.6292\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7275 - val_loss: 3.6202\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 3.7152 - val_loss: 3.6278\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7271 - val_loss: 3.6271\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7262 - val_loss: 3.6235\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7254 - val_loss: 3.6451\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7244 - val_loss: 3.6350\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7127 - val_loss: 3.6208\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 3.7229 - val_loss: 3.6265\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 3.7202 - val_loss: 3.6156\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.7251 - val_loss: 3.6282\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7141 - val_loss: 3.6279\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7256 - val_loss: 3.6185\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7091 - val_loss: 3.6243\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7188 - val_loss: 3.6341\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7247 - val_loss: 3.6198\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7025 - val_loss: 3.6133\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7097 - val_loss: 3.6120\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7191 - val_loss: 3.6275\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7166 - val_loss: 3.6134\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 3.7075 - val_loss: 3.6354\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.7190 - val_loss: 3.6123\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.7174 - val_loss: 3.6087\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7121 - val_loss: 3.6156\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 3.7019 - val_loss: 3.6130\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 3.7082 - val_loss: 3.6114\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.7060 - val_loss: 3.6147\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.7098 - val_loss: 3.6151\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7080 - val_loss: 3.6251\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7166 - val_loss: 3.6089\n",
      "Epoch 235/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7103 - val_loss: 3.6130\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 3.7122 - val_loss: 3.6222\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7064 - val_loss: 3.6076\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7109 - val_loss: 3.6136\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7111 - val_loss: 3.6101\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7076 - val_loss: 3.6249\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7159 - val_loss: 3.6100\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.7031 - val_loss: 3.6262\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7005 - val_loss: 3.6150\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.7078 - val_loss: 3.6111\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.7041 - val_loss: 3.6079\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7130 - val_loss: 3.6130\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.7110 - val_loss: 3.6078\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 67us/sample - loss: 3.6970 - val_loss: 3.6036\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 3.6993 - val_loss: 3.6065\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6951 - val_loss: 3.6016\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.6972 - val_loss: 3.6124\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7093 - val_loss: 3.6062\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 3.6895 - val_loss: 3.5987\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6976 - val_loss: 3.6021\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.7012 - val_loss: 3.6200\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.7098 - val_loss: 3.6391\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7004 - val_loss: 3.6455\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7069 - val_loss: 3.6064\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6948 - val_loss: 3.6024\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6900 - val_loss: 3.6017\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.7040 - val_loss: 3.5996\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.7054 - val_loss: 3.6057\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6808 - val_loss: 3.6097\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6925 - val_loss: 3.6070\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6863 - val_loss: 3.6073\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.7118 - val_loss: 3.6140\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.6936 - val_loss: 3.6044\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6933 - val_loss: 3.6079\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6978 - val_loss: 3.6007\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6923 - val_loss: 3.6076\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6936 - val_loss: 3.6039\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6771 - val_loss: 3.5940\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.6850 - val_loss: 3.5976\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6827 - val_loss: 3.5998\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6833 - val_loss: 3.5923\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6885 - val_loss: 3.5890\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6934 - val_loss: 3.5968\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 3.6912 - val_loss: 3.5972\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6867 - val_loss: 3.5980\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6900 - val_loss: 3.5957\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6772 - val_loss: 3.5921\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6878 - val_loss: 3.5944\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6864 - val_loss: 3.5978\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6850 - val_loss: 3.5933\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.6830 - val_loss: 3.5907\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.6894 - val_loss: 3.5983\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6976 - val_loss: 3.6004\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6757 - val_loss: 3.5892\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6775 - val_loss: 3.5836\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6768 - val_loss: 3.5854\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6939 - val_loss: 3.5938\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6855 - val_loss: 3.5929\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6814 - val_loss: 3.6082\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6931 - val_loss: 3.6321\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6755 - val_loss: 3.5946\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6776 - val_loss: 3.6012\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6804 - val_loss: 3.5890\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6874 - val_loss: 3.5951\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6883 - val_loss: 3.5928\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6736 - val_loss: 3.5908\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6807 - val_loss: 3.5900\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6855 - val_loss: 3.5923\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6814 - val_loss: 3.5970\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6787 - val_loss: 3.6181\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6840 - val_loss: 3.5859\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6787 - val_loss: 3.5884\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6721 - val_loss: 3.5907\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6690 - val_loss: 3.5836\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6675 - val_loss: 3.5831\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 3.6609 - val_loss: 3.5775\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6909 - val_loss: 3.5980\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6757 - val_loss: 3.5805\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.6586 - val_loss: 3.5813\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6690 - val_loss: 3.5780\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6602 - val_loss: 3.5888\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6695 - val_loss: 3.5757\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 3.6647 - val_loss: 3.5841\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 3.6728 - val_loss: 3.5778\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 3.6822 - val_loss: 3.5918\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6670 - val_loss: 3.5832\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 3.6673 - val_loss: 3.5762\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.6739 - val_loss: 3.5835\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6679 - val_loss: 3.5840\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 3.6630 - val_loss: 3.6341\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6706 - val_loss: 3.5848\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.6696 - val_loss: 3.5977\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 3.6766 - val_loss: 3.5824\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 3.6689 - val_loss: 3.5766\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 3.6822 - val_loss: 3.5782\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 3.6764 - val_loss: 3.5771\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 3.6629 - val_loss: 3.5779\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 3.6624 - val_loss: 3.5810\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6795 - val_loss: 3.5792\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 3.6633 - val_loss: 3.6359\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 3.6706 - val_loss: 3.5766\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 3.6646 - val_loss: 3.5781\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 3.6647 - val_loss: 3.5860\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6686 - val_loss: 3.5792\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 3.6544 - val_loss: 3.5878\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 3.6651 - val_loss: 3.6042\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 408us/sample - loss: 14.5832 - val_loss: 10.1800\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 9.7228 - val_loss: 9.2501\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 9.1814 - val_loss: 9.0593\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 9.0139 - val_loss: 8.9379\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 8.8790 - val_loss: 8.8258\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.7718 - val_loss: 8.7095\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.6622 - val_loss: 8.6028\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.5480 - val_loss: 8.4829\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.4458 - val_loss: 8.3738\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.3277 - val_loss: 8.2626\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.2200 - val_loss: 8.1609\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1134 - val_loss: 8.0462\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.0057 - val_loss: 7.9405\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 7.8998 - val_loss: 7.8383\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 7.7963 - val_loss: 7.7313\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 7.6931 - val_loss: 7.6245\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 7.5834 - val_loss: 7.5184\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 7.4879 - val_loss: 7.4235\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 7.3759 - val_loss: 7.3063\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 7.2745 - val_loss: 7.2015\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 7.1758 - val_loss: 7.0977\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 7.0743 - val_loss: 7.0023\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.9670 - val_loss: 6.9033\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.8646 - val_loss: 6.8034\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.7697 - val_loss: 6.7021\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.6839 - val_loss: 6.6092\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.5833 - val_loss: 6.5093\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.4821 - val_loss: 6.4131\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.3793 - val_loss: 6.3263\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2990 - val_loss: 6.2323\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2030 - val_loss: 6.1421\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1229 - val_loss: 6.0601\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.0322 - val_loss: 5.9687\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 5.9472 - val_loss: 5.8837\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.8577 - val_loss: 5.7886\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 5.7659 - val_loss: 5.7074\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.6934 - val_loss: 5.6296\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 5.5986 - val_loss: 5.5423\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 5.5208 - val_loss: 5.4674\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 5.4469 - val_loss: 5.3916\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.3837 - val_loss: 5.3228\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 5.3132 - val_loss: 5.2558\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 5.2516 - val_loss: 5.2012\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 5.1919 - val_loss: 5.1590\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 5.1669 - val_loss: 5.1334\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 5.1399 - val_loss: 5.1068\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 5.1224 - val_loss: 5.0897\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 5.0938 - val_loss: 5.0654\n",
      "Epoch 49/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 100us/sample - loss: 5.0755 - val_loss: 5.0481\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 5.0668 - val_loss: 5.0385\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 5.0510 - val_loss: 5.0257\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.0473 - val_loss: 5.0151\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.0427 - val_loss: 5.0120\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 5.0365 - val_loss: 5.0078\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 5.0293 - val_loss: 5.0012\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 5.0222 - val_loss: 4.9905\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 5.0217 - val_loss: 4.9861\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 5.0170 - val_loss: 4.9838\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 5.0055 - val_loss: 4.9748\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 5.0030 - val_loss: 4.9663\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 5.0069 - val_loss: 4.9602\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9832 - val_loss: 4.9550\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 4.9846 - val_loss: 4.9467\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9801 - val_loss: 4.9365\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.9796 - val_loss: 4.9332\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.9872 - val_loss: 4.9310\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.9639 - val_loss: 4.9225\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9607 - val_loss: 4.9136\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.9665 - val_loss: 4.9064\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9563 - val_loss: 4.9015\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9553 - val_loss: 4.8966\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9637 - val_loss: 4.8924\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9494 - val_loss: 4.8922\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9503 - val_loss: 4.8855\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.9511 - val_loss: 4.8956\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9375 - val_loss: 4.8811\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9481 - val_loss: 4.8745\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9430 - val_loss: 4.8905\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9460 - val_loss: 4.8675\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.9294 - val_loss: 4.8759\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9427 - val_loss: 4.8594\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.9348 - val_loss: 4.8623\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.9286 - val_loss: 4.8536\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9247 - val_loss: 4.8528\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9262 - val_loss: 4.8524\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9191 - val_loss: 4.8547\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9322 - val_loss: 4.8417\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.9103 - val_loss: 4.8376\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.9224 - val_loss: 4.8429\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.9220 - val_loss: 4.8323\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.9170 - val_loss: 4.8315\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9150 - val_loss: 4.8341\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.9012 - val_loss: 4.8285\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.9133 - val_loss: 4.8270\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9088 - val_loss: 4.8276\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.9141 - val_loss: 4.8258\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9073 - val_loss: 4.8278\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.9029 - val_loss: 4.8234\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9010 - val_loss: 4.8170\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.9054 - val_loss: 4.8295\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8979 - val_loss: 4.8155\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.9017 - val_loss: 4.8133\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8943 - val_loss: 4.8038\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9039 - val_loss: 4.8029\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.9033 - val_loss: 4.8076\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.9062 - val_loss: 4.8019\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8914 - val_loss: 4.8077\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8962 - val_loss: 4.8198\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8911 - val_loss: 4.7937\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.8829 - val_loss: 4.7953\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.8928 - val_loss: 4.7912\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8826 - val_loss: 4.7896\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8942 - val_loss: 4.7876\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8811 - val_loss: 4.7899\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8808 - val_loss: 4.7980\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8899 - val_loss: 4.7823\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8767 - val_loss: 4.7807\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8871 - val_loss: 4.7861\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8846 - val_loss: 4.7904\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8810 - val_loss: 4.7793\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8916 - val_loss: 4.7738\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.8927 - val_loss: 4.7738\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8840 - val_loss: 4.7797\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8808 - val_loss: 4.7735\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8720 - val_loss: 4.7687\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 4.8773 - val_loss: 4.8013\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8719 - val_loss: 4.7656\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8712 - val_loss: 4.7651\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.8721 - val_loss: 4.7616\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8706 - val_loss: 4.7618\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 4.8726 - val_loss: 4.7578\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8724 - val_loss: 4.7582\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8620 - val_loss: 4.7554\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8617 - val_loss: 4.7678\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8553 - val_loss: 4.7581\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8529 - val_loss: 4.7608\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8594 - val_loss: 4.7473\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8634 - val_loss: 4.7461\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8565 - val_loss: 4.7682\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8619 - val_loss: 4.7441\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.8629 - val_loss: 4.7414\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8658 - val_loss: 4.7409\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8568 - val_loss: 4.7599\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8582 - val_loss: 4.7381\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8622 - val_loss: 4.7404\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8642 - val_loss: 4.7460\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8440 - val_loss: 4.7332\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8500 - val_loss: 4.7445\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8699 - val_loss: 4.7429\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8641 - val_loss: 4.7564\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8609 - val_loss: 4.7347\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 4.8448 - val_loss: 4.7395\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8486 - val_loss: 4.7281\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8412 - val_loss: 4.7326\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 4.8443 - val_loss: 4.7402\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.8515 - val_loss: 4.7361\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8494 - val_loss: 4.7387\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8480 - val_loss: 4.7226\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8507 - val_loss: 4.7192\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8571 - val_loss: 4.7450\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8414 - val_loss: 4.7175\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8557 - val_loss: 4.7217\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8420 - val_loss: 4.7178\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8411 - val_loss: 4.7209\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8424 - val_loss: 4.7134\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8469 - val_loss: 4.7540\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8386 - val_loss: 4.7101\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8478 - val_loss: 4.7118\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8403 - val_loss: 4.7083\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8413 - val_loss: 4.7148\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8358 - val_loss: 4.7035\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8533 - val_loss: 4.7089\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8334 - val_loss: 4.7083\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8397 - val_loss: 4.7045\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8421 - val_loss: 4.7040\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8225 - val_loss: 4.7094\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8387 - val_loss: 4.6981\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8443 - val_loss: 4.7120\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8374 - val_loss: 4.7242\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8281 - val_loss: 4.6981\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8283 - val_loss: 4.6961\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 4.8348 - val_loss: 4.7023\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8268 - val_loss: 4.6987\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8366 - val_loss: 4.6913\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8337 - val_loss: 4.7145\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8262 - val_loss: 4.6911\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8351 - val_loss: 4.6905\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8332 - val_loss: 4.6914\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8271 - val_loss: 4.6864\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.8292 - val_loss: 4.6916\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8320 - val_loss: 4.6931\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8470 - val_loss: 4.6898\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8251 - val_loss: 4.6902\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8250 - val_loss: 4.6917\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 4.8217 - val_loss: 4.6868\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8251 - val_loss: 4.6845\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8323 - val_loss: 4.6945\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8262 - val_loss: 4.6905\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8223 - val_loss: 4.6788\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8277 - val_loss: 4.6869\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8105 - val_loss: 4.6794\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8253 - val_loss: 4.6805\n",
      "Epoch 203/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 92us/sample - loss: 4.8284 - val_loss: 4.6890\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8263 - val_loss: 4.6847\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 4.8199 - val_loss: 4.6856\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8174 - val_loss: 4.6785\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8217 - val_loss: 4.6758\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8110 - val_loss: 4.6730\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8191 - val_loss: 4.6796\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8217 - val_loss: 4.6850\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8250 - val_loss: 4.6741\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.8176 - val_loss: 4.7008\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8174 - val_loss: 4.6705\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8041 - val_loss: 4.6697\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8231 - val_loss: 4.6691\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8203 - val_loss: 4.6822\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8267 - val_loss: 4.6688\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8117 - val_loss: 4.6675\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8127 - val_loss: 4.6698\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8216 - val_loss: 4.6699\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8065 - val_loss: 4.6665\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 4.8243 - val_loss: 4.6666\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8150 - val_loss: 4.6687\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.8125 - val_loss: 4.6827\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8053 - val_loss: 4.6629\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8210 - val_loss: 4.6655\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8101 - val_loss: 4.6652\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8111 - val_loss: 4.6683\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8079 - val_loss: 4.6785\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8120 - val_loss: 4.6779\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8153 - val_loss: 4.6620\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8139 - val_loss: 4.6642\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8103 - val_loss: 4.6648\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8160 - val_loss: 4.6712\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8017 - val_loss: 4.6613\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 4.8135 - val_loss: 4.6580\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8040 - val_loss: 4.6826\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 4.8101 - val_loss: 4.6717\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 75us/sample - loss: 4.8037 - val_loss: 4.6576\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 76us/sample - loss: 4.8103 - val_loss: 4.6581\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8002 - val_loss: 4.6534\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8024 - val_loss: 4.6641\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 4.8063 - val_loss: 4.6560\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 4.8107 - val_loss: 4.6807\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8048 - val_loss: 4.6573\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8189 - val_loss: 4.6618\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 4.7987 - val_loss: 4.6541\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8018 - val_loss: 4.6558\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8209 - val_loss: 4.6550\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8128 - val_loss: 4.6825\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.7932 - val_loss: 4.6822\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.8091 - val_loss: 4.6631\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8154 - val_loss: 4.6528\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8135 - val_loss: 4.6528\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 4.8141 - val_loss: 4.6543\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 4.8063 - val_loss: 4.6811\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.7976 - val_loss: 4.6578\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.7995 - val_loss: 4.6491\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.8098 - val_loss: 4.6479\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.8084 - val_loss: 4.6547\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 4.8063 - val_loss: 4.6507\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.7870 - val_loss: 4.6468\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.8115 - val_loss: 4.6503\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.8065 - val_loss: 4.6791\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.7998 - val_loss: 4.6484\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8003 - val_loss: 4.6455\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8002 - val_loss: 4.6460\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.8051 - val_loss: 4.6514\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.7909 - val_loss: 4.6467\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7890 - val_loss: 4.6719\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8088 - val_loss: 4.6452\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7881 - val_loss: 4.6488\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7975 - val_loss: 4.6441\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8030 - val_loss: 4.6533\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7970 - val_loss: 4.6537\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8099 - val_loss: 4.6558\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7974 - val_loss: 4.6422\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7945 - val_loss: 4.6636\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8032 - val_loss: 4.6438\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.7958 - val_loss: 4.6427\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8036 - val_loss: 4.6494\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7946 - val_loss: 4.6433\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 4.7892 - val_loss: 4.6648\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7982 - val_loss: 4.6392\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 4.7901 - val_loss: 4.6405\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.8024 - val_loss: 4.6390\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 4.7887 - val_loss: 4.6397\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.7873 - val_loss: 4.6534\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.8012 - val_loss: 4.6537\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7953 - val_loss: 4.6411\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7849 - val_loss: 4.6505\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.7822 - val_loss: 4.6362\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8007 - val_loss: 4.6422\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7905 - val_loss: 4.6357\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7910 - val_loss: 4.6350\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7788 - val_loss: 4.6360\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7939 - val_loss: 4.6427\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7827 - val_loss: 4.6334\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7951 - val_loss: 4.6658\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7801 - val_loss: 4.6439\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.7831 - val_loss: 4.6444\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7929 - val_loss: 4.6310\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7832 - val_loss: 4.6388\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7922 - val_loss: 4.6385\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 4.7882 - val_loss: 4.6446\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7924 - val_loss: 4.6327\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 4.7800 - val_loss: 4.6417\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7846 - val_loss: 4.6413\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7774 - val_loss: 4.6282\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.7943 - val_loss: 4.6397\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7988 - val_loss: 4.6335\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.7980 - val_loss: 4.6297\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7829 - val_loss: 4.6603\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.7913 - val_loss: 4.6285\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7906 - val_loss: 4.6469\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7846 - val_loss: 4.6376\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7884 - val_loss: 4.6386\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.7846 - val_loss: 4.6360\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7938 - val_loss: 4.6388\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 4.7846 - val_loss: 4.6422\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.7829 - val_loss: 4.6394\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 4.7878 - val_loss: 4.6275\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7924 - val_loss: 4.6314\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.7935 - val_loss: 4.6404\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7874 - val_loss: 4.6335\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.7905 - val_loss: 4.6323\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7794 - val_loss: 4.6266\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7883 - val_loss: 4.6283\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 4.7955 - val_loss: 4.6308\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 4.7801 - val_loss: 4.6631\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.7795 - val_loss: 4.6260\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.8010 - val_loss: 4.6276\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7859 - val_loss: 4.6289\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 4.7816 - val_loss: 4.6248\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7912 - val_loss: 4.6311\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 4.7816 - val_loss: 4.6255\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 4.7806 - val_loss: 4.6253\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 4.7915 - val_loss: 4.6248\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 4.7809 - val_loss: 4.6349\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 4.7753 - val_loss: 4.6231\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 408us/sample - loss: 19.0098 - val_loss: 12.9490\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 12.6980 - val_loss: 12.1797\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 12.1853 - val_loss: 11.9169\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 11.9415 - val_loss: 11.7068\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 11.7412 - val_loss: 11.5316\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 11.5137 - val_loss: 11.3719\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 11.3684 - val_loss: 11.2314\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 11.2097 - val_loss: 11.0721\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 11.0513 - val_loss: 10.9260\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.9084 - val_loss: 10.7945\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7420 - val_loss: 10.6382\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6039 - val_loss: 10.4876\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.4617 - val_loss: 10.3412\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.3096 - val_loss: 10.1910\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.1713 - val_loss: 10.0488\n",
      "Epoch 16/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 95us/sample - loss: 10.0286 - val_loss: 9.8979\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 9.8724 - val_loss: 9.7644\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 9.7380 - val_loss: 9.6080\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 9.5943 - val_loss: 9.4626\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 9.4448 - val_loss: 9.3181\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 9.3122 - val_loss: 9.1828\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 9.1703 - val_loss: 9.0401\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 9.0277 - val_loss: 8.8942\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.8765 - val_loss: 8.7526\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.7368 - val_loss: 8.6254\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.6098 - val_loss: 8.4776\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.4656 - val_loss: 8.3419\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.3282 - val_loss: 8.2060\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2016 - val_loss: 8.0839\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.0790 - val_loss: 7.9527\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 7.9548 - val_loss: 7.8338\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 7.8170 - val_loss: 7.7061\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 7.7046 - val_loss: 7.5789\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 7.5786 - val_loss: 7.4653\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 7.4626 - val_loss: 7.3407\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 7.3427 - val_loss: 7.2384\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 7.2379 - val_loss: 7.1267\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 7.1188 - val_loss: 7.0131\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 7.0150 - val_loss: 6.9084\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.9153 - val_loss: 6.8185\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.8178 - val_loss: 6.7298\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.7242 - val_loss: 6.6490\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.6550 - val_loss: 6.5986\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.6135 - val_loss: 6.5490\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.5598 - val_loss: 6.5085\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.5152 - val_loss: 6.4599\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.4772 - val_loss: 6.4267\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.4567 - val_loss: 6.4001\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.4351 - val_loss: 6.3936\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.4295 - val_loss: 6.3837\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.4246 - val_loss: 6.3803\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.4144 - val_loss: 6.3694\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.4086 - val_loss: 6.3657\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.3988 - val_loss: 6.3634\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.3921 - val_loss: 6.3512\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.3911 - val_loss: 6.3425\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.3888 - val_loss: 6.3452\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.3938 - val_loss: 6.3330\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.3816 - val_loss: 6.3321\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.3733 - val_loss: 6.3291\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.3687 - val_loss: 6.3170\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.3618 - val_loss: 6.3203\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.3633 - val_loss: 6.3142\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.3556 - val_loss: 6.3066\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.3521 - val_loss: 6.3084\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.3455 - val_loss: 6.3025\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.3448 - val_loss: 6.2890\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.3524 - val_loss: 6.2934\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.3363 - val_loss: 6.2808\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.3280 - val_loss: 6.2905\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.3304 - val_loss: 6.2722\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.3210 - val_loss: 6.2671\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 362us/sample - loss: 6.3275 - val_loss: 6.2668\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 67us/sample - loss: 6.3186 - val_loss: 6.2629\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 6.3255 - val_loss: 6.2605\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.3164 - val_loss: 6.2601\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.3042 - val_loss: 6.2507\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 6.3136 - val_loss: 6.2542\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.3123 - val_loss: 6.2468\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.3107 - val_loss: 6.2596\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.3045 - val_loss: 6.2392\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2998 - val_loss: 6.2395\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.3047 - val_loss: 6.2392\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2934 - val_loss: 6.2573\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2902 - val_loss: 6.2267\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.2913 - val_loss: 6.2355\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2828 - val_loss: 6.2217\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2875 - val_loss: 6.2238\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2859 - val_loss: 6.2321\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2860 - val_loss: 6.2153\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.2764 - val_loss: 6.2122\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.2719 - val_loss: 6.2229\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2827 - val_loss: 6.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2666 - val_loss: 6.2063\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2750 - val_loss: 6.2115\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2762 - val_loss: 6.2459\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2819 - val_loss: 6.2044\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2661 - val_loss: 6.2129\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.2673 - val_loss: 6.2145\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2592 - val_loss: 6.1964\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2651 - val_loss: 6.1946\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2605 - val_loss: 6.1981\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2620 - val_loss: 6.1951\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2607 - val_loss: 6.1856\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.2576 - val_loss: 6.1840\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.2582 - val_loss: 6.1883\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.2432 - val_loss: 6.1815\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2558 - val_loss: 6.1829\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2566 - val_loss: 6.1819\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2533 - val_loss: 6.1874\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2544 - val_loss: 6.1775\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2428 - val_loss: 6.1777\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2461 - val_loss: 6.1902\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2498 - val_loss: 6.1797\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2386 - val_loss: 6.1793\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2413 - val_loss: 6.1672\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2395 - val_loss: 6.1734\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.2428 - val_loss: 6.1633\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2483 - val_loss: 6.1684\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2418 - val_loss: 6.1690\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 6.2357 - val_loss: 6.1590\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2442 - val_loss: 6.1593\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2283 - val_loss: 6.1558\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2305 - val_loss: 6.1534\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2274 - val_loss: 6.1553\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.2438 - val_loss: 6.1568\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2322 - val_loss: 6.1573\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.2243 - val_loss: 6.1639\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2213 - val_loss: 6.1516\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.2299 - val_loss: 6.1466\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2256 - val_loss: 6.1789\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2268 - val_loss: 6.1444\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2219 - val_loss: 6.1436\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2287 - val_loss: 6.1443\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.2109 - val_loss: 6.1482\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2176 - val_loss: 6.1507\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.2200 - val_loss: 6.1411\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.2259 - val_loss: 6.1390\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2263 - val_loss: 6.1516\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2211 - val_loss: 6.1368\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.2159 - val_loss: 6.1362\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2190 - val_loss: 6.1389\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2082 - val_loss: 6.1346\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2059 - val_loss: 6.1391\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2053 - val_loss: 6.1363\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2132 - val_loss: 6.1359\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 6.2239 - val_loss: 6.1281\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2177 - val_loss: 6.1538\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2090 - val_loss: 6.1444\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2049 - val_loss: 6.1451\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2178 - val_loss: 6.1383\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2106 - val_loss: 6.1310\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2181 - val_loss: 6.1229\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.2157 - val_loss: 6.1452\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.2094 - val_loss: 6.1257\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 6.2096 - val_loss: 6.1234\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.2093 - val_loss: 6.1473\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2102 - val_loss: 6.1215\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.2102 - val_loss: 6.1441\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.2083 - val_loss: 6.1167\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2017 - val_loss: 6.1152\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.2089 - val_loss: 6.1195\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.2085 - val_loss: 6.1184\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1909 - val_loss: 6.1254\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.2066 - val_loss: 6.1179\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 6.2090 - val_loss: 6.1135\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1995 - val_loss: 6.1147\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1992 - val_loss: 6.1124\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1952 - val_loss: 6.1095\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1937 - val_loss: 6.1081\n",
      "Epoch 171/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1953 - val_loss: 6.1088\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1954 - val_loss: 6.1042\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.2037 - val_loss: 6.1135\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1991 - val_loss: 6.1031\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1973 - val_loss: 6.1104\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1954 - val_loss: 6.1035\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1902 - val_loss: 6.1029\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.1964 - val_loss: 6.1182\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 6.1878 - val_loss: 6.0997\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1870 - val_loss: 6.1071\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1831 - val_loss: 6.1006\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1988 - val_loss: 6.0968\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1750 - val_loss: 6.1356\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1995 - val_loss: 6.1222\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1967 - val_loss: 6.1112\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1846 - val_loss: 6.1123\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1887 - val_loss: 6.0970\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1775 - val_loss: 6.1174\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1884 - val_loss: 6.1079\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1857 - val_loss: 6.0929\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1952 - val_loss: 6.0991\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1867 - val_loss: 6.0944\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1961 - val_loss: 6.0961\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1800 - val_loss: 6.1038\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1871 - val_loss: 6.0932\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1924 - val_loss: 6.0911\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1786 - val_loss: 6.0885\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.1910 - val_loss: 6.0941\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1863 - val_loss: 6.1043\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1904 - val_loss: 6.0896\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1793 - val_loss: 6.0906\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1891 - val_loss: 6.0887\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1915 - val_loss: 6.0940\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1779 - val_loss: 6.0854\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1731 - val_loss: 6.0907\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1796 - val_loss: 6.0849\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1687 - val_loss: 6.0954\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.1792 - val_loss: 6.0886\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1794 - val_loss: 6.0892\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1769 - val_loss: 6.0854\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1757 - val_loss: 6.0933\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1800 - val_loss: 6.0871\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1789 - val_loss: 6.1011\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1642 - val_loss: 6.0758\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1741 - val_loss: 6.0754\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.1773 - val_loss: 6.0755\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.1699 - val_loss: 6.0796\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 6.1761 - val_loss: 6.0720\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 6.1760 - val_loss: 6.0893\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1634 - val_loss: 6.0798\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1881 - val_loss: 6.0871\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1766 - val_loss: 6.0891\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1730 - val_loss: 6.1125\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1758 - val_loss: 6.0819\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1604 - val_loss: 6.0771\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.1714 - val_loss: 6.0811\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1765 - val_loss: 6.0704\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1615 - val_loss: 6.0725\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.1767 - val_loss: 6.0850\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.1692 - val_loss: 6.0806\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 6.1830 - val_loss: 6.0689\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1735 - val_loss: 6.0710\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1735 - val_loss: 6.0726\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1703 - val_loss: 6.0663\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1678 - val_loss: 6.0862\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1838 - val_loss: 6.0658\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1763 - val_loss: 6.0672\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1680 - val_loss: 6.0643\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1683 - val_loss: 6.0652\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1675 - val_loss: 6.0644\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1634 - val_loss: 6.0654\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1669 - val_loss: 6.0664\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 6.1627 - val_loss: 6.0670\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1700 - val_loss: 6.0667\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1720 - val_loss: 6.0926\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1642 - val_loss: 6.0747\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1648 - val_loss: 6.0770\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1704 - val_loss: 6.0606\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 6.1620 - val_loss: 6.1001\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1722 - val_loss: 6.0763\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 6.1668 - val_loss: 6.0717\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1769 - val_loss: 6.0978\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1686 - val_loss: 6.0588\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1661 - val_loss: 6.0590\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1659 - val_loss: 6.0604\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1714 - val_loss: 6.0565\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1670 - val_loss: 6.0586\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1684 - val_loss: 6.0634\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1598 - val_loss: 6.0603\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1651 - val_loss: 6.0658\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1543 - val_loss: 6.0717\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1706 - val_loss: 6.0545\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1627 - val_loss: 6.0624\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.1604 - val_loss: 6.0594\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1591 - val_loss: 6.1141\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1720 - val_loss: 6.0598\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1628 - val_loss: 6.0575\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1604 - val_loss: 6.0635\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1691 - val_loss: 6.0571\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1578 - val_loss: 6.0518\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1683 - val_loss: 6.0577\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1563 - val_loss: 6.0500\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1659 - val_loss: 6.0614\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.1602 - val_loss: 6.0573\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1486 - val_loss: 6.0928\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1678 - val_loss: 6.0482\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 6.1643 - val_loss: 6.0503\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1530 - val_loss: 6.0486\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1530 - val_loss: 6.0540\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1460 - val_loss: 6.0527\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1569 - val_loss: 6.0945\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1487 - val_loss: 6.0600\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1627 - val_loss: 6.0874\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1560 - val_loss: 6.0732\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1649 - val_loss: 6.0465\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1651 - val_loss: 6.0818\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1588 - val_loss: 6.0441\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1438 - val_loss: 6.0459\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.1571 - val_loss: 6.0486\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1681 - val_loss: 6.0919\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 6.1586 - val_loss: 6.0491\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1558 - val_loss: 6.0432\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1607 - val_loss: 6.0487\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1573 - val_loss: 6.0428\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1568 - val_loss: 6.0722\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1610 - val_loss: 6.0407\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1555 - val_loss: 6.0495\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1593 - val_loss: 6.0416\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1521 - val_loss: 6.0420\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1509 - val_loss: 6.0399\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1560 - val_loss: 6.0444\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.1536 - val_loss: 6.0423\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1551 - val_loss: 6.0570\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 6.1551 - val_loss: 6.0498\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 6.1446 - val_loss: 6.0457\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 6.1402 - val_loss: 6.0461\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1519 - val_loss: 6.0462\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1473 - val_loss: 6.0461\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1425 - val_loss: 6.0831\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1484 - val_loss: 6.0609\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 6.1488 - val_loss: 6.0476\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1499 - val_loss: 6.0457\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 6.1584 - val_loss: 6.0562\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 6.1467 - val_loss: 6.0363\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1511 - val_loss: 6.0369\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1498 - val_loss: 6.0347\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1480 - val_loss: 6.0446\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 6.1545 - val_loss: 6.0372\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1576 - val_loss: 6.0352\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1542 - val_loss: 6.0424\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 6.1468 - val_loss: 6.0468\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1428 - val_loss: 6.0491\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1338 - val_loss: 6.0409\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 6.1357 - val_loss: 6.0317\n",
      "Epoch 325/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1601 - val_loss: 6.0379\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1507 - val_loss: 6.0334\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1485 - val_loss: 6.0382\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1430 - val_loss: 6.0418\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1378 - val_loss: 6.0353\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 6.1388 - val_loss: 6.0317\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 6.1434 - val_loss: 6.0396\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 6.1412 - val_loss: 6.0316\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1453 - val_loss: 6.0486\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1448 - val_loss: 6.0331\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 6.1468 - val_loss: 6.0379\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 6.1365 - val_loss: 6.0257\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 6.1438 - val_loss: 6.0363\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1396 - val_loss: 6.0164\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 6.1236 - val_loss: 6.0268\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 6.1346 - val_loss: 6.0188\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 434us/sample - loss: 23.5379 - val_loss: 16.6954\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 17.2596 - val_loss: 16.3503\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 16.6158 - val_loss: 16.0336\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 16.1795 - val_loss: 15.7050\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 15.7884 - val_loss: 15.4032\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 15.4018 - val_loss: 15.1346\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 15.1541 - val_loss: 14.8963\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.8669 - val_loss: 14.6754\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.6358 - val_loss: 14.4618\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.4097 - val_loss: 14.2423\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1654 - val_loss: 14.0296\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 13.9703 - val_loss: 13.8275\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 13.7663 - val_loss: 13.6265\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 13.5615 - val_loss: 13.4297\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 13.3554 - val_loss: 13.2309\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 13.1617 - val_loss: 13.0333\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 12.9675 - val_loss: 12.8321\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 12.7592 - val_loss: 12.6339\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 12.5632 - val_loss: 12.4351\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 12.3717 - val_loss: 12.2395\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 12.1826 - val_loss: 12.0425\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 11.9802 - val_loss: 11.8466\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 11.7921 - val_loss: 11.6538\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 11.5836 - val_loss: 11.4605\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 11.4089 - val_loss: 11.2690\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 11.1978 - val_loss: 11.0758\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 11.0089 - val_loss: 10.8827\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.8182 - val_loss: 10.6949\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6355 - val_loss: 10.5103\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.4540 - val_loss: 10.3285\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.2651 - val_loss: 10.1425\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.0780 - val_loss: 9.9594\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 9.8912 - val_loss: 9.7834\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 9.7217 - val_loss: 9.6068\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 9.5488 - val_loss: 9.4319\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 9.3719 - val_loss: 9.2616\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 9.1974 - val_loss: 9.0985\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 9.0470 - val_loss: 8.9414\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.8853 - val_loss: 8.7924\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.7351 - val_loss: 8.6423\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.5769 - val_loss: 8.4823\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.4334 - val_loss: 8.3746\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.3564 - val_loss: 8.3254\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.3187 - val_loss: 8.2901\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.2888 - val_loss: 8.2743\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.2770 - val_loss: 8.2616\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.2678 - val_loss: 8.2502\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2613 - val_loss: 8.2469\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.2587 - val_loss: 8.2455\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.2578 - val_loss: 8.2433\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.2567 - val_loss: 8.2382\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.2537 - val_loss: 8.2363\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.2516 - val_loss: 8.2331\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.2492 - val_loss: 8.2318\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.2464 - val_loss: 8.2251\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.2456 - val_loss: 8.2214\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2453 - val_loss: 8.2178\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.2399 - val_loss: 8.2120\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.2421 - val_loss: 8.2118\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.2387 - val_loss: 8.2034\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.2350 - val_loss: 8.2051\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.2333 - val_loss: 8.1986\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.2336 - val_loss: 8.1932\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.2316 - val_loss: 8.1921\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.2292 - val_loss: 8.1848\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2275 - val_loss: 8.1832\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.2233 - val_loss: 8.1821\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.2186 - val_loss: 8.1761\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2207 - val_loss: 8.1687\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.2225 - val_loss: 8.1667\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.2145 - val_loss: 8.1630\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2186 - val_loss: 8.1606\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2151 - val_loss: 8.1519\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.2094 - val_loss: 8.1549\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.2081 - val_loss: 8.1466\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.2065 - val_loss: 8.1489\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2102 - val_loss: 8.1391\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.2045 - val_loss: 8.1338\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.2013 - val_loss: 8.1387\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.2030 - val_loss: 8.1324\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1966 - val_loss: 8.1268\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1917 - val_loss: 8.1220\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1974 - val_loss: 8.1197\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1938 - val_loss: 8.1238\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1972 - val_loss: 8.1126\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1943 - val_loss: 8.1195\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1899 - val_loss: 8.1088\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1874 - val_loss: 8.1178\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1832 - val_loss: 8.1006\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 110us/sample - loss: 8.1804 - val_loss: 8.1046\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1820 - val_loss: 8.0959\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1802 - val_loss: 8.0960\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 8.1780 - val_loss: 8.0921\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1722 - val_loss: 8.0853\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1729 - val_loss: 8.0932\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1735 - val_loss: 8.0875\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1640 - val_loss: 8.0781\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1701 - val_loss: 8.0794\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1669 - val_loss: 8.0732\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1704 - val_loss: 8.0714\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1673 - val_loss: 8.0820\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1707 - val_loss: 8.0653\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1566 - val_loss: 8.0642\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 8.1661 - val_loss: 8.0604\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1617 - val_loss: 8.0582\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1612 - val_loss: 8.0566\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1539 - val_loss: 8.0568\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1592 - val_loss: 8.0550\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1489 - val_loss: 8.0571\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 8.1538 - val_loss: 8.0456\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 8.1523 - val_loss: 8.0558\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1448 - val_loss: 8.0449\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1499 - val_loss: 8.0406\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1502 - val_loss: 8.0391\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1491 - val_loss: 8.0380\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1481 - val_loss: 8.0408\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1497 - val_loss: 8.0352\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1485 - val_loss: 8.0344\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.1461 - val_loss: 8.0296\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 8.1482 - val_loss: 8.0277\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 8.1454 - val_loss: 8.0370\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1460 - val_loss: 8.0326\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.1434 - val_loss: 8.0240\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1471 - val_loss: 8.0373\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1429 - val_loss: 8.0223\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1449 - val_loss: 8.0219\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1493 - val_loss: 8.0183\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.1415 - val_loss: 8.0206\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.1355 - val_loss: 8.0281\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1399 - val_loss: 8.0271\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 8.1416 - val_loss: 8.0294\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1360 - val_loss: 8.0150\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1426 - val_loss: 8.0121\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1324 - val_loss: 8.0258\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1384 - val_loss: 8.0098\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1400 - val_loss: 8.0208\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 8.1361 - val_loss: 8.0067\n",
      "Epoch 138/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 91us/sample - loss: 8.1277 - val_loss: 8.0149\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1409 - val_loss: 8.0079\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1386 - val_loss: 8.0039\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1352 - val_loss: 8.0063\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1343 - val_loss: 8.0070\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1327 - val_loss: 8.0013\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1280 - val_loss: 8.0037\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1329 - val_loss: 8.0234\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1328 - val_loss: 7.9983\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1345 - val_loss: 7.9974\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1324 - val_loss: 8.0073\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1314 - val_loss: 7.9947\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 8.1389 - val_loss: 7.9952\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1301 - val_loss: 7.9940\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1302 - val_loss: 8.0243\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1291 - val_loss: 7.9978\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1273 - val_loss: 7.9979\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1298 - val_loss: 7.9935\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1326 - val_loss: 7.9939\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1315 - val_loss: 7.9903\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1256 - val_loss: 7.9891\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1299 - val_loss: 8.0105\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1327 - val_loss: 7.9887\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1295 - val_loss: 8.0030\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1214 - val_loss: 8.0064\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1332 - val_loss: 7.9868\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1337 - val_loss: 7.9880\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1172 - val_loss: 7.9865\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1278 - val_loss: 7.9885\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1241 - val_loss: 7.9974\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1284 - val_loss: 7.9921\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1243 - val_loss: 7.9876\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1193 - val_loss: 7.9836\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1224 - val_loss: 7.9964\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1250 - val_loss: 7.9913\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1222 - val_loss: 7.9828\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1284 - val_loss: 7.9946\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1231 - val_loss: 7.9798\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1212 - val_loss: 7.9867\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1245 - val_loss: 7.9846\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1216 - val_loss: 7.9913\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1216 - val_loss: 7.9827\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1240 - val_loss: 7.9809\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1192 - val_loss: 7.9792\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1214 - val_loss: 7.9841\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1204 - val_loss: 7.9761\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1182 - val_loss: 7.9813\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1166 - val_loss: 7.9911\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1145 - val_loss: 7.9751\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1244 - val_loss: 7.9739\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1210 - val_loss: 7.9875\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1257 - val_loss: 7.9762\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1254 - val_loss: 7.9757\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1175 - val_loss: 7.9729\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1136 - val_loss: 7.9765\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1275 - val_loss: 7.9754\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1142 - val_loss: 7.9732\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1203 - val_loss: 7.9803\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 8.1214 - val_loss: 7.9898\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1111 - val_loss: 7.9715\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1193 - val_loss: 7.9730\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1210 - val_loss: 7.9711\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1278 - val_loss: 7.9705\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1156 - val_loss: 7.9686\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1148 - val_loss: 7.9765\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1112 - val_loss: 7.9711\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 8.1154 - val_loss: 7.9754\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1172 - val_loss: 7.9709\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1174 - val_loss: 7.9906\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1279 - val_loss: 7.9710\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1194 - val_loss: 7.9690\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1217 - val_loss: 7.9755\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1128 - val_loss: 7.9955\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1233 - val_loss: 7.9715\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1207 - val_loss: 7.9671\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.1093 - val_loss: 7.9670\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1166 - val_loss: 7.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1093 - val_loss: 7.9673\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1214 - val_loss: 7.9675\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1132 - val_loss: 7.9681\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1149 - val_loss: 7.9680\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1222 - val_loss: 7.9831\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1118 - val_loss: 7.9811\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1186 - val_loss: 7.9681\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1149 - val_loss: 7.9784\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1177 - val_loss: 7.9732\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1110 - val_loss: 7.9733\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1151 - val_loss: 7.9640\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1182 - val_loss: 7.9638\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 8.1113 - val_loss: 7.9704\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1200 - val_loss: 7.9653\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1170 - val_loss: 7.9679\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1219 - val_loss: 7.9760\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1107 - val_loss: 7.9622\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1228 - val_loss: 7.9626\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1103 - val_loss: 7.9746\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1153 - val_loss: 7.9818\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1118 - val_loss: 7.9647\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1121 - val_loss: 7.9641\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1186 - val_loss: 7.9657\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1197 - val_loss: 7.9621\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1157 - val_loss: 7.9632\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1143 - val_loss: 7.9719\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1168 - val_loss: 7.9656\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1165 - val_loss: 7.9630\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1119 - val_loss: 7.9643\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1126 - val_loss: 7.9618\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1110 - val_loss: 7.9621\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1099 - val_loss: 7.9675\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1051 - val_loss: 7.9670\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1106 - val_loss: 7.9735\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1223 - val_loss: 7.9772\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1162 - val_loss: 7.9598\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1144 - val_loss: 7.9599\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1079 - val_loss: 7.9597\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1106 - val_loss: 7.9582\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1189 - val_loss: 7.9619\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1124 - val_loss: 7.9779\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1175 - val_loss: 7.9620\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1069 - val_loss: 7.9594\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1019 - val_loss: 7.9639\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1151 - val_loss: 7.9648\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1148 - val_loss: 7.9872\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1155 - val_loss: 7.9597\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1168 - val_loss: 7.9668\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1142 - val_loss: 7.9660\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1109 - val_loss: 7.9644\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1163 - val_loss: 7.9605\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1196 - val_loss: 7.9596\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1136 - val_loss: 7.9581\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1105 - val_loss: 7.9799\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1177 - val_loss: 7.9742\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1096 - val_loss: 7.9561\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1113 - val_loss: 7.9583\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1045 - val_loss: 7.9564\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1181 - val_loss: 7.9579\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1196 - val_loss: 7.9586\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 8.1107 - val_loss: 7.9578\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 8.1183 - val_loss: 7.9573\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1140 - val_loss: 7.9614\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1047 - val_loss: 7.9563\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1233 - val_loss: 7.9618\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1181 - val_loss: 7.9787\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1098 - val_loss: 7.9542\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1129 - val_loss: 7.9617\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1081 - val_loss: 7.9566\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1139 - val_loss: 7.9552\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1144 - val_loss: 7.9528\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1158 - val_loss: 7.9553\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1046 - val_loss: 7.9601\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1111 - val_loss: 7.9548\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1167 - val_loss: 7.9538\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1111 - val_loss: 7.9565\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.1129 - val_loss: 7.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1075 - val_loss: 7.9629\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1134 - val_loss: 7.9543\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1057 - val_loss: 7.9575\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1106 - val_loss: 7.9732\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1107 - val_loss: 7.9525\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1131 - val_loss: 7.9533\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1169 - val_loss: 7.9524\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1096 - val_loss: 7.9547\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 8.1106 - val_loss: 7.9599\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1067 - val_loss: 7.9562\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1134 - val_loss: 7.9536\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 8.1016 - val_loss: 7.9547\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1057 - val_loss: 7.9612\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1057 - val_loss: 7.9565\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1130 - val_loss: 7.9626\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1130 - val_loss: 7.9529\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1064 - val_loss: 7.9556\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1118 - val_loss: 7.9768\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1080 - val_loss: 7.9563\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1086 - val_loss: 7.9602\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1068 - val_loss: 7.9720\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1140 - val_loss: 7.9893\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1112 - val_loss: 7.9543\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1197 - val_loss: 7.9601\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1058 - val_loss: 7.9583\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1184 - val_loss: 7.9562\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 8.1054 - val_loss: 7.9543\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 8.1055 - val_loss: 7.9546\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1027 - val_loss: 7.9892\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 8.1090 - val_loss: 7.9618\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1133 - val_loss: 7.9533\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.1049 - val_loss: 7.9622\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.0991 - val_loss: 7.9572\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1104 - val_loss: 7.9542\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 8.1070 - val_loss: 7.9569\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 8.1078 - val_loss: 7.9512\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1092 - val_loss: 7.9627\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 8.1100 - val_loss: 7.9551\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1014 - val_loss: 7.9679\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1074 - val_loss: 7.9559\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1117 - val_loss: 7.9530\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 8.1069 - val_loss: 7.9561\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 8.1044 - val_loss: 7.9568\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 8.0989 - val_loss: 7.9514\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1074 - val_loss: 7.9474\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 8.1132 - val_loss: 7.9532\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1067 - val_loss: 7.9525\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 8.1139 - val_loss: 7.9547\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 8.1081 - val_loss: 7.9529\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 444us/sample - loss: 31.4113 - val_loss: 21.4601\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 21.4511 - val_loss: 21.0199\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 21.0131 - val_loss: 20.6855\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 20.7038 - val_loss: 20.3882\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 20.3459 - val_loss: 20.0844\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 20.0562 - val_loss: 19.8297\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 19.7717 - val_loss: 19.5474\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 19.4673 - val_loss: 19.2672\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 19.1964 - val_loss: 18.9838\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.9504 - val_loss: 18.7201\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.6545 - val_loss: 18.4545\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.3802 - val_loss: 18.1746\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.1110 - val_loss: 17.9075\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 17.8294 - val_loss: 17.6425\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 17.5821 - val_loss: 17.3653\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 17.3163 - val_loss: 17.0955\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 17.0511 - val_loss: 16.8534\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 16.7710 - val_loss: 16.5771\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 16.5168 - val_loss: 16.3108\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 16.2570 - val_loss: 16.0534\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 15.9809 - val_loss: 15.7893\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 15.7524 - val_loss: 15.5562\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 15.4954 - val_loss: 15.2903\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 15.2333 - val_loss: 15.0433\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.9776 - val_loss: 14.7879\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.7311 - val_loss: 14.5285\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.4858 - val_loss: 14.2774\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.2212 - val_loss: 14.0375\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 13.9915 - val_loss: 13.7973\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 13.7390 - val_loss: 13.5490\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 13.5219 - val_loss: 13.3119\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 13.2638 - val_loss: 13.0792\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 13.0392 - val_loss: 12.8480\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 12.8167 - val_loss: 12.6263\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 12.5872 - val_loss: 12.4042\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 12.3590 - val_loss: 12.1842\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 12.1502 - val_loss: 11.9792\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 11.9488 - val_loss: 11.7755\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 11.7477 - val_loss: 11.5877\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 11.5528 - val_loss: 11.3866\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 11.3544 - val_loss: 11.1964\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 11.1905 - val_loss: 11.0838\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 11.0951 - val_loss: 11.0012\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 11.0286 - val_loss: 10.9371\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.9742 - val_loss: 10.9001\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.9514 - val_loss: 10.8784\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.9294 - val_loss: 10.8587\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.9075 - val_loss: 10.8449\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.9046 - val_loss: 10.8370\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.8946 - val_loss: 10.8293\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.8853 - val_loss: 10.8164\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.8663 - val_loss: 10.7967\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.8551 - val_loss: 10.7815\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.8398 - val_loss: 10.7757\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.8358 - val_loss: 10.7711\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.8267 - val_loss: 10.7703\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.8215 - val_loss: 10.7596\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.8189 - val_loss: 10.7582\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.8050 - val_loss: 10.7365\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.7938 - val_loss: 10.7199\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.7892 - val_loss: 10.7150\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7735 - val_loss: 10.7110\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.7815 - val_loss: 10.7087\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 10.7751 - val_loss: 10.7030\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.7734 - val_loss: 10.7054\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.7738 - val_loss: 10.6977\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.7678 - val_loss: 10.6920\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.7661 - val_loss: 10.6975\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7568 - val_loss: 10.6856\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7556 - val_loss: 10.6822\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7646 - val_loss: 10.6825\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7529 - val_loss: 10.6812\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7503 - val_loss: 10.6748\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.7517 - val_loss: 10.6795\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7480 - val_loss: 10.6704\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7498 - val_loss: 10.6680\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7439 - val_loss: 10.6631\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7387 - val_loss: 10.6620\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.7348 - val_loss: 10.6582\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7403 - val_loss: 10.6621\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.7394 - val_loss: 10.6537\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.7361 - val_loss: 10.6601\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7300 - val_loss: 10.6582\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7294 - val_loss: 10.6473\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7327 - val_loss: 10.6495\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7245 - val_loss: 10.6450\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7208 - val_loss: 10.6451\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7247 - val_loss: 10.6417\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7189 - val_loss: 10.6396\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7176 - val_loss: 10.6412\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7184 - val_loss: 10.6466\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 10.7206 - val_loss: 10.6364\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7099 - val_loss: 10.6373\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 10.7092 - val_loss: 10.6423\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 10.7097 - val_loss: 10.6346\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.7095 - val_loss: 10.6264\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7089 - val_loss: 10.6315\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.7048 - val_loss: 10.6345\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 10.7143 - val_loss: 10.6249\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.7061 - val_loss: 10.6229\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.7033 - val_loss: 10.6180\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7137 - val_loss: 10.6209\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7000 - val_loss: 10.6229\n",
      "Epoch 104/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6921 - val_loss: 10.6166\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6987 - val_loss: 10.6225\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.7040 - val_loss: 10.6123\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.7014 - val_loss: 10.6129\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6974 - val_loss: 10.6155\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6923 - val_loss: 10.6120\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6909 - val_loss: 10.6267\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6961 - val_loss: 10.6229\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.7032 - val_loss: 10.6128\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6937 - val_loss: 10.6073\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6976 - val_loss: 10.6040\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6904 - val_loss: 10.6041\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6864 - val_loss: 10.6019\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6813 - val_loss: 10.6207\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6854 - val_loss: 10.6044\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6863 - val_loss: 10.5985\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6875 - val_loss: 10.6006\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 72us/sample - loss: 10.6795 - val_loss: 10.6014\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 73us/sample - loss: 10.6822 - val_loss: 10.5956\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 10.6773 - val_loss: 10.5972\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6883 - val_loss: 10.5929\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 74us/sample - loss: 10.6704 - val_loss: 10.5930\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 10.6913 - val_loss: 10.5937\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6792 - val_loss: 10.5907\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6692 - val_loss: 10.6558\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6740 - val_loss: 10.5882\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 10.6750 - val_loss: 10.5863\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6693 - val_loss: 10.5853\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 10.6890 - val_loss: 10.5877\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6778 - val_loss: 10.5898\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6729 - val_loss: 10.5861\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6787 - val_loss: 10.5945\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 10.6714 - val_loss: 10.5848\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6706 - val_loss: 10.5853\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6725 - val_loss: 10.5825\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6712 - val_loss: 10.5889\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6712 - val_loss: 10.5987\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6765 - val_loss: 10.5847\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6672 - val_loss: 10.5875\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6672 - val_loss: 10.5785\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6724 - val_loss: 10.5772\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6655 - val_loss: 10.6296\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6771 - val_loss: 10.5952\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6711 - val_loss: 10.5779\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6688 - val_loss: 10.5934\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6764 - val_loss: 10.5753\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 10.6706 - val_loss: 10.5785\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6640 - val_loss: 10.5929\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 10.6550 - val_loss: 10.5699\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 10.6538 - val_loss: 10.5759\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6677 - val_loss: 10.5810\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6724 - val_loss: 10.5983\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6589 - val_loss: 10.5869\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6700 - val_loss: 10.5766\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6671 - val_loss: 10.5956\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6652 - val_loss: 10.5700\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6623 - val_loss: 10.5679\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6544 - val_loss: 10.5863\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6664 - val_loss: 10.5643\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 10.6652 - val_loss: 10.5665\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 10.6584 - val_loss: 10.5914\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6520 - val_loss: 10.5642\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6580 - val_loss: 10.5782\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6546 - val_loss: 10.5645\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6656 - val_loss: 10.5879\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6510 - val_loss: 10.5629\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6538 - val_loss: 10.5646\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6518 - val_loss: 10.5712\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6631 - val_loss: 10.5600\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6619 - val_loss: 10.5763\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6653 - val_loss: 10.5701\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6648 - val_loss: 10.5579\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6526 - val_loss: 10.5672\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6590 - val_loss: 10.5591\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6499 - val_loss: 10.5576\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6524 - val_loss: 10.5578\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6612 - val_loss: 10.5552\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6535 - val_loss: 10.5646\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6583 - val_loss: 10.5605\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6586 - val_loss: 10.5715\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6457 - val_loss: 10.5647\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6420 - val_loss: 10.5655\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6470 - val_loss: 10.5580\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6531 - val_loss: 10.5535\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6370 - val_loss: 10.5673\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6445 - val_loss: 10.5619\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 10.6456 - val_loss: 10.5534\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6454 - val_loss: 10.5549\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6435 - val_loss: 10.5487\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6624 - val_loss: 10.5529\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6537 - val_loss: 10.5873\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6508 - val_loss: 10.5506\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6404 - val_loss: 10.5525\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 10.6561 - val_loss: 10.5512\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6432 - val_loss: 10.5712\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6516 - val_loss: 10.5567\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6458 - val_loss: 10.5512\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6409 - val_loss: 10.5627\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6474 - val_loss: 10.5590\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6486 - val_loss: 10.5595\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6383 - val_loss: 10.5565\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6379 - val_loss: 10.5510\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6434 - val_loss: 10.5510\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 10.6471 - val_loss: 10.5435\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6451 - val_loss: 10.5424\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6435 - val_loss: 10.5476\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6482 - val_loss: 10.5468\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6450 - val_loss: 10.5458\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6448 - val_loss: 10.5448\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6376 - val_loss: 10.6329\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6538 - val_loss: 10.5538\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 10.6436 - val_loss: 10.5462\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6462 - val_loss: 10.5431\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6447 - val_loss: 10.5577\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6476 - val_loss: 10.5428\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6404 - val_loss: 10.5529\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6499 - val_loss: 10.5455\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6292 - val_loss: 10.5469\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6347 - val_loss: 10.5467\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6347 - val_loss: 10.5401\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6406 - val_loss: 10.5393\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6430 - val_loss: 10.5381\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6292 - val_loss: 10.5675\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6299 - val_loss: 10.5457\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 10.6368 - val_loss: 10.5371\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6532 - val_loss: 10.5516\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6404 - val_loss: 10.5617\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6380 - val_loss: 10.5468\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6337 - val_loss: 10.5501\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6480 - val_loss: 10.5535\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6327 - val_loss: 10.5686\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6386 - val_loss: 10.5389\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6408 - val_loss: 10.5744\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6363 - val_loss: 10.5547\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6410 - val_loss: 10.5387\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6275 - val_loss: 10.5408\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6374 - val_loss: 10.5344\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6385 - val_loss: 10.5356\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6268 - val_loss: 10.5465\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6332 - val_loss: 10.5326\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 10.6378 - val_loss: 10.5325\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6288 - val_loss: 10.5707\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6302 - val_loss: 10.5457\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6347 - val_loss: 10.5617\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6322 - val_loss: 10.6089\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6354 - val_loss: 10.5463\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6356 - val_loss: 10.5316\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6374 - val_loss: 10.5311\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6275 - val_loss: 10.5328\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6314 - val_loss: 10.5559\n",
      "Epoch 254/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6256 - val_loss: 10.5445\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 10.6319 - val_loss: 10.5532\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6221 - val_loss: 10.5325\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6308 - val_loss: 10.5566\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6414 - val_loss: 10.5492\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6260 - val_loss: 10.5293\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6237 - val_loss: 10.5307\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6401 - val_loss: 10.5529\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6355 - val_loss: 10.5275\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6358 - val_loss: 10.5335\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 10.6271 - val_loss: 10.5357\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 10.6234 - val_loss: 10.5300\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6246 - val_loss: 10.5539\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6304 - val_loss: 10.5270\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6300 - val_loss: 10.5286\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6258 - val_loss: 10.5348\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6343 - val_loss: 10.5266\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6279 - val_loss: 10.5305\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6158 - val_loss: 10.5289\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6232 - val_loss: 10.5217\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6255 - val_loss: 10.5387\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 10.6283 - val_loss: 10.5346\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 10.6239 - val_loss: 10.5387\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6318 - val_loss: 10.5423\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6209 - val_loss: 10.5477\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6230 - val_loss: 10.5309\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6311 - val_loss: 10.5521\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6223 - val_loss: 10.5593\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6228 - val_loss: 10.5273\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6270 - val_loss: 10.5230\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6275 - val_loss: 10.5220\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 10.6234 - val_loss: 10.5419\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6274 - val_loss: 10.5258\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6236 - val_loss: 10.5415\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 10.6210 - val_loss: 10.5244\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6308 - val_loss: 10.5225\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6123 - val_loss: 10.5198\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6259 - val_loss: 10.5267\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6331 - val_loss: 10.5214\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6289 - val_loss: 10.5310\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6269 - val_loss: 10.5382\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6212 - val_loss: 10.5204\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 10.6219 - val_loss: 10.5190\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6327 - val_loss: 10.5399\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6269 - val_loss: 10.5236\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6170 - val_loss: 10.5267\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6196 - val_loss: 10.5256\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6294 - val_loss: 10.5231\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6234 - val_loss: 10.5487\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6213 - val_loss: 10.5516\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 10.6219 - val_loss: 10.5299\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6346 - val_loss: 10.5220\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6262 - val_loss: 10.5264\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6248 - val_loss: 10.5198\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 10.6186 - val_loss: 10.5190\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6223 - val_loss: 10.5304\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6222 - val_loss: 10.5246\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6177 - val_loss: 10.5524\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 10.6343 - val_loss: 10.5349\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6165 - val_loss: 10.5222\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6125 - val_loss: 10.5306\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6228 - val_loss: 10.5262\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6203 - val_loss: 10.5198\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6339 - val_loss: 10.5298\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6108 - val_loss: 10.5579\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6160 - val_loss: 10.5328\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6157 - val_loss: 10.5372\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6246 - val_loss: 10.5196\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 80us/sample - loss: 10.6169 - val_loss: 10.5168\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6238 - val_loss: 10.5178\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6161 - val_loss: 10.5235\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6302 - val_loss: 10.5157\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6200 - val_loss: 10.5184\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 10.6143 - val_loss: 10.5150\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6172 - val_loss: 10.5131\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 10.6215 - val_loss: 10.5473\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6194 - val_loss: 10.5136\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 10.6153 - val_loss: 10.5354\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 10.6221 - val_loss: 10.5465\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 10.6220 - val_loss: 10.5149\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 10.6190 - val_loss: 10.5144\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 10.6106 - val_loss: 10.5191\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 10.6120 - val_loss: 10.5776\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 10.6169 - val_loss: 10.5349\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 114us/sample - loss: 10.6273 - val_loss: 10.5181\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6260 - val_loss: 10.5243\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 10.6244 - val_loss: 10.5317\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 394us/sample - loss: 39.8425 - val_loss: 28.4381\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 71us/sample - loss: 28.3792 - val_loss: 27.8652\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 27.8369 - val_loss: 27.4232\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 27.3282 - val_loss: 27.0228\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 26.9056 - val_loss: 26.6263\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 26.5078 - val_loss: 26.2497\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 26.1244 - val_loss: 25.8843\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.7736 - val_loss: 25.5143\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.4116 - val_loss: 25.1581\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.0554 - val_loss: 24.7900\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 24.6809 - val_loss: 24.4251\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 24.3311 - val_loss: 24.0542\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 23.9752 - val_loss: 23.6961\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 23.6047 - val_loss: 23.3293\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 23.2558 - val_loss: 22.9708\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 22.8960 - val_loss: 22.6125\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 22.5300 - val_loss: 22.2519\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 22.1830 - val_loss: 21.9056\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 21.8277 - val_loss: 21.5468\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 21.4562 - val_loss: 21.1939\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 21.1245 - val_loss: 20.8379\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 20.7743 - val_loss: 20.4925\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 20.4134 - val_loss: 20.1399\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 20.0685 - val_loss: 19.7940\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 19.7135 - val_loss: 19.4463\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 19.3636 - val_loss: 19.1041\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 19.0190 - val_loss: 18.7549\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.6826 - val_loss: 18.4180\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.3482 - val_loss: 18.0818\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 17.9934 - val_loss: 17.7470\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 17.6481 - val_loss: 17.4139\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 17.3314 - val_loss: 17.0865\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 16.9910 - val_loss: 16.7592\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 16.6598 - val_loss: 16.4367\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 16.3422 - val_loss: 16.1261\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 16.0249 - val_loss: 15.8208\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 15.7173 - val_loss: 15.5259\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 15.4264 - val_loss: 15.2385\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 15.1277 - val_loss: 14.9551\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.8410 - val_loss: 14.6638\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.5597 - val_loss: 14.4363\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.3965 - val_loss: 14.3369\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.3143 - val_loss: 14.2767\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.2584 - val_loss: 14.2223\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 14.2113 - val_loss: 14.1860\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1900 - val_loss: 14.1865\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1898 - val_loss: 14.1885\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1907 - val_loss: 14.1873\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1910 - val_loss: 14.1868\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 107us/sample - loss: 14.1886 - val_loss: 14.1864\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1898 - val_loss: 14.1868\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1903 - val_loss: 14.1848\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 14.1898 - val_loss: 14.1842\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 14.1899 - val_loss: 14.1830\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1876 - val_loss: 14.1824\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1886 - val_loss: 14.1821\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1876 - val_loss: 14.1820\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1878 - val_loss: 14.1805\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1887 - val_loss: 14.1788\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1866 - val_loss: 14.1753\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1871 - val_loss: 14.1745\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 14.1850 - val_loss: 14.1719\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1870 - val_loss: 14.1682\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1851 - val_loss: 14.1674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1807 - val_loss: 14.1645\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1828 - val_loss: 14.1614\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1807 - val_loss: 14.1597\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1804 - val_loss: 14.1583\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1806 - val_loss: 14.1563\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1766 - val_loss: 14.1536\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1765 - val_loss: 14.1512\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1781 - val_loss: 14.1509\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1755 - val_loss: 14.1451\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1717 - val_loss: 14.1432\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1741 - val_loss: 14.1408\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1689 - val_loss: 14.1367\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1696 - val_loss: 14.1332\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1690 - val_loss: 14.1296\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1683 - val_loss: 14.1337\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1647 - val_loss: 14.1253\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1663 - val_loss: 14.1235\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1633 - val_loss: 14.1188\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1634 - val_loss: 14.1170\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1609 - val_loss: 14.1168\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1606 - val_loss: 14.1113\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1609 - val_loss: 14.1092\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1577 - val_loss: 14.1045\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1556 - val_loss: 14.1086\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1531 - val_loss: 14.1019\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1566 - val_loss: 14.0962\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1535 - val_loss: 14.0925\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1574 - val_loss: 14.0946\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1493 - val_loss: 14.0904\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1551 - val_loss: 14.0937\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1529 - val_loss: 14.0870\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1441 - val_loss: 14.0851\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1497 - val_loss: 14.0822\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1471 - val_loss: 14.0791\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1474 - val_loss: 14.0787\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1467 - val_loss: 14.0761\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1397 - val_loss: 14.0730\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1453 - val_loss: 14.0789\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1415 - val_loss: 14.0663\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1378 - val_loss: 14.0652\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1399 - val_loss: 14.0678\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1413 - val_loss: 14.0714\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1443 - val_loss: 14.0628\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1423 - val_loss: 14.0634\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1419 - val_loss: 14.0650\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1386 - val_loss: 14.0575\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1382 - val_loss: 14.0589\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1407 - val_loss: 14.0615\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1445 - val_loss: 14.0533\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1373 - val_loss: 14.0662\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1399 - val_loss: 14.0529\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1383 - val_loss: 14.0515\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1341 - val_loss: 14.0516\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1390 - val_loss: 14.0474\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1374 - val_loss: 14.0458\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1339 - val_loss: 14.0528\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1305 - val_loss: 14.0494\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1325 - val_loss: 14.0451\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1270 - val_loss: 14.0570\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1369 - val_loss: 14.0476\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1304 - val_loss: 14.0441\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 14.1354 - val_loss: 14.0468\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1282 - val_loss: 14.0494\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1314 - val_loss: 14.0546\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1329 - val_loss: 14.0489\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 14.1285 - val_loss: 14.0341\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1331 - val_loss: 14.0457\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 14.1312 - val_loss: 14.0409\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1324 - val_loss: 14.0411\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1294 - val_loss: 14.0332\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1295 - val_loss: 14.0396\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1265 - val_loss: 14.0349\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1307 - val_loss: 14.0319\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1267 - val_loss: 14.0351\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1208 - val_loss: 14.0316\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1226 - val_loss: 14.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1273 - val_loss: 14.0273\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1268 - val_loss: 14.0433\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 14.1351 - val_loss: 14.0305\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1311 - val_loss: 14.0295\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1355 - val_loss: 14.0368\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1260 - val_loss: 14.0288\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1284 - val_loss: 14.0328\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1282 - val_loss: 14.0247\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1316 - val_loss: 14.0367\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1280 - val_loss: 14.0236\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1246 - val_loss: 14.0444\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1222 - val_loss: 14.0320\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1238 - val_loss: 14.0252\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1262 - val_loss: 14.0211\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1324 - val_loss: 14.0353\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1272 - val_loss: 14.0295\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1273 - val_loss: 14.0264\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1284 - val_loss: 14.0282\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1177 - val_loss: 14.0325\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1273 - val_loss: 14.0323\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1196 - val_loss: 14.0211\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1262 - val_loss: 14.0228\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1313 - val_loss: 14.0221\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1269 - val_loss: 14.0345\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1243 - val_loss: 14.0244\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1274 - val_loss: 14.0194\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1229 - val_loss: 14.0284\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1255 - val_loss: 14.0295\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1255 - val_loss: 14.0432\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1253 - val_loss: 14.0236\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1247 - val_loss: 14.0296\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1276 - val_loss: 14.0170\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1264 - val_loss: 14.0234\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1278 - val_loss: 14.0296\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1285 - val_loss: 14.0262\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1270 - val_loss: 14.0197\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 14.1216 - val_loss: 14.0294\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1181 - val_loss: 14.0190\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1220 - val_loss: 14.0164\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1214 - val_loss: 14.0411\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 14.1197 - val_loss: 14.0147\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1225 - val_loss: 14.0311\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 14.1205 - val_loss: 14.0143\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1247 - val_loss: 14.0263\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1289 - val_loss: 14.0293\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1201 - val_loss: 14.0189\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1217 - val_loss: 14.0206\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1195 - val_loss: 14.0190\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1195 - val_loss: 14.0172\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1194 - val_loss: 14.0138\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1201 - val_loss: 14.0295\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1172 - val_loss: 14.0324\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1188 - val_loss: 14.0252\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1215 - val_loss: 14.0132\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1137 - val_loss: 14.0234\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1182 - val_loss: 14.0233\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1151 - val_loss: 14.0088\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 14.1157 - val_loss: 14.0247\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1181 - val_loss: 14.0166\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1187 - val_loss: 14.0219\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1205 - val_loss: 14.0271\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1261 - val_loss: 14.0080\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1183 - val_loss: 14.0165\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1290 - val_loss: 14.0100\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1212 - val_loss: 14.0251\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1140 - val_loss: 14.0205\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1214 - val_loss: 14.0335\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 14.1196 - val_loss: 14.0090\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1239 - val_loss: 14.0144\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1153 - val_loss: 14.0220\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1131 - val_loss: 14.0253\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1129 - val_loss: 14.0145\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1161 - val_loss: 14.0086\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1160 - val_loss: 14.0071\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1136 - val_loss: 14.0261\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1192 - val_loss: 14.0145\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1180 - val_loss: 14.0049\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1171 - val_loss: 14.0082\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1130 - val_loss: 14.0285\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1144 - val_loss: 14.0063\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1165 - val_loss: 14.0067\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1107 - val_loss: 14.0050\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1154 - val_loss: 14.0088\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1195 - val_loss: 14.0170\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1236 - val_loss: 14.0115\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1162 - val_loss: 14.0146\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1179 - val_loss: 14.0045\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1171 - val_loss: 14.0441\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1231 - val_loss: 14.0081\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1168 - val_loss: 14.0096\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1155 - val_loss: 14.0148\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 14.1195 - val_loss: 14.0045\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 14.1168 - val_loss: 14.0038\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1207 - val_loss: 14.0087\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1133 - val_loss: 14.0137\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1196 - val_loss: 14.0062\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1206 - val_loss: 14.0074\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1190 - val_loss: 14.0088\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1173 - val_loss: 14.0217\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1170 - val_loss: 14.0199\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1178 - val_loss: 14.0172\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1142 - val_loss: 14.0273\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1115 - val_loss: 14.0184\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1131 - val_loss: 14.0021\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1201 - val_loss: 14.0020\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1131 - val_loss: 14.0144\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1171 - val_loss: 14.0332\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1172 - val_loss: 14.0052\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1160 - val_loss: 14.0057\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1143 - val_loss: 14.0039\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1089 - val_loss: 14.0018\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1157 - val_loss: 14.0136\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1139 - val_loss: 14.0133\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1195 - val_loss: 14.0179\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1145 - val_loss: 14.0146\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1134 - val_loss: 14.0005\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1208 - val_loss: 14.0012\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1191 - val_loss: 14.0083\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1148 - val_loss: 14.0107\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 14.1210 - val_loss: 14.0047\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 14.1150 - val_loss: 14.0127\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 14.1165 - val_loss: 14.0008\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1186 - val_loss: 13.9997\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1126 - val_loss: 14.0085\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1097 - val_loss: 14.0030\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1146 - val_loss: 14.0015\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1127 - val_loss: 14.0205\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1079 - val_loss: 14.0436\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 14.1154 - val_loss: 14.0089\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 14.1152 - val_loss: 14.0062\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1119 - val_loss: 14.0065\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1176 - val_loss: 14.0048\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1177 - val_loss: 14.0052\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 14.1079 - val_loss: 14.0075\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1137 - val_loss: 14.0163\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1167 - val_loss: 14.0022\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1165 - val_loss: 14.0069\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1126 - val_loss: 13.9996\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1132 - val_loss: 14.0188\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1149 - val_loss: 14.0040\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1131 - val_loss: 14.0068\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1115 - val_loss: 14.0070\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1108 - val_loss: 13.9977\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1100 - val_loss: 13.9966\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1153 - val_loss: 14.0100\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1207 - val_loss: 14.0038\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1131 - val_loss: 14.0015\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1167 - val_loss: 14.0128\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1144 - val_loss: 14.0369\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1088 - val_loss: 14.0168\n",
      "Epoch 291/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1135 - val_loss: 14.0070\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1094 - val_loss: 13.9972\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1129 - val_loss: 14.0259\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1165 - val_loss: 13.9966\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1078 - val_loss: 14.0254\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1173 - val_loss: 14.0462\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 14.1122 - val_loss: 14.0214\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1131 - val_loss: 14.0008\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1092 - val_loss: 14.0300\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1168 - val_loss: 14.0064\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1086 - val_loss: 14.0099\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1136 - val_loss: 14.0063\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1133 - val_loss: 14.0229\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1118 - val_loss: 14.0188\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1131 - val_loss: 14.0286\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1149 - val_loss: 13.9946\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1151 - val_loss: 14.0049\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1169 - val_loss: 14.0044\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1103 - val_loss: 14.0276\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1163 - val_loss: 13.9952\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1137 - val_loss: 14.0070\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 14.1162 - val_loss: 14.0055\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1097 - val_loss: 14.0137\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1120 - val_loss: 14.0272\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1118 - val_loss: 14.0026\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1067 - val_loss: 13.9981\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1152 - val_loss: 14.0061\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1166 - val_loss: 14.0146\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1132 - val_loss: 13.9964\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1161 - val_loss: 13.9986\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1075 - val_loss: 13.9984\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 14.1109 - val_loss: 14.0304\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 14.1157 - val_loss: 14.0074\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 14.1119 - val_loss: 14.0054\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 14.1029 - val_loss: 14.0167\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1110 - val_loss: 14.0002\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1141 - val_loss: 13.9998\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 14.1148 - val_loss: 13.9948\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 14.1109 - val_loss: 14.0021\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1090 - val_loss: 14.0112\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 14.1112 - val_loss: 13.9931\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1098 - val_loss: 14.0003\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1104 - val_loss: 14.0796\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1220 - val_loss: 14.0311\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1100 - val_loss: 13.9936\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 14.1121 - val_loss: 13.9935\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 14.1140 - val_loss: 14.0047\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 14.1155 - val_loss: 14.0227\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 14.1140 - val_loss: 14.0196\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 14.1153 - val_loss: 13.9987\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 397us/sample - loss: 54.4057 - val_loss: 38.6926\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 63us/sample - loss: 38.4325 - val_loss: 37.7726\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 37.5702 - val_loss: 37.0668\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 36.8474 - val_loss: 36.4485\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 36.1874 - val_loss: 35.8826\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 35.6485 - val_loss: 35.3559\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 35.1223 - val_loss: 34.8362\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 34.6048 - val_loss: 34.3361\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 34.0971 - val_loss: 33.8520\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 33.6049 - val_loss: 33.3500\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 33.1145 - val_loss: 32.8582\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 32.6107 - val_loss: 32.3666\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 32.1224 - val_loss: 31.8715\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 31.6365 - val_loss: 31.3781\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 31.1514 - val_loss: 30.8918\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 30.6525 - val_loss: 30.3984\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 30.1699 - val_loss: 29.9030\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 29.6844 - val_loss: 29.4118\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 29.1920 - val_loss: 28.9259\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 28.7040 - val_loss: 28.4363\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 28.2172 - val_loss: 27.9417\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 27.7351 - val_loss: 27.4559\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 27.2461 - val_loss: 26.9774\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 26.7648 - val_loss: 26.4869\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 26.2843 - val_loss: 26.0021\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.8036 - val_loss: 25.5190\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.3103 - val_loss: 25.0363\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 24.8456 - val_loss: 24.5552\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 24.3537 - val_loss: 24.0808\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 23.8855 - val_loss: 23.6091\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 23.4161 - val_loss: 23.1357\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 22.9413 - val_loss: 22.6698\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 22.4807 - val_loss: 22.2025\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 22.0048 - val_loss: 21.7409\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 21.5477 - val_loss: 21.2874\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 21.0958 - val_loss: 20.8424\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 20.6488 - val_loss: 20.4040\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 20.2134 - val_loss: 19.9777\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 19.7887 - val_loss: 19.5502\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 19.3277 - val_loss: 19.0721\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.8986 - val_loss: 18.7922\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7796 - val_loss: 18.7750\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7760 - val_loss: 18.7748\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7754 - val_loss: 18.7745\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7757 - val_loss: 18.7743\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7742\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7741\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7755 - val_loss: 18.7741\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7741\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7747 - val_loss: 18.7738\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7750 - val_loss: 18.7739\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7749 - val_loss: 18.7738\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 18.7757 - val_loss: 18.7739\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7750 - val_loss: 18.7739\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7755 - val_loss: 18.7739\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7749 - val_loss: 18.7738\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7759 - val_loss: 18.7738\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7750 - val_loss: 18.7739\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7759 - val_loss: 18.7739\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7757 - val_loss: 18.7738\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7748 - val_loss: 18.7740\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7755 - val_loss: 18.7739\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7749 - val_loss: 18.7740\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 102/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7757 - val_loss: 18.7737\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7749 - val_loss: 18.7738\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7761 - val_loss: 18.7737\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7750 - val_loss: 18.7737\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7756 - val_loss: 18.7736\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7753 - val_loss: 18.7736\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7755 - val_loss: 18.7736\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7736\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7755 - val_loss: 18.7736\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7755 - val_loss: 18.7737\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7755 - val_loss: 18.7739\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7736\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7737\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7737\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7750 - val_loss: 18.7739\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7756 - val_loss: 18.7737\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7758 - val_loss: 18.7738\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7756 - val_loss: 18.7738\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7755 - val_loss: 18.7738\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7754 - val_loss: 18.7737\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7755 - val_loss: 18.7737\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7752 - val_loss: 18.7737\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 109us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7755 - val_loss: 18.7737\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 252/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7751 - val_loss: 18.7740\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 81us/sample - loss: 18.7753 - val_loss: 18.7740\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7750 - val_loss: 18.7739\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7750 - val_loss: 18.7738\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 289/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7740\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7751 - val_loss: 18.7741\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7751 - val_loss: 18.7741\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7741\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 18.7751 - val_loss: 18.7741\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7740\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7749 - val_loss: 18.7739\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 18.7751 - val_loss: 18.7740\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 108us/sample - loss: 18.7750 - val_loss: 18.7740\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7752 - val_loss: 18.7740\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7755 - val_loss: 18.7740\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7749 - val_loss: 18.7739\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7749 - val_loss: 18.7740\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7753 - val_loss: 18.7740\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7739\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 18.7753 - val_loss: 18.7738\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7755 - val_loss: 18.7737\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7753 - val_loss: 18.7737\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 18.7753 - val_loss: 18.7736\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 18.7751 - val_loss: 18.7737\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 18.7752 - val_loss: 18.7738\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 18.7754 - val_loss: 18.7738\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7738\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7749 - val_loss: 18.7739\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7751 - val_loss: 18.7739\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 18.7752 - val_loss: 18.7739\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 18.7754 - val_loss: 18.7739\n",
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/340\n",
      "816/816 [==============================] - 0s 411us/sample - loss: 71.3892 - val_loss: 51.2606\n",
      "Epoch 2/340\n",
      "816/816 [==============================] - 0s 79us/sample - loss: 50.9378 - val_loss: 50.3852\n",
      "Epoch 3/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 50.1267 - val_loss: 49.5967\n",
      "Epoch 4/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 49.3427 - val_loss: 48.8675\n",
      "Epoch 5/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 48.5693 - val_loss: 48.1404\n",
      "Epoch 6/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 47.8451 - val_loss: 47.4398\n",
      "Epoch 7/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 47.1484 - val_loss: 46.7468\n",
      "Epoch 8/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 46.4318 - val_loss: 46.0637\n",
      "Epoch 9/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 45.7506 - val_loss: 45.3892\n",
      "Epoch 10/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 45.0728 - val_loss: 44.7197\n",
      "Epoch 11/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 44.4017 - val_loss: 44.0418\n",
      "Epoch 12/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 43.7297 - val_loss: 43.3752\n",
      "Epoch 13/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 43.0677 - val_loss: 42.7103\n",
      "Epoch 14/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 42.4029 - val_loss: 42.0513\n",
      "Epoch 15/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 41.7505 - val_loss: 41.3915\n",
      "Epoch 16/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 41.0964 - val_loss: 40.7357\n",
      "Epoch 17/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 40.4372 - val_loss: 40.0670\n",
      "Epoch 18/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 39.7713 - val_loss: 39.4049\n",
      "Epoch 19/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 39.1107 - val_loss: 38.7454\n",
      "Epoch 20/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 38.4665 - val_loss: 38.0934\n",
      "Epoch 21/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 37.7916 - val_loss: 37.4290\n",
      "Epoch 22/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 37.1319 - val_loss: 36.7616\n",
      "Epoch 23/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 36.4750 - val_loss: 36.1027\n",
      "Epoch 24/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 35.8054 - val_loss: 35.4438\n",
      "Epoch 25/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 35.1612 - val_loss: 34.7899\n",
      "Epoch 26/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 34.5040 - val_loss: 34.1377\n",
      "Epoch 27/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 33.8550 - val_loss: 33.4865\n",
      "Epoch 28/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 33.2088 - val_loss: 32.8394\n",
      "Epoch 29/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 32.5598 - val_loss: 32.1943\n",
      "Epoch 30/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 31.9110 - val_loss: 31.5493\n",
      "Epoch 31/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 31.2653 - val_loss: 30.9117\n",
      "Epoch 32/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 30.6312 - val_loss: 30.2701\n",
      "Epoch 33/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 29.9828 - val_loss: 29.6345\n",
      "Epoch 34/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 29.3547 - val_loss: 29.0039\n",
      "Epoch 35/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 28.7259 - val_loss: 28.3772\n",
      "Epoch 36/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 28.0935 - val_loss: 27.7613\n",
      "Epoch 37/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 27.4771 - val_loss: 27.1463\n",
      "Epoch 38/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 26.8736 - val_loss: 26.5539\n",
      "Epoch 39/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 26.2796 - val_loss: 25.9570\n",
      "Epoch 40/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.6487 - val_loss: 25.3026\n",
      "Epoch 41/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.1222 - val_loss: 25.0372\n",
      "Epoch 42/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0317 - val_loss: 25.0316\n",
      "Epoch 43/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0310 - val_loss: 25.0308\n",
      "Epoch 44/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0305\n",
      "Epoch 45/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0302\n",
      "Epoch 46/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0318 - val_loss: 25.0298\n",
      "Epoch 47/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0297\n",
      "Epoch 48/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 49/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 50/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0310 - val_loss: 25.0297\n",
      "Epoch 51/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.0303 - val_loss: 25.0296\n",
      "Epoch 52/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 53/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0317 - val_loss: 25.0294\n",
      "Epoch 54/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 55/340\n",
      "816/816 [==============================] - 0s 106us/sample - loss: 25.0308 - val_loss: 25.0296\n",
      "Epoch 56/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0318 - val_loss: 25.0297\n",
      "Epoch 57/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0315 - val_loss: 25.0296\n",
      "Epoch 58/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 59/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0313 - val_loss: 25.0294\n",
      "Epoch 60/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.0308 - val_loss: 25.0296\n",
      "Epoch 61/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0295 - val_loss: 25.0295\n",
      "Epoch 62/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0307 - val_loss: 25.0297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0310 - val_loss: 25.0295\n",
      "Epoch 64/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0308 - val_loss: 25.0296\n",
      "Epoch 65/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0301 - val_loss: 25.0294\n",
      "Epoch 66/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0299 - val_loss: 25.0294\n",
      "Epoch 67/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0311 - val_loss: 25.0294\n",
      "Epoch 68/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 25.0311 - val_loss: 25.0293\n",
      "Epoch 69/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0313 - val_loss: 25.0294\n",
      "Epoch 70/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0319 - val_loss: 25.0292\n",
      "Epoch 71/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0316 - val_loss: 25.0292\n",
      "Epoch 72/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0301 - val_loss: 25.0294\n",
      "Epoch 73/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0315 - val_loss: 25.0293\n",
      "Epoch 74/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 75/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0318 - val_loss: 25.0295\n",
      "Epoch 76/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0312 - val_loss: 25.0293\n",
      "Epoch 77/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 78/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0310 - val_loss: 25.0293\n",
      "Epoch 79/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0303 - val_loss: 25.0293\n",
      "Epoch 80/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 81/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 25.0316 - val_loss: 25.0291\n",
      "Epoch 82/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0309 - val_loss: 25.0291\n",
      "Epoch 83/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 84/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0315 - val_loss: 25.0294\n",
      "Epoch 85/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0312 - val_loss: 25.0294\n",
      "Epoch 86/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 87/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 88/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0312 - val_loss: 25.0293\n",
      "Epoch 89/340\n",
      "816/816 [==============================] - 0s 105us/sample - loss: 25.0319 - val_loss: 25.0291\n",
      "Epoch 90/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0302 - val_loss: 25.0291\n",
      "Epoch 91/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 92/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 93/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0290\n",
      "Epoch 94/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0312 - val_loss: 25.0292\n",
      "Epoch 95/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 96/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 97/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0311 - val_loss: 25.0293\n",
      "Epoch 98/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 99/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0302 - val_loss: 25.0294\n",
      "Epoch 100/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0296\n",
      "Epoch 101/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 102/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0316 - val_loss: 25.0294\n",
      "Epoch 103/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 104/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 105/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0310 - val_loss: 25.0293\n",
      "Epoch 106/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0312 - val_loss: 25.0292\n",
      "Epoch 107/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 108/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 109/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0304 - val_loss: 25.0290\n",
      "Epoch 110/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0302 - val_loss: 25.0290\n",
      "Epoch 111/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0311 - val_loss: 25.0289\n",
      "Epoch 112/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0301 - val_loss: 25.0290\n",
      "Epoch 113/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0304 - val_loss: 25.0290\n",
      "Epoch 114/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0304 - val_loss: 25.0292\n",
      "Epoch 115/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 116/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0315 - val_loss: 25.0294\n",
      "Epoch 117/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0314 - val_loss: 25.0293\n",
      "Epoch 118/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 119/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 120/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0315 - val_loss: 25.0291\n",
      "Epoch 121/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0311 - val_loss: 25.0291\n",
      "Epoch 122/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0316 - val_loss: 25.0290\n",
      "Epoch 123/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0290\n",
      "Epoch 124/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0299 - val_loss: 25.0291\n",
      "Epoch 125/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0309 - val_loss: 25.0291\n",
      "Epoch 126/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0304 - val_loss: 25.0291\n",
      "Epoch 127/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0310 - val_loss: 25.0291\n",
      "Epoch 128/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 129/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0311 - val_loss: 25.0291\n",
      "Epoch 130/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0316 - val_loss: 25.0291\n",
      "Epoch 131/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0313 - val_loss: 25.0291\n",
      "Epoch 132/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 133/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0313 - val_loss: 25.0292\n",
      "Epoch 134/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 135/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 136/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 137/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 138/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 140/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0311 - val_loss: 25.0294\n",
      "Epoch 141/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0309 - val_loss: 25.0292\n",
      "Epoch 142/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 143/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0309 - val_loss: 25.0292\n",
      "Epoch 144/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 145/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0311 - val_loss: 25.0292\n",
      "Epoch 146/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0310 - val_loss: 25.0291\n",
      "Epoch 147/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 148/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 149/340\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 25.0311 - val_loss: 25.0293\n",
      "Epoch 150/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0312 - val_loss: 25.0294\n",
      "Epoch 151/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 152/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 153/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 154/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0314 - val_loss: 25.0293\n",
      "Epoch 155/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 156/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0314 - val_loss: 25.0293\n",
      "Epoch 157/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 158/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 159/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 160/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 161/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0304 - val_loss: 25.0293\n",
      "Epoch 162/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 163/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 164/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 165/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0307 - val_loss: 25.0289\n",
      "Epoch 166/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0289\n",
      "Epoch 167/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0309 - val_loss: 25.0289\n",
      "Epoch 168/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0310 - val_loss: 25.0289\n",
      "Epoch 169/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0312 - val_loss: 25.0290\n",
      "Epoch 170/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0309 - val_loss: 25.0291\n",
      "Epoch 171/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 172/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 173/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0310 - val_loss: 25.0291\n",
      "Epoch 174/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 175/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 176/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 177/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 178/340\n",
      "816/816 [==============================] - 0s 78us/sample - loss: 25.0304 - val_loss: 25.0292\n",
      "Epoch 179/340\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 180/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 181/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 182/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 183/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 184/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0310 - val_loss: 25.0292\n",
      "Epoch 185/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 186/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 187/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0295\n",
      "Epoch 188/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0313 - val_loss: 25.0294\n",
      "Epoch 189/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 190/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0310 - val_loss: 25.0294\n",
      "Epoch 191/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 192/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 193/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 194/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0310 - val_loss: 25.0292\n",
      "Epoch 195/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 196/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 197/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 198/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 199/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0311 - val_loss: 25.0293\n",
      "Epoch 200/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0305 - val_loss: 25.0294\n",
      "Epoch 201/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0304 - val_loss: 25.0293\n",
      "Epoch 202/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 203/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0309 - val_loss: 25.0295\n",
      "Epoch 204/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0310 - val_loss: 25.0294\n",
      "Epoch 205/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0309 - val_loss: 25.0295\n",
      "Epoch 206/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 207/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 208/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0295\n",
      "Epoch 209/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0305 - val_loss: 25.0295\n",
      "Epoch 210/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 211/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0309 - val_loss: 25.0292\n",
      "Epoch 212/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 213/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 214/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0312 - val_loss: 25.0294\n",
      "Epoch 215/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0305 - val_loss: 25.0295\n",
      "Epoch 216/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 217/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0310 - val_loss: 25.0294\n",
      "Epoch 218/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0295\n",
      "Epoch 219/340\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 220/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0311 - val_loss: 25.0293\n",
      "Epoch 221/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 222/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0304 - val_loss: 25.0293\n",
      "Epoch 223/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 224/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 225/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 226/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 227/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 228/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0311 - val_loss: 25.0292\n",
      "Epoch 229/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 230/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 231/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 232/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0312 - val_loss: 25.0292\n",
      "Epoch 233/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 234/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 235/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 236/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 237/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 238/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 239/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 240/340\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 241/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0294\n",
      "Epoch 242/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 243/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 244/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 245/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0292\n",
      "Epoch 246/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 247/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 248/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 249/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 250/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0303 - val_loss: 25.0293\n",
      "Epoch 251/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0310 - val_loss: 25.0293\n",
      "Epoch 252/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 253/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 254/340\n",
      "816/816 [==============================] - 0s 104us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 255/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 256/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 257/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 258/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 259/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 260/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 261/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 262/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0306 - val_loss: 25.0296\n",
      "Epoch 263/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0308 - val_loss: 25.0295\n",
      "Epoch 264/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0295\n",
      "Epoch 265/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0304 - val_loss: 25.0295\n",
      "Epoch 266/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 267/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 268/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 269/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0303 - val_loss: 25.0294\n",
      "Epoch 270/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 25.0305 - val_loss: 25.0294\n",
      "Epoch 271/340\n",
      "816/816 [==============================] - 0s 83us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 272/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 273/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0292\n",
      "Epoch 274/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0304 - val_loss: 25.0292\n",
      "Epoch 275/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 276/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 277/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 278/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 279/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 280/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 281/340\n",
      "816/816 [==============================] - 0s 91us/sample - loss: 25.0304 - val_loss: 25.0294\n",
      "Epoch 282/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 283/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 284/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 285/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 286/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 287/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 288/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0308 - val_loss: 25.0294\n",
      "Epoch 289/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0305 - val_loss: 25.0294\n",
      "Epoch 290/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0294\n",
      "Epoch 291/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0310 - val_loss: 25.0293\n",
      "Epoch 292/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 293/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0309 - val_loss: 25.0294\n",
      "Epoch 294/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0304 - val_loss: 25.0293\n",
      "Epoch 295/340\n",
      "816/816 [==============================] - 0s 87us/sample - loss: 25.0309 - val_loss: 25.0293\n",
      "Epoch 296/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 297/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 298/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 299/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 300/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 301/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 302/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0306 - val_loss: 25.0290\n",
      "Epoch 303/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0306 - val_loss: 25.0290\n",
      "Epoch 304/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0307 - val_loss: 25.0290\n",
      "Epoch 305/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 306/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 307/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 308/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 309/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 310/340\n",
      "816/816 [==============================] - 0s 89us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 311/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 312/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 313/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0293\n",
      "Epoch 314/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 315/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 316/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 317/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 318/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0307 - val_loss: 25.0292\n",
      "Epoch 319/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 320/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 321/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0305 - val_loss: 25.0292\n",
      "Epoch 322/340\n",
      "816/816 [==============================] - 0s 95us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 323/340\n",
      "816/816 [==============================] - 0s 97us/sample - loss: 25.0303 - val_loss: 25.0291\n",
      "Epoch 324/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 325/340\n",
      "816/816 [==============================] - 0s 101us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 326/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 327/340\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 328/340\n",
      "816/816 [==============================] - 0s 94us/sample - loss: 25.0304 - val_loss: 25.0291\n",
      "Epoch 329/340\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 25.0305 - val_loss: 25.0291\n",
      "Epoch 330/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0307 - val_loss: 25.0291\n",
      "Epoch 331/340\n",
      "816/816 [==============================] - 0s 103us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 332/340\n",
      "816/816 [==============================] - 0s 99us/sample - loss: 25.0306 - val_loss: 25.0291\n",
      "Epoch 333/340\n",
      "816/816 [==============================] - 0s 102us/sample - loss: 25.0308 - val_loss: 25.0291\n",
      "Epoch 334/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0309 - val_loss: 25.0291\n",
      "Epoch 335/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0306 - val_loss: 25.0292\n",
      "Epoch 336/340\n",
      "816/816 [==============================] - 0s 98us/sample - loss: 25.0308 - val_loss: 25.0293\n",
      "Epoch 337/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0308 - val_loss: 25.0292\n",
      "Epoch 338/340\n",
      "816/816 [==============================] - 0s 96us/sample - loss: 25.0305 - val_loss: 25.0293\n",
      "Epoch 339/340\n",
      "816/816 [==============================] - 0s 92us/sample - loss: 25.0307 - val_loss: 25.0293\n",
      "Epoch 340/340\n",
      "816/816 [==============================] - 0s 100us/sample - loss: 25.0309 - val_loss: 25.0292\n"
     ]
    }
   ],
   "source": [
    "weights_history = []\n",
    "loss = []\n",
    "val_loss = []\n",
    "\n",
    "num_alphas = 20\n",
    "alpha_range = np.logspace(-2.4, 0.1, num_alphas)\n",
    "\n",
    "weights = np.array([])\n",
    "acc = np.array([])\n",
    "for al in alpha_range:\n",
    "    model = Sequential([selection_layer(units=X.shape[-1], alpha = al, norm=.5*100*int(800/32.)), layers.Dense(10, activation='relu'), layers.Dropout(.1), layers.Dense(3, activation='softmax')])\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    hi = model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=340, validation_split = 0.15, callbacks=[MyCallback()])\n",
    "    weights = np.append(weights,tf.linalg.tensor_diag_part(model.layers[0].weights[0]).numpy())\n",
    "    acc = np.append(acc, accuracy_score(y_test,model.predict_classes(X_test)))\n",
    "    loss= np.append(loss, hi.history['loss'])\n",
    "    val_loss = np.append(val_loss, hi.history['val_loss'])\n",
    "weights = weights.reshape(-1,20)\n",
    "weights_history = np.array(weights_history).reshape(num_alphas,-1,X.shape[-1])\n",
    "loss = loss.reshape(num_alphas,-1)\n",
    "val_loss = val_loss.reshape(num_alphas,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savez('classifier_for_poster', weight=weights, weights_history=weights_history, alpha_range=alpha_range, loss=loss, val_loss=val_loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "weight",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_obj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight is not a file in the archive'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-22c89d59db65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classifier_for_poster.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_obj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: weight"
     ]
    }
   ],
   "source": [
    "data = np.load('classifier_for_poster.npz')\n",
    "weights, weights_history, alpha_range, loss, val_loss = data.f.weight, data.f.weights_history, data.f.alpha_range, data.f.loss, data.f.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77916667 0.79583333 0.82083333 0.80416667 0.7875     0.80833333\n",
      " 0.72083333 0.81666667 0.77916667 0.81666667 0.7875     0.77083333\n",
      " 0.60833333 0.675      0.46666667 0.625      0.27916667 0.27916667\n",
      " 0.27916667 0.27916667]\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "plot performance and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "#fig.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(r'Performance and feature selection as function of $\\alpha$')\n",
    "\n",
    "ax[0].plot(alpha_range, acc, color = 'olivedrab')\n",
    "#xlabel(r'regularization strength $\\alpha$')\n",
    "ax[0].set_ylabel(r'accuracy score')\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "tick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\n",
    "tick.set_powerlimits((0,0))\n",
    "tg = [u\"${}$\".format(tick.format_data(round(x,3))) for x in alpha_range]\n",
    "\n",
    "sns.heatmap((weights.T>0), ax = ax[1], cmap='tab20c_r', cbar=False, alpha=.7, linewidth=.5, xticklabels=tg)\n",
    "ax[1].set_ylabel('feature #')\n",
    "ax[1].set_xlabel(r'regularization strength $\\alpha$')\n",
    "ax[1].axhline(y=10, color = 'k', ls = ':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ind = -5\n",
    "[plt.plot(x, c = 'indianred', lw = .75, alpha = .7) for x in weights_history[ind].T[:9]]\n",
    "plt.plot(weights_history[ind].T[9], c = 'indianred', lw = .75, alpha = .7, label='informative features')\n",
    "[plt.plot(x, c = 'dodgerblue', lw = .75, alpha = .7) for x in weights_history[ind].T[11:]]\n",
    "plt.plot(weights_history[ind].T[10], c = 'dodgerblue', lw = .75, alpha = .7, label='non-informative features')\n",
    "plt.xlabel('# batches')\n",
    "plt.ylabel('selection layer weights')\n",
    "plt.title(r'$\\alpha$={:.2f}'.format(alpha_range[ind]))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = -5\n",
    "plt.figure()\n",
    "plt.plot(loss[ind], label='loss')\n",
    "plt.plot(val_loss[ind], label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.title(r'$\\alpha$={:.2f}'.format(alpha_range[ind]))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### single $\\alpha$ run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/14\n",
      "816/816 [==============================] - 0s 431us/sample - loss: 112.1359 - val_loss: 80.2545\n",
      "Epoch 2/14\n",
      "816/816 [==============================] - 0s 70us/sample - loss: 79.9357 - val_loss: 79.0001\n",
      "Epoch 3/14\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 78.6966 - val_loss: 77.8895\n",
      "Epoch 4/14\n",
      "816/816 [==============================] - 0s 90us/sample - loss: 77.5167 - val_loss: 76.8096\n",
      "Epoch 5/14\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 76.4026 - val_loss: 75.7098\n",
      "Epoch 6/14\n",
      "816/816 [==============================] - 0s 85us/sample - loss: 75.2596 - val_loss: 74.6341\n",
      "Epoch 7/14\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 74.1346 - val_loss: 73.5542\n",
      "Epoch 8/14\n",
      "816/816 [==============================] - 0s 93us/sample - loss: 73.0985 - val_loss: 72.4877\n",
      "Epoch 9/14\n",
      "816/816 [==============================] - 0s 86us/sample - loss: 71.9918 - val_loss: 71.4297\n",
      "Epoch 10/14\n",
      "816/816 [==============================] - 0s 84us/sample - loss: 70.9456 - val_loss: 70.3524\n",
      "Epoch 11/14\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 69.8610 - val_loss: 69.2999\n",
      "Epoch 12/14\n",
      "816/816 [==============================] - 0s 78us/sample - loss: 68.8130 - val_loss: 68.2237\n",
      "Epoch 13/14\n",
      "816/816 [==============================] - 0s 88us/sample - loss: 67.7519 - val_loss: 67.1799\n",
      "Epoch 14/14\n",
      "816/816 [==============================] - 0s 82us/sample - loss: 66.7052 - val_loss: 66.1332\n"
     ]
    }
   ],
   "source": [
    "weights_history = []\n",
    "model = Sequential([selection_layer(units=X.shape[-1], alpha = 2., norm=100*int(800/32.)), layers.Dense(10, activation='relu'), layers.Dropout(.1), layers.Dense(3, activation='softmax')])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "history = model.fit(X_train, tf.keras.utils.to_categorical(y_train), epochs=14, validation_split = 0.15, callbacks=[MyCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hippocampus data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herfurtht/miniconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['axes', 'concatenate']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "\n",
    "from scipy.io import loadmat\n",
    "sys.path.append('/home/herfurtht/mpi-br/project1/')\n",
    "sys.path.append('/home/herfurtht/mpi-br/rat/Neural_Decoding_fork/')\n",
    "\n",
    "import preprocessing_funcs\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'run_speed', 'spikes', 'x_pos', 'y_pos'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = loadmat('hippo/data_CA1.mat')  # load mat-file\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595000, 94), (595000, 1))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['time'] = arange(len(mat['run_speed']))/1000. #time in sec\n",
    "mat['run_speed'], mat['x_pos'], mat['y_pos'] = mat['run_speed'].ravel(), mat['x_pos'].ravel(), mat['y_pos'].ravel()\n",
    "mat['spikes'].shape, mat['x_pos'].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_shift = 0 #here in ms\n",
    "\n",
    "mat['spikes'] = mat['spikes'][:]\n",
    "spike_times = preprocessing_funcs.binary_to_times(mat['spikes'], .001)\n",
    "t_start = 0.\n",
    "t_end = 595.- time_shift/1000.\n",
    "vel_times = arange(0, 595., .001)\n",
    "vels = array(list(zip(mat['x_pos'], mat['y_pos'])))\n",
    "\n",
    "vels = vels[time_shift:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "times = 0, 595000\n",
    "scatter(mat['x_pos'][times[0]:times[1]], mat['y_pos'][times[0]:times[1]], c = arange(len(mat['x_pos'][times[0]:times[1]])), norm = mpl.colors.Normalize(vmin=0., vmax= len(mat['x_pos'][times[0]:times[1]])), cmap = cm.jet, s = .3)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt= .05 #Size of time bins (in seconds)\n",
    "downsample_factor=1 #Downsampling of output (to make binning go faster). 1 means no downsamplinga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###Preprocessing to put spikes and output in bins###\n",
    "\n",
    "#Bin neural data using \"bin_spikes\" function\n",
    "neural_data= preprocessing_funcs.bin_spikes(spike_times,dt,t_start,t_end)\n",
    "### remove neurons with too little spikes\n",
    "neural_data = neural_data[:, neural_data.sum(0)> 10]\n",
    "\n",
    "#Bin output (velocity) data using \"bin_output\" function\n",
    "vels_binned= preprocessing_funcs.bin_output(vels,vel_times,dt,t_start,t_end,downsample_factor)\n",
    "\n",
    "#velocities in either direction\n",
    "#vels_binned = gradient(vels_binned, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#6, 1, 6 before 0, 1, 21\n",
    "bins_before= 5 #How many bins of neural data prior to the output are used for decoding\n",
    "bins_current = 1 #Whether to use concurrent time bin of neural data\n",
    "bins_after= 5 #How many bins of neural data after the output are used for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "X=preprocessing_funcs.get_spikes_with_history(neural_data,bins_before,bins_after,bins_current)\n",
    "\n",
    "# Format for Wiener Filter, Wiener Cascade, XGBoost, and Dense Neural Network\n",
    "#Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "X_flat=X.reshape(X.shape[0],(X.shape[1]*X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set decoding output\n",
    "y=vels_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_mean, X_train, X_test, X_valid, X_flat_train_mean, X_flat_train, X_flat_test, X_flat_valid, y_train_mean, y_train, y_test, y_valid = preprocessing_funcs.get_training_data(X,y, [.8,.8], bins_before, bins_after)\n",
    "X_test, y_test = X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## build decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, SimpleRNN, GRU, Activation, Dropout, Conv1D, concatenate, Flatten, TimeDistributed\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8080 samples, validate on 1427 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-d6f78cb8e573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Set loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0my_valid_predicted_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Callbacks batch end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \"\"\"\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# For backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-35e89ccd7b90>\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_diag_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mweights_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    " #Declare model\n",
    "model=Sequential() #Declare model\n",
    "# Add selection layer (Time distributed)\n",
    "model.add(TimeDistributed(selection_layer(units=X_train.shape[2], alpha = 5000, norm=100)))\n",
    "\n",
    "#Add recurrent layer\n",
    "model.add(LSTM(64, recurrent_dropout=.1,dropout=.1)) #Within recurrent layer, include dropout\n",
    "model.add(Dropout(.1)) #Dropout some units (recurrent layer output units)\n",
    "\n",
    "#Add dense connections to output layer\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "#Fit model (and set fitting parameters)\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['accuracy']) #Set loss function and optimizer\n",
    "#Fit the model\n",
    "model.fit(X_train,y_train, epochs=10,verbose=1, validation_split = .15, callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience= 2, verbose=0, mode='auto'), MyCallback()]) #Get predictions\n",
    "y_valid_predicted_lstm=model.predict(X_valid)\n",
    "\n",
    "#Get metric of fit\n",
    "R2s_lstm=r2_score(y_valid,y_valid_predicted_lstm)\n",
    "\n",
    "print('R2s:', R2s_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 729us/sample - loss: 14816.4889 - accuracy: 0.8349 - val_loss: 13494.4677 - val_accuracy: 0.6854\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 600us/sample - loss: 12807.8059 - accuracy: 0.8837 - val_loss: 11865.9307 - val_accuracy: 0.8458\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 11089.0463 - accuracy: 0.9008 - val_loss: 10670.5110 - val_accuracy: 0.8276\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 9572.8911 - accuracy: 0.9055 - val_loss: 9552.5425 - val_accuracy: 0.8591\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 8234.2215 - accuracy: 0.9207 - val_loss: 8669.6163 - val_accuracy: 0.8416\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 7079.0327 - accuracy: 0.9209 - val_loss: 7909.0391 - val_accuracy: 0.8269\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 6066.7747 - accuracy: 0.9266 - val_loss: 7158.7001 - val_accuracy: 0.8641\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 5212.7385 - accuracy: 0.9265 - val_loss: 6783.4145 - val_accuracy: 0.8549\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 612us/sample - loss: 4460.9802 - accuracy: 0.9296 - val_loss: 6329.2755 - val_accuracy: 0.8472\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 612us/sample - loss: 3843.6363 - accuracy: 0.9316 - val_loss: 5854.0700 - val_accuracy: 0.8381\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 579us/sample - loss: 3294.2749 - accuracy: 0.9301 - val_loss: 5702.4369 - val_accuracy: 0.8409\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 2829.5030 - accuracy: 0.9322 - val_loss: 5544.9883 - val_accuracy: 0.7849\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 593us/sample - loss: 2448.3814 - accuracy: 0.9364 - val_loss: 5179.1327 - val_accuracy: 0.8346\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 592us/sample - loss: 2173.6656 - accuracy: 0.9363 - val_loss: 5024.2292 - val_accuracy: 0.8332\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 1916.6623 - accuracy: 0.9373 - val_loss: 4801.7376 - val_accuracy: 0.8409\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 1696.2496 - accuracy: 0.9365 - val_loss: 4803.7887 - val_accuracy: 0.8388\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 1553.7590 - accuracy: 0.9402 - val_loss: 4607.9523 - val_accuracy: 0.8171\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 1370.8312 - accuracy: 0.9386 - val_loss: 4856.4196 - val_accuracy: 0.8472\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 1331.3627 - accuracy: 0.9420 - val_loss: 4296.0526 - val_accuracy: 0.8402\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 1239.4153 - accuracy: 0.9431 - val_loss: 4529.9363 - val_accuracy: 0.8276\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 612us/sample - loss: 1168.5418 - accuracy: 0.9412 - val_loss: 4283.1204 - val_accuracy: 0.8234\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 1141.5210 - accuracy: 0.9412 - val_loss: 4502.4272 - val_accuracy: 0.8297\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 1065.2121 - accuracy: 0.9477 - val_loss: 4537.0393 - val_accuracy: 0.8283\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 1023.9048 - accuracy: 0.9472 - val_loss: 4155.3682 - val_accuracy: 0.8409\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 1005.9384 - accuracy: 0.9453 - val_loss: 4481.0681 - val_accuracy: 0.8297\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 719us/sample - loss: 14909.7145 - accuracy: 0.8410 - val_loss: 13305.1451 - val_accuracy: 0.8774\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 12853.0748 - accuracy: 0.8801 - val_loss: 11899.2033 - val_accuracy: 0.8577\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 11202.3872 - accuracy: 0.8943 - val_loss: 10804.7816 - val_accuracy: 0.8767\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 9740.2943 - accuracy: 0.9050 - val_loss: 9846.1477 - val_accuracy: 0.8648\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 8460.2775 - accuracy: 0.9099 - val_loss: 8975.3535 - val_accuracy: 0.8430\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 7305.0419 - accuracy: 0.9175 - val_loss: 8472.3852 - val_accuracy: 0.8388\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 6333.6454 - accuracy: 0.9213 - val_loss: 7714.7980 - val_accuracy: 0.8479\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 598us/sample - loss: 5495.6861 - accuracy: 0.9218 - val_loss: 7251.0866 - val_accuracy: 0.8304\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 4723.3924 - accuracy: 0.9268 - val_loss: 6693.5448 - val_accuracy: 0.8374\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 600us/sample - loss: 4141.3994 - accuracy: 0.9284 - val_loss: 6181.9556 - val_accuracy: 0.8283\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 3591.9442 - accuracy: 0.9295 - val_loss: 5844.8348 - val_accuracy: 0.8500\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 601us/sample - loss: 3095.0965 - accuracy: 0.9292 - val_loss: 5638.8774 - val_accuracy: 0.8339\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 2736.2930 - accuracy: 0.9316 - val_loss: 5172.6004 - val_accuracy: 0.8402\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 2414.7591 - accuracy: 0.9354 - val_loss: 4897.0140 - val_accuracy: 0.8367\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 583us/sample - loss: 2138.6144 - accuracy: 0.9360 - val_loss: 5278.5186 - val_accuracy: 0.8500\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 1962.3923 - accuracy: 0.9344 - val_loss: 4939.1776 - val_accuracy: 0.8423\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 576us/sample - loss: 1749.2946 - accuracy: 0.9358 - val_loss: 4826.1807 - val_accuracy: 0.8423\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 562us/sample - loss: 1620.3246 - accuracy: 0.9357 - val_loss: 4230.7941 - val_accuracy: 0.8465\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 577us/sample - loss: 1518.7890 - accuracy: 0.9379 - val_loss: 4254.6054 - val_accuracy: 0.8591\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 586us/sample - loss: 1449.6297 - accuracy: 0.9381 - val_loss: 4660.6426 - val_accuracy: 0.8626\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 4s 548us/sample - loss: 1346.2854 - accuracy: 0.9380 - val_loss: 4294.4638 - val_accuracy: 0.8591\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 4s 550us/sample - loss: 1309.4417 - accuracy: 0.9411 - val_loss: 4200.7587 - val_accuracy: 0.8605\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 562us/sample - loss: 1251.2570 - accuracy: 0.9439 - val_loss: 4216.5870 - val_accuracy: 0.8528\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 572us/sample - loss: 1263.1579 - accuracy: 0.9421 - val_loss: 4580.1031 - val_accuracy: 0.8339\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 568us/sample - loss: 1217.2211 - accuracy: 0.9454 - val_loss: 4224.9686 - val_accuracy: 0.8570\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 734us/sample - loss: 15406.4227 - accuracy: 0.8114 - val_loss: 13989.7018 - val_accuracy: 0.7169\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 597us/sample - loss: 13334.5605 - accuracy: 0.8606 - val_loss: 12490.2253 - val_accuracy: 0.7912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 11643.3202 - accuracy: 0.8886 - val_loss: 11359.2503 - val_accuracy: 0.8255\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 601us/sample - loss: 10187.0436 - accuracy: 0.9003 - val_loss: 10277.4621 - val_accuracy: 0.8206\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 8901.5444 - accuracy: 0.9061 - val_loss: 9417.1564 - val_accuracy: 0.8444\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 7768.5266 - accuracy: 0.9141 - val_loss: 8754.7010 - val_accuracy: 0.8367\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 6791.0888 - accuracy: 0.9180 - val_loss: 8080.0937 - val_accuracy: 0.8311\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 5925.7164 - accuracy: 0.9233 - val_loss: 7554.8636 - val_accuracy: 0.8486\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 5186.0896 - accuracy: 0.9254 - val_loss: 7195.9178 - val_accuracy: 0.8248\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 4581.8115 - accuracy: 0.9243 - val_loss: 6728.6133 - val_accuracy: 0.8577\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 4001.9522 - accuracy: 0.9246 - val_loss: 6656.5839 - val_accuracy: 0.8269\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 4s 548us/sample - loss: 3534.6584 - accuracy: 0.9287 - val_loss: 6242.1167 - val_accuracy: 0.8549\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 575us/sample - loss: 3119.1477 - accuracy: 0.9313 - val_loss: 5847.3740 - val_accuracy: 0.8683\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 2809.8373 - accuracy: 0.9326 - val_loss: 5726.0117 - val_accuracy: 0.8500\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 584us/sample - loss: 2543.8030 - accuracy: 0.9297 - val_loss: 5655.1712 - val_accuracy: 0.8633\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 586us/sample - loss: 2340.5710 - accuracy: 0.9329 - val_loss: 5331.9741 - val_accuracy: 0.8486\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 569us/sample - loss: 2163.9947 - accuracy: 0.9332 - val_loss: 5403.5471 - val_accuracy: 0.8395\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 580us/sample - loss: 1990.3104 - accuracy: 0.9363 - val_loss: 5470.6811 - val_accuracy: 0.8626\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 1887.0031 - accuracy: 0.9380 - val_loss: 5022.5060 - val_accuracy: 0.8535\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 589us/sample - loss: 1819.1745 - accuracy: 0.9401 - val_loss: 5102.1622 - val_accuracy: 0.8612\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 590us/sample - loss: 1765.7581 - accuracy: 0.9399 - val_loss: 4784.1065 - val_accuracy: 0.8648\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 583us/sample - loss: 1711.7439 - accuracy: 0.9452 - val_loss: 5299.5679 - val_accuracy: 0.8325\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 1672.3186 - accuracy: 0.9400 - val_loss: 5119.2309 - val_accuracy: 0.8584\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 583us/sample - loss: 1624.7006 - accuracy: 0.9421 - val_loss: 4924.3691 - val_accuracy: 0.8584\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 1641.4272 - accuracy: 0.9464 - val_loss: 4772.0681 - val_accuracy: 0.8402\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 732us/sample - loss: 16301.4960 - accuracy: 0.7863 - val_loss: 14746.2803 - val_accuracy: 0.7239\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 595us/sample - loss: 14145.9438 - accuracy: 0.8445 - val_loss: 13266.8312 - val_accuracy: 0.8199\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 12487.7511 - accuracy: 0.8755 - val_loss: 12212.3624 - val_accuracy: 0.8633\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 11012.4245 - accuracy: 0.8875 - val_loss: 11102.6053 - val_accuracy: 0.8760\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 9717.6270 - accuracy: 0.9010 - val_loss: 10472.5603 - val_accuracy: 0.8704\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 602us/sample - loss: 8603.3172 - accuracy: 0.9055 - val_loss: 9527.3288 - val_accuracy: 0.8507\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 7628.0857 - accuracy: 0.9135 - val_loss: 8993.2665 - val_accuracy: 0.8465\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 6769.0584 - accuracy: 0.9182 - val_loss: 8492.1696 - val_accuracy: 0.8500\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 6016.8587 - accuracy: 0.9223 - val_loss: 8089.6642 - val_accuracy: 0.8297\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 5306.8719 - accuracy: 0.9243 - val_loss: 7667.9476 - val_accuracy: 0.8353\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 4793.9824 - accuracy: 0.9211 - val_loss: 7532.1360 - val_accuracy: 0.8199\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 4319.5387 - accuracy: 0.9227 - val_loss: 6906.0784 - val_accuracy: 0.8591\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 3930.4927 - accuracy: 0.9181 - val_loss: 6459.7322 - val_accuracy: 0.8514\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 3581.2332 - accuracy: 0.9282 - val_loss: 6254.5915 - val_accuracy: 0.8255\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 3351.8909 - accuracy: 0.9260 - val_loss: 6116.9936 - val_accuracy: 0.8521\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 582us/sample - loss: 3101.7863 - accuracy: 0.9258 - val_loss: 5927.4033 - val_accuracy: 0.8381\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 581us/sample - loss: 2927.0852 - accuracy: 0.9298 - val_loss: 6191.5012 - val_accuracy: 0.8416\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 2807.4435 - accuracy: 0.9338 - val_loss: 5811.3345 - val_accuracy: 0.8269\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 2744.4671 - accuracy: 0.9319 - val_loss: 5675.0160 - val_accuracy: 0.8472\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 584us/sample - loss: 2644.1536 - accuracy: 0.9342 - val_loss: 5570.7709 - val_accuracy: 0.8626\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 583us/sample - loss: 2579.0527 - accuracy: 0.9338 - val_loss: 5285.9969 - val_accuracy: 0.8619\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 2517.4109 - accuracy: 0.9379 - val_loss: 5448.9742 - val_accuracy: 0.8584\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 586us/sample - loss: 2504.4277 - accuracy: 0.9313 - val_loss: 5777.3285 - val_accuracy: 0.8570\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 2452.6197 - accuracy: 0.9364 - val_loss: 5562.3920 - val_accuracy: 0.8633\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 2412.3334 - accuracy: 0.9415 - val_loss: 5506.9735 - val_accuracy: 0.8690\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 745us/sample - loss: 18149.0052 - accuracy: 0.8401 - val_loss: 16427.1327 - val_accuracy: 0.8339\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 597us/sample - loss: 15845.6273 - accuracy: 0.8718 - val_loss: 14949.8922 - val_accuracy: 0.8262\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 14114.0197 - accuracy: 0.8920 - val_loss: 13631.1696 - val_accuracy: 0.8220\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 12623.4139 - accuracy: 0.8983 - val_loss: 12583.3648 - val_accuracy: 0.8612\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 11296.6917 - accuracy: 0.9073 - val_loss: 11623.6342 - val_accuracy: 0.8556\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 10135.1454 - accuracy: 0.9074 - val_loss: 10945.2444 - val_accuracy: 0.8893\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 9167.9051 - accuracy: 0.9104 - val_loss: 10277.7087 - val_accuracy: 0.8816\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 8301.7277 - accuracy: 0.9145 - val_loss: 9640.0884 - val_accuracy: 0.8234\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 7574.2408 - accuracy: 0.9201 - val_loss: 9246.0942 - val_accuracy: 0.8858\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 6943.7320 - accuracy: 0.9192 - val_loss: 8867.2268 - val_accuracy: 0.8844\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 6436.7937 - accuracy: 0.9230 - val_loss: 8580.8783 - val_accuracy: 0.8444\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 5972.0272 - accuracy: 0.9222 - val_loss: 8272.9193 - val_accuracy: 0.8725\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 5631.8301 - accuracy: 0.9229 - val_loss: 8010.6323 - val_accuracy: 0.8619\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 5305.7948 - accuracy: 0.9209 - val_loss: 7944.0987 - val_accuracy: 0.8704\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 591us/sample - loss: 5002.7148 - accuracy: 0.9270 - val_loss: 7753.5294 - val_accuracy: 0.8381\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 4805.9619 - accuracy: 0.9318 - val_loss: 7270.7133 - val_accuracy: 0.8339\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 4594.2316 - accuracy: 0.9282 - val_loss: 7149.3716 - val_accuracy: 0.8472\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 4424.9432 - accuracy: 0.9360 - val_loss: 7537.0917 - val_accuracy: 0.8591\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 4332.1106 - accuracy: 0.9308 - val_loss: 6981.0740 - val_accuracy: 0.8542\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 601us/sample - loss: 4231.4012 - accuracy: 0.9378 - val_loss: 7024.5387 - val_accuracy: 0.8935\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 4177.8582 - accuracy: 0.9360 - val_loss: 6614.4823 - val_accuracy: 0.8830\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 4072.1145 - accuracy: 0.9363 - val_loss: 7098.4871 - val_accuracy: 0.8823\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 4078.6614 - accuracy: 0.9359 - val_loss: 7099.4436 - val_accuracy: 0.8535\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 4005.3807 - accuracy: 0.9386 - val_loss: 6981.5530 - val_accuracy: 0.8697\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 3972.1790 - accuracy: 0.9362 - val_loss: 6591.8088 - val_accuracy: 0.8676\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 757us/sample - loss: 21895.8019 - accuracy: 0.8096 - val_loss: 19944.7633 - val_accuracy: 0.6573\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 19226.1868 - accuracy: 0.8603 - val_loss: 18203.1832 - val_accuracy: 0.8353\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 618us/sample - loss: 17379.1254 - accuracy: 0.8839 - val_loss: 16923.7577 - val_accuracy: 0.8192\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 619us/sample - loss: 15816.2098 - accuracy: 0.8946 - val_loss: 15859.9101 - val_accuracy: 0.8669\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 622us/sample - loss: 14479.2743 - accuracy: 0.8968 - val_loss: 14928.0832 - val_accuracy: 0.8851\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 13312.8610 - accuracy: 0.9029 - val_loss: 14255.7341 - val_accuracy: 0.8066\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 623us/sample - loss: 12354.4241 - accuracy: 0.9046 - val_loss: 13339.0690 - val_accuracy: 0.8886\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 623us/sample - loss: 11489.4797 - accuracy: 0.9087 - val_loss: 13050.4649 - val_accuracy: 0.8858\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 10779.2929 - accuracy: 0.9098 - val_loss: 12420.9557 - val_accuracy: 0.8612\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 622us/sample - loss: 10132.4524 - accuracy: 0.9159 - val_loss: 12179.2352 - val_accuracy: 0.8837\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 9559.6467 - accuracy: 0.9124 - val_loss: 11465.2451 - val_accuracy: 0.8577\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 620us/sample - loss: 9121.1479 - accuracy: 0.9161 - val_loss: 11416.3801 - val_accuracy: 0.8521\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 8663.4476 - accuracy: 0.9172 - val_loss: 11305.2316 - val_accuracy: 0.8395\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 8331.5783 - accuracy: 0.9227 - val_loss: 10893.2852 - val_accuracy: 0.8493\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 8097.5770 - accuracy: 0.9211 - val_loss: 10908.2544 - val_accuracy: 0.8192\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 7901.9935 - accuracy: 0.9224 - val_loss: 10383.2913 - val_accuracy: 0.8605\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 7681.3922 - accuracy: 0.9245 - val_loss: 10324.0034 - val_accuracy: 0.8500\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 7533.5134 - accuracy: 0.9264 - val_loss: 10293.8240 - val_accuracy: 0.8591\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 623us/sample - loss: 7421.9564 - accuracy: 0.9264 - val_loss: 10333.3271 - val_accuracy: 0.8633\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 624us/sample - loss: 7315.3957 - accuracy: 0.9305 - val_loss: 10282.5816 - val_accuracy: 0.8542\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 7260.3338 - accuracy: 0.9298 - val_loss: 9631.3236 - val_accuracy: 0.8633\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 621us/sample - loss: 7167.2752 - accuracy: 0.9293 - val_loss: 9720.5443 - val_accuracy: 0.8711\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 620us/sample - loss: 7148.8593 - accuracy: 0.9341 - val_loss: 10121.4833 - val_accuracy: 0.8683\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 620us/sample - loss: 7166.6457 - accuracy: 0.9297 - val_loss: 9855.2446 - val_accuracy: 0.8591\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 618us/sample - loss: 7070.2213 - accuracy: 0.9339 - val_loss: 9678.0127 - val_accuracy: 0.8683\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 742us/sample - loss: 29490.4364 - accuracy: 0.8528 - val_loss: 26867.8684 - val_accuracy: 0.8605\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 25990.5760 - accuracy: 0.8858 - val_loss: 24804.9818 - val_accuracy: 0.8374\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 613us/sample - loss: 23883.7593 - accuracy: 0.8919 - val_loss: 23313.8093 - val_accuracy: 0.8577\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 22060.3172 - accuracy: 0.8962 - val_loss: 22053.0256 - val_accuracy: 0.8865\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 614us/sample - loss: 20656.0995 - accuracy: 0.8997 - val_loss: 20886.5076 - val_accuracy: 0.8949\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 19452.9201 - accuracy: 0.8990 - val_loss: 20096.6466 - val_accuracy: 0.9005\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8082/8082 [==============================] - 5s 611us/sample - loss: 18431.8685 - accuracy: 0.9029 - val_loss: 19322.5066 - val_accuracy: 0.8816\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 613us/sample - loss: 17581.5832 - accuracy: 0.9076 - val_loss: 18878.7037 - val_accuracy: 0.8753\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 16843.4030 - accuracy: 0.9103 - val_loss: 18681.0123 - val_accuracy: 0.8879\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 613us/sample - loss: 16207.8394 - accuracy: 0.9114 - val_loss: 18054.3977 - val_accuracy: 0.8746\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 600us/sample - loss: 15667.5533 - accuracy: 0.9063 - val_loss: 17478.0115 - val_accuracy: 0.8388\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 15236.2167 - accuracy: 0.9122 - val_loss: 17402.4063 - val_accuracy: 0.8676\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 14855.1675 - accuracy: 0.9093 - val_loss: 17235.1758 - val_accuracy: 0.8458\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 14540.0383 - accuracy: 0.9109 - val_loss: 17040.9751 - val_accuracy: 0.9075\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 613us/sample - loss: 14278.8198 - accuracy: 0.9136 - val_loss: 16800.5204 - val_accuracy: 0.9005\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 14059.9476 - accuracy: 0.9159 - val_loss: 16386.7509 - val_accuracy: 0.8528\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 13856.5012 - accuracy: 0.9165 - val_loss: 16218.0164 - val_accuracy: 0.8227\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 13748.7226 - accuracy: 0.9150 - val_loss: 16303.7604 - val_accuracy: 0.8507\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 613us/sample - loss: 13609.8597 - accuracy: 0.9220 - val_loss: 15998.6009 - val_accuracy: 0.8704\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 13498.2267 - accuracy: 0.9209 - val_loss: 16310.7415 - val_accuracy: 0.8746\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 13477.1569 - accuracy: 0.9181 - val_loss: 15931.7800 - val_accuracy: 0.8612\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 614us/sample - loss: 13312.3100 - accuracy: 0.9216 - val_loss: 15990.6831 - val_accuracy: 0.8683\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 13311.2936 - accuracy: 0.9214 - val_loss: 15589.3063 - val_accuracy: 0.8655\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 13274.5931 - accuracy: 0.9222 - val_loss: 15371.4927 - val_accuracy: 0.9026\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 576us/sample - loss: 13171.0464 - accuracy: 0.9250 - val_loss: 15812.9281 - val_accuracy: 0.8837\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 736us/sample - loss: 44870.2342 - accuracy: 0.7811 - val_loss: 40979.1136 - val_accuracy: 0.6678\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 596us/sample - loss: 39713.1236 - accuracy: 0.8300 - val_loss: 38277.7206 - val_accuracy: 0.8024\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 36915.5845 - accuracy: 0.8578 - val_loss: 36047.4609 - val_accuracy: 0.8507\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 34613.7503 - accuracy: 0.8700 - val_loss: 34462.3011 - val_accuracy: 0.8662\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 32913.5151 - accuracy: 0.8755 - val_loss: 33196.1033 - val_accuracy: 0.8662\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 31718.6498 - accuracy: 0.8816 - val_loss: 32563.8320 - val_accuracy: 0.8851\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 612us/sample - loss: 30735.6994 - accuracy: 0.8865 - val_loss: 31840.0321 - val_accuracy: 0.8872\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 29880.1874 - accuracy: 0.8883 - val_loss: 31041.2735 - val_accuracy: 0.8563\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 29199.6358 - accuracy: 0.8877 - val_loss: 30574.7852 - val_accuracy: 0.8984\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 576us/sample - loss: 28604.3112 - accuracy: 0.8931 - val_loss: 29983.6223 - val_accuracy: 0.9159\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 594us/sample - loss: 27966.0390 - accuracy: 0.8948 - val_loss: 30516.0786 - val_accuracy: 0.8823\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 591us/sample - loss: 27484.3290 - accuracy: 0.8985 - val_loss: 29401.1013 - val_accuracy: 0.8402\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 590us/sample - loss: 27125.9284 - accuracy: 0.8957 - val_loss: 29189.9895 - val_accuracy: 0.9012\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 590us/sample - loss: 26794.4272 - accuracy: 0.8994 - val_loss: 28595.5502 - val_accuracy: 0.8276\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 590us/sample - loss: 26549.5559 - accuracy: 0.9013 - val_loss: 28573.0233 - val_accuracy: 0.8430\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 568us/sample - loss: 26315.1077 - accuracy: 0.9036 - val_loss: 28209.8257 - val_accuracy: 0.8283\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 26110.5083 - accuracy: 0.9046 - val_loss: 28273.8961 - val_accuracy: 0.8150\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 586us/sample - loss: 25951.1704 - accuracy: 0.9045 - val_loss: 28071.4636 - val_accuracy: 0.8220\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 578us/sample - loss: 25850.6304 - accuracy: 0.9083 - val_loss: 27779.4866 - val_accuracy: 0.9005\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 25724.9179 - accuracy: 0.9091 - val_loss: 27988.2999 - val_accuracy: 0.8486\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 25665.2356 - accuracy: 0.9108 - val_loss: 28102.9407 - val_accuracy: 0.8949\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 589us/sample - loss: 25570.8893 - accuracy: 0.9138 - val_loss: 28082.0589 - val_accuracy: 0.8795\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 585us/sample - loss: 25533.8605 - accuracy: 0.9119 - val_loss: 28148.0703 - val_accuracy: 0.8977\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 4s 455us/sample - loss: 25542.4077 - accuracy: 0.9115 - val_loss: 28148.4192 - val_accuracy: 0.8781\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 4s 505us/sample - loss: 25446.8957 - accuracy: 0.9103 - val_loss: 27724.7662 - val_accuracy: 0.8809\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 731us/sample - loss: 76143.7430 - accuracy: 0.7811 - val_loss: 69610.0710 - val_accuracy: 0.5936\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 67529.5153 - accuracy: 0.8347 - val_loss: 65317.1403 - val_accuracy: 0.7302\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 63134.2702 - accuracy: 0.8675 - val_loss: 61369.5349 - val_accuracy: 0.8577\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 59397.1609 - accuracy: 0.8727 - val_loss: 58578.5524 - val_accuracy: 0.8914\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 57014.3265 - accuracy: 0.8706 - val_loss: 57139.2636 - val_accuracy: 0.8122\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 55689.1832 - accuracy: 0.8747 - val_loss: 56184.2336 - val_accuracy: 0.8150\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 54710.9922 - accuracy: 0.8774 - val_loss: 55716.2373 - val_accuracy: 0.8648\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 53938.4990 - accuracy: 0.8817 - val_loss: 55040.7826 - val_accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 594us/sample - loss: 53238.1751 - accuracy: 0.8827 - val_loss: 54579.3192 - val_accuracy: 0.9208\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 52640.9653 - accuracy: 0.8943 - val_loss: 54495.3913 - val_accuracy: 0.8486\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 52147.0316 - accuracy: 0.8896 - val_loss: 54148.3518 - val_accuracy: 0.9054\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 51726.9439 - accuracy: 0.8909 - val_loss: 53509.5255 - val_accuracy: 0.8921\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 51397.9265 - accuracy: 0.8924 - val_loss: 53202.4825 - val_accuracy: 0.9075\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 51052.7875 - accuracy: 0.8941 - val_loss: 53347.6984 - val_accuracy: 0.9117\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 50872.6809 - accuracy: 0.8977 - val_loss: 52829.3410 - val_accuracy: 0.8900\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 50647.8758 - accuracy: 0.8935 - val_loss: 52794.2797 - val_accuracy: 0.8872\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 50565.3333 - accuracy: 0.8998 - val_loss: 52594.3673 - val_accuracy: 0.9005\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 50396.8312 - accuracy: 0.9000 - val_loss: 52807.2464 - val_accuracy: 0.9173\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 50278.8450 - accuracy: 0.9015 - val_loss: 52555.0527 - val_accuracy: 0.9131\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 50204.0882 - accuracy: 0.9023 - val_loss: 52410.2294 - val_accuracy: 0.8998\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 50147.8912 - accuracy: 0.9011 - val_loss: 52146.1376 - val_accuracy: 0.8935\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 50059.2970 - accuracy: 0.9084 - val_loss: 52200.5398 - val_accuracy: 0.9110\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 49997.6583 - accuracy: 0.8987 - val_loss: 52239.8101 - val_accuracy: 0.8865\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 49912.5084 - accuracy: 0.9077 - val_loss: 52118.3985 - val_accuracy: 0.8711\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 49884.6011 - accuracy: 0.9062 - val_loss: 52272.2007 - val_accuracy: 0.8879\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 732us/sample - loss: 140206.3877 - accuracy: 0.8262 - val_loss: 128144.2374 - val_accuracy: 0.7379\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 602us/sample - loss: 124573.9333 - accuracy: 0.8690 - val_loss: 120699.7936 - val_accuracy: 0.7954\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 117029.7408 - accuracy: 0.8825 - val_loss: 113771.9382 - val_accuracy: 0.8500\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 110309.0133 - accuracy: 0.8820 - val_loss: 108095.5141 - val_accuracy: 0.8655\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 106491.9227 - accuracy: 0.8632 - val_loss: 105973.8335 - val_accuracy: 0.8998\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 105161.6489 - accuracy: 0.8646 - val_loss: 105572.1154 - val_accuracy: 0.8227\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 104105.5837 - accuracy: 0.8701 - val_loss: 105240.6472 - val_accuracy: 0.7022\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 588us/sample - loss: 103378.4884 - accuracy: 0.8760 - val_loss: 104271.5561 - val_accuracy: 0.8535\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 102736.3168 - accuracy: 0.8768 - val_loss: 103816.3622 - val_accuracy: 0.9159\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 102177.0204 - accuracy: 0.8753 - val_loss: 103341.8529 - val_accuracy: 0.8956\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 101724.7873 - accuracy: 0.8842 - val_loss: 103655.6739 - val_accuracy: 0.7884\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 101341.2700 - accuracy: 0.8848 - val_loss: 102781.4907 - val_accuracy: 0.9117\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 101022.5726 - accuracy: 0.8878 - val_loss: 102676.7100 - val_accuracy: 0.8998\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 100754.0159 - accuracy: 0.8881 - val_loss: 102673.1080 - val_accuracy: 0.8760\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 100510.9616 - accuracy: 0.8858 - val_loss: 102600.4145 - val_accuracy: 0.8900\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 100416.1738 - accuracy: 0.8888 - val_loss: 102503.7507 - val_accuracy: 0.8507\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 100215.6866 - accuracy: 0.8907 - val_loss: 102232.0705 - val_accuracy: 0.8129\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 100162.4062 - accuracy: 0.8925 - val_loss: 101890.8153 - val_accuracy: 0.9047\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 100006.2522 - accuracy: 0.8904 - val_loss: 101700.6961 - val_accuracy: 0.8725\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 99873.6538 - accuracy: 0.8958 - val_loss: 101933.4361 - val_accuracy: 0.7954\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 99846.1194 - accuracy: 0.8938 - val_loss: 101507.4940 - val_accuracy: 0.8914\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 610us/sample - loss: 99804.0221 - accuracy: 0.8951 - val_loss: 101561.3369 - val_accuracy: 0.9026\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 614us/sample - loss: 99667.8803 - accuracy: 0.8948 - val_loss: 101490.4462 - val_accuracy: 0.8928\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 99689.4030 - accuracy: 0.8959 - val_loss: 101310.3289 - val_accuracy: 0.8998\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 99630.3132 - accuracy: 0.8984 - val_loss: 101269.1489 - val_accuracy: 0.8851\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 733us/sample - loss: 270493.2884 - accuracy: 0.8395 - val_loss: 247364.1464 - val_accuracy: 0.8556\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 598us/sample - loss: 240566.7991 - accuracy: 0.8795 - val_loss: 233491.1673 - val_accuracy: 0.8535\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 226586.4764 - accuracy: 0.8857 - val_loss: 220156.8247 - val_accuracy: 0.8591\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 213602.7831 - accuracy: 0.8820 - val_loss: 208848.0943 - val_accuracy: 0.8949\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 609us/sample - loss: 206797.2191 - accuracy: 0.8413 - val_loss: 206288.7825 - val_accuracy: 0.8872\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 594us/sample - loss: 205424.7847 - accuracy: 0.8439 - val_loss: 205444.6197 - val_accuracy: 0.8465\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 599us/sample - loss: 204473.0861 - accuracy: 0.8525 - val_loss: 204648.7335 - val_accuracy: 0.8977\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 203725.1409 - accuracy: 0.8540 - val_loss: 204663.1815 - val_accuracy: 0.8648\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 203032.2053 - accuracy: 0.8619 - val_loss: 205219.7554 - val_accuracy: 0.9047\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 202466.4112 - accuracy: 0.8679 - val_loss: 203372.8335 - val_accuracy: 0.8907\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 202012.2553 - accuracy: 0.8753 - val_loss: 203279.9527 - val_accuracy: 0.8774\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 201676.1582 - accuracy: 0.8691 - val_loss: 202756.1621 - val_accuracy: 0.9089\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 608us/sample - loss: 201306.6765 - accuracy: 0.8744 - val_loss: 202964.1314 - val_accuracy: 0.9138\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 201063.2612 - accuracy: 0.8714 - val_loss: 202294.7456 - val_accuracy: 0.9026\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 601us/sample - loss: 200930.8699 - accuracy: 0.8760 - val_loss: 202324.3352 - val_accuracy: 0.9040\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 200652.6514 - accuracy: 0.8722 - val_loss: 202035.1028 - val_accuracy: 0.9068\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 200579.2297 - accuracy: 0.8753 - val_loss: 203041.0738 - val_accuracy: 0.9159\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 200417.0745 - accuracy: 0.8816 - val_loss: 202643.7434 - val_accuracy: 0.8626\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 604us/sample - loss: 200324.9808 - accuracy: 0.8785 - val_loss: 201864.0774 - val_accuracy: 0.9187\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 200322.8602 - accuracy: 0.8753 - val_loss: 201937.0095 - val_accuracy: 0.8816\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 200228.1319 - accuracy: 0.8794 - val_loss: 201660.6283 - val_accuracy: 0.9201\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 607us/sample - loss: 200171.4523 - accuracy: 0.8790 - val_loss: 201570.1348 - val_accuracy: 0.9145\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 605us/sample - loss: 200057.0281 - accuracy: 0.8802 - val_loss: 201406.1214 - val_accuracy: 0.8823\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 199970.0774 - accuracy: 0.8812 - val_loss: 201434.5184 - val_accuracy: 0.9096\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 606us/sample - loss: 199975.3811 - accuracy: 0.8795 - val_loss: 201480.8161 - val_accuracy: 0.8304\n",
      "Train on 8082 samples, validate on 1427 samples\n",
      "Epoch 1/25\n",
      "8082/8082 [==============================] - 6s 734us/sample - loss: 536056.1887 - accuracy: 0.8420 - val_loss: 490278.8695 - val_accuracy: 0.7947\n",
      "Epoch 2/25\n",
      "8082/8082 [==============================] - 5s 603us/sample - loss: 477097.6833 - accuracy: 0.8806 - val_loss: 463444.4363 - val_accuracy: 0.8234\n",
      "Epoch 3/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 450082.6027 - accuracy: 0.8848 - val_loss: 436907.5952 - val_accuracy: 0.8493\n",
      "Epoch 4/25\n",
      "8082/8082 [==============================] - 5s 611us/sample - loss: 424135.6142 - accuracy: 0.8744 - val_loss: 414208.6070 - val_accuracy: 0.8914\n",
      "Epoch 5/25\n",
      "8082/8082 [==============================] - 5s 587us/sample - loss: 410751.5632 - accuracy: 0.8244 - val_loss: 409622.3630 - val_accuracy: 0.8395\n",
      "Epoch 6/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 409015.8063 - accuracy: 0.8236 - val_loss: 408569.6641 - val_accuracy: 0.8830\n",
      "Epoch 7/25\n",
      "8082/8082 [==============================] - 5s 620us/sample - loss: 408089.4108 - accuracy: 0.8346 - val_loss: 408015.7876 - val_accuracy: 0.8914\n",
      "Epoch 8/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 407433.3692 - accuracy: 0.8363 - val_loss: 407705.5260 - val_accuracy: 0.8725\n",
      "Epoch 9/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 406860.6102 - accuracy: 0.8436 - val_loss: 407515.9329 - val_accuracy: 0.7281\n",
      "Epoch 10/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 406340.9644 - accuracy: 0.8469 - val_loss: 407342.5559 - val_accuracy: 0.7372\n",
      "Epoch 11/25\n",
      "8082/8082 [==============================] - 5s 618us/sample - loss: 405936.8306 - accuracy: 0.8494 - val_loss: 406728.6189 - val_accuracy: 0.8823\n",
      "Epoch 12/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 405505.9064 - accuracy: 0.8550 - val_loss: 406543.6712 - val_accuracy: 0.8949\n",
      "Epoch 13/25\n",
      "8082/8082 [==============================] - 5s 615us/sample - loss: 405263.4915 - accuracy: 0.8567 - val_loss: 405815.1002 - val_accuracy: 0.8423\n",
      "Epoch 14/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 404942.7935 - accuracy: 0.8597 - val_loss: 406563.1477 - val_accuracy: 0.6945\n",
      "Epoch 15/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 404782.9727 - accuracy: 0.8562 - val_loss: 405991.4963 - val_accuracy: 0.9082\n",
      "Epoch 16/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 404641.7279 - accuracy: 0.8635 - val_loss: 405460.3499 - val_accuracy: 0.8823\n",
      "Epoch 17/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 404534.7477 - accuracy: 0.8607 - val_loss: 405851.4901 - val_accuracy: 0.7386\n",
      "Epoch 18/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 404328.9556 - accuracy: 0.8604 - val_loss: 406048.2913 - val_accuracy: 0.8493\n",
      "Epoch 19/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 404279.0975 - accuracy: 0.8674 - val_loss: 405472.1243 - val_accuracy: 0.9082\n",
      "Epoch 20/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 404181.8995 - accuracy: 0.8656 - val_loss: 405295.5298 - val_accuracy: 0.8781\n",
      "Epoch 21/25\n",
      "8082/8082 [==============================] - 5s 618us/sample - loss: 404175.1665 - accuracy: 0.8649 - val_loss: 405582.7086 - val_accuracy: 0.8998\n",
      "Epoch 22/25\n",
      "8082/8082 [==============================] - 5s 616us/sample - loss: 404059.7415 - accuracy: 0.8624 - val_loss: 405028.8140 - val_accuracy: 0.8865\n",
      "Epoch 23/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 403950.4017 - accuracy: 0.8648 - val_loss: 405218.1267 - val_accuracy: 0.8795\n",
      "Epoch 24/25\n",
      "8082/8082 [==============================] - 5s 618us/sample - loss: 403989.9613 - accuracy: 0.8659 - val_loss: 405546.6607 - val_accuracy: 0.7239\n",
      "Epoch 25/25\n",
      "8082/8082 [==============================] - 5s 617us/sample - loss: 403974.6310 - accuracy: 0.8649 - val_loss: 405378.0378 - val_accuracy: 0.8844\n",
      "CPU times: user 1h 19min 33s, sys: 17min 46s, total: 1h 37min 19s\n",
      "Wall time: 30min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weights_history = []\n",
    "loss = []\n",
    "val_loss = []\n",
    "\n",
    "num_alphas = 12\n",
    "alpha_range = np.logspace(-.3, 3.1, num_alphas)\n",
    "\n",
    "weights = np.array([])\n",
    "acc = np.array([])\n",
    "for al in alpha_range:\n",
    "    model=Sequential() #Declare model\n",
    "    # Add selection layer (Time distributed)\n",
    "    model.add(TimeDistributed(selection_layer(units=X_train.shape[2], alpha = al, norm=100)))\n",
    "\n",
    "    #Add recurrent layer\n",
    "    model.add(LSTM(64, recurrent_dropout=.1,dropout=.1)) #Within recurrent layer, include dropout\n",
    "    model.add(Dropout(.1)) #Dropout some units (recurrent layer output units)\n",
    "\n",
    "    #Add dense connections to output layer\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    #Fit model (and set fitting parameters)\n",
    "    model.compile(loss='mse',optimizer='rmsprop',metrics=['accuracy']) #Set loss function and optimizer\n",
    "    #Fit the model\n",
    "    hi = model.fit(X_train,y_train, epochs=25, verbose=1, validation_split = .15, \n",
    "                   callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience= 10, verbose=0, mode='auto'), MyCallback()]) \n",
    "    weights = np.append(weights,tf.linalg.tensor_diag_part(model.layers[0].weights[0]).numpy())\n",
    "    acc = np.append(acc, r2_score(y_test,model.predict(X_test)))\n",
    "    loss= np.append(loss, hi.history['loss'])\n",
    "    val_loss = np.append(val_loss, hi.history['val_loss'])\n",
    "weights = weights.reshape(-1,X_train.shape[2])\n",
    "weights_history = np.array(weights_history).reshape(num_alphas,-1, X_train.shape[2])\n",
    "loss = loss.reshape(num_alphas,-1)\n",
    "val_loss = val_loss.reshape(num_alphas,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "save for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savez('hippocampus_for_poster', weights=weights, weights_history=weights_history, alpha_range=alpha_range, loss=loss, val_loss=val_loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "weight",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_obj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight is not a file in the archive'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-73ddc65c1b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hippocampus_for_poster.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_obj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: weight"
     ]
    }
   ],
   "source": [
    "data = np.load('hippocampus_for_poster.npz')\n",
    "weights, weights_history, alpha_range, loss, val_loss = data.f.weight, data.f.weights_history, data.f.alpha_range, data.f.loss, data.f.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92357421, 0.92698608, 0.92233252, 0.92108096, 0.91525409,\n",
       "       0.91818462, 0.91182068, 0.90188446, 0.89707568, 0.84478207,\n",
       "       0.80698121, 0.76027209])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ind = -2\n",
    "[plt.plot(x, c = 'indianred', lw = .5) for x in weights_history[ind].T[:]]\n",
    "#[plt.plot(x, c = 'dodgerblue') for x in weights_history[ind].T[10:]]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "performance and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha_new = array(['{:.2f}'.format(x) for x in alpha_range])\n",
    "alpha_new = alpha_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\n",
    "#fig.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(r'Performance and feature selection as function of $\\alpha$')\n",
    "\n",
    "ax[0].plot(alpha_range, acc, color = 'olivedrab')\n",
    "#xlabel(r'regularization strength $\\alpha$')\n",
    "ax[0].set_ylabel(r'$r^2$-score')\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "tick = ticker.ScalarFormatter(useOffset=False, useMathText=True)\n",
    "tick.set_powerlimits((0,0))\n",
    "tg = [u\"${}$\".format(tick.format_data(x)) for x in alpha_new]\n",
    "\n",
    "sns.heatmap((weights[:,argsort(sum(weights>0, axis=0))].T>0), ax=ax[1],cmap='tab20c_r', alpha=.7, cbar=False, linewidth=.3, linecolor = 'k', xticklabels=tg)\n",
    "ax[1].set_ylabel('cell # (sorted)')\n",
    "ax[1].set_xlabel(r'regularization strength $\\alpha$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ind = -2\n",
    "[plt.plot(x, c = 'dodgerblue', lw = .75, alpha = .7) for x in weights_history[ind].T]\n",
    "plt.xlabel('# batches')\n",
    "plt.ylabel('selection layer weights')\n",
    "plt.title(r'$\\alpha$={:.2f}'.format(alpha_range[ind]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = -2\n",
    "plt.figure()\n",
    "plt.plot(loss[ind], label='loss')\n",
    "plt.plot(val_loss[ind], label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.title(r'$\\alpha$={:.2f}'.format(alpha_range[ind]))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**notes**\n",
    "- schedulder for offset (!)\n",
    "- compare different feature selectors (and performance at random set with same size)\n",
    "- show correlations\n",
    "- hippocampus temporal data\n",
    "- better for removing unimportant than for ranking!\n",
    "- only for positive values"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
